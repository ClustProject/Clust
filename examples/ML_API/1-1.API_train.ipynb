{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0e3d70",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d01d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available.\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as iC\n",
    "from Clust.clust.ingestion.mongo import mongo_client\n",
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "from Clust.clust.ML.common import ML_api\n",
    "influxdb_client = iC.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongodb_client = mongo_client.MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472041e",
   "metadata": {},
   "source": [
    "# 1. set param from Front End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a7b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "param1 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainy',\n",
    "        \"feature_list\":[\"value\"]\n",
    "    },\n",
    "    'data_y_flag' : 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'split_mode' : 'window_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'data_clean_option' : \"false\"\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# forecasting\n",
    "param2 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Temperature', 'out_temp','sin_hour']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainy',\n",
    "        \"feature_list\":['Temperature']\n",
    "    },\n",
    "    'data_y_flag' : 'false',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"false\",\n",
    "        'split_mode' : 'step_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        'past_step':24, #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'future_step':2\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# classification\n",
    "param3 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainX',\n",
    "        \"feature_list\":['col_0', 'col_1','col_2','col_3','col_4','col_5','col_6','col_7','col_8']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainy',\n",
    "        \"feature_list\":['value']\n",
    "    },\n",
    "    'data_y_flag' : 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"false\",\n",
    "        'split_mode' : 'window_split' # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "    },\n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'classification',\n",
    "        'model_method' : 'LSTM_cf',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\",\"num_classes\":6, 'rnn_type':'lstm'}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79772cfb",
   "metadata": {},
   "source": [
    "# 2. Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3436645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Backend Prameter Setting\n",
    "from Clust.clust.ML.common import ML_api\n",
    "\n",
    "# parameter tunning\n",
    "param = param1\n",
    "param = ML_api.convert_param_for_backend(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7fbfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. train data meta check\n",
    "train_data_info = ML_api.get_train_data_meta (mongodb_client, param['ingestion_param_X'])\n",
    "param['train_data_info'] = train_data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc8d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket_name': 'integration', 'ms_name': 'regression_energy_cleanLevel4_trainX', 'feature_list': ['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']}\n",
      "['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
      "Make New scaler File\n",
      "./scaler/regression_energy_cleanLevel4_trainX/minmax/900878d7bba6f2a4017d1c3399909ea7/scaler.pkl\n",
      "['value']\n",
      "Make New scaler File\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'split_mode': 'window_split',\n",
       " 'data_clean_option': False,\n",
       " 'nan_process_info': {'type': 'num',\n",
       "  'ConsecutiveNanLimit': 10000,\n",
       "  'totalNaNLimit': 100000},\n",
       " 'max_nan_limit_ratio': 0.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Data Preparation\n",
    "#train_X_array, train_y_array, val_X_array, val_y_array = ML_api.ML_data_preparation(param, influxdb_client)\n",
    "\n",
    "from Clust.clust.ML.common import ML_pipeline\n",
    "# 1. Oirignla data ingestion\n",
    "data_X, data_y = ML_pipeline.Xy_data_preparation(param['ingestion_param_X'], \n",
    "                                             param['data_y_flag'], \n",
    "                                             param['ingestion_param_y'],\n",
    "                                             'ms_all', \n",
    "                                             influxdb_client)\n",
    "# 2. Scaling\n",
    "dataX_scaled, datay_scaled = ML_pipeline.Xy_data_scaling_train(param['ingestion_param_X']['ms_name'], \n",
    "                                                                                 data_X, \n",
    "                                                                                 param['ingestion_param_y']['ms_name'], \n",
    "                                                                                 data_y, \n",
    "                                                                                 param['scaler_param'])\n",
    "\n",
    "\n",
    "\n",
    "# 3.clean column\n",
    "dataX_scaled = ML_pipeline.clean_low_quality_column(dataX_scaled, param['transform_param'])\n",
    "\n",
    "param['transform_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a8d616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split_mode': 'window_split', 'data_clean_option': False, 'nan_process_info': {'type': 'num', 'ConsecutiveNanLimit': 10000, 'totalNaNLimit': 100000}, 'max_nan_limit_ratio': 0.5, 'future_step': None, 'past_step': 144}\n",
      "window_split\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 4. split train/Val\n",
    "split_ratio = 0.8\n",
    "train_X, val_X, train_y, val_y, param['transform_param']= ML_pipeline.split_data_by_mode(dataX_scaled, \n",
    "                                                                                         datay_scaled, \n",
    "                                                                                         split_ratio, \n",
    "                                                                                         param['transform_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2067660c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>RH_5</th>\n",
       "      <th>RH_6</th>\n",
       "      <th>RH_7</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>...</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Windspeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-11 00:00:00+00:00</th>\n",
       "      <td>0.693237</td>\n",
       "      <td>0.127786</td>\n",
       "      <td>0.324722</td>\n",
       "      <td>0.255336</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.230779</td>\n",
       "      <td>0.247370</td>\n",
       "      <td>0.205674</td>\n",
       "      <td>0.171008</td>\n",
       "      <td>0.426523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417117</td>\n",
       "      <td>0.196847</td>\n",
       "      <td>0.353806</td>\n",
       "      <td>0.622997</td>\n",
       "      <td>0.570034</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>0.335484</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 00:10:00+00:00</th>\n",
       "      <td>0.695250</td>\n",
       "      <td>0.134942</td>\n",
       "      <td>0.328622</td>\n",
       "      <td>0.258140</td>\n",
       "      <td>0.105062</td>\n",
       "      <td>0.228774</td>\n",
       "      <td>0.252495</td>\n",
       "      <td>0.203073</td>\n",
       "      <td>0.171008</td>\n",
       "      <td>0.428085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417117</td>\n",
       "      <td>0.196847</td>\n",
       "      <td>0.350216</td>\n",
       "      <td>0.616085</td>\n",
       "      <td>0.563625</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>0.332258</td>\n",
       "      <td>0.110106</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.525641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 00:20:00+00:00</th>\n",
       "      <td>0.697262</td>\n",
       "      <td>0.138611</td>\n",
       "      <td>0.336128</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.112363</td>\n",
       "      <td>0.229225</td>\n",
       "      <td>0.249798</td>\n",
       "      <td>0.204374</td>\n",
       "      <td>0.173521</td>\n",
       "      <td>0.428085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.203854</td>\n",
       "      <td>0.346335</td>\n",
       "      <td>0.609488</td>\n",
       "      <td>0.556912</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.111614</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 00:30:00+00:00</th>\n",
       "      <td>0.699275</td>\n",
       "      <td>0.144115</td>\n",
       "      <td>0.343927</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.118024</td>\n",
       "      <td>0.228323</td>\n",
       "      <td>0.247808</td>\n",
       "      <td>0.204374</td>\n",
       "      <td>0.177862</td>\n",
       "      <td>0.426523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.196847</td>\n",
       "      <td>0.344297</td>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.547757</td>\n",
       "      <td>0.371835</td>\n",
       "      <td>0.325806</td>\n",
       "      <td>0.113122</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 00:40:00+00:00</th>\n",
       "      <td>0.701288</td>\n",
       "      <td>0.146133</td>\n",
       "      <td>0.350556</td>\n",
       "      <td>0.263281</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>0.226819</td>\n",
       "      <td>0.249764</td>\n",
       "      <td>0.203073</td>\n",
       "      <td>0.175805</td>\n",
       "      <td>0.426523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411411</td>\n",
       "      <td>0.196847</td>\n",
       "      <td>0.342163</td>\n",
       "      <td>0.594722</td>\n",
       "      <td>0.542264</td>\n",
       "      <td>0.371835</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.114630</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26 23:10:00+00:00</th>\n",
       "      <td>0.754831</td>\n",
       "      <td>0.201174</td>\n",
       "      <td>0.328037</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>0.148118</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>0.177862</td>\n",
       "      <td>0.391392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723724</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.791706</td>\n",
       "      <td>0.805005</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.605376</td>\n",
       "      <td>0.479638</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26 23:20:00+00:00</th>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.188148</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>0.138881</td>\n",
       "      <td>0.116991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189970</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.790494</td>\n",
       "      <td>0.802389</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.466063</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26 23:30:00+00:00</th>\n",
       "      <td>0.752415</td>\n",
       "      <td>0.185396</td>\n",
       "      <td>0.330209</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>0.147820</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190780</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.386706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717718</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.795850</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.609677</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26 23:40:00+00:00</th>\n",
       "      <td>0.751208</td>\n",
       "      <td>0.185396</td>\n",
       "      <td>0.338448</td>\n",
       "      <td>0.256337</td>\n",
       "      <td>0.167486</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.172515</td>\n",
       "      <td>0.380804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723724</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.693494</td>\n",
       "      <td>0.789282</td>\n",
       "      <td>0.793836</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.611828</td>\n",
       "      <td>0.438914</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26 23:50:00+00:00</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.190166</td>\n",
       "      <td>0.343620</td>\n",
       "      <td>0.259168</td>\n",
       "      <td>0.185364</td>\n",
       "      <td>0.107132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187943</td>\n",
       "      <td>0.171008</td>\n",
       "      <td>0.378613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.688837</td>\n",
       "      <td>0.786616</td>\n",
       "      <td>0.788657</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.613978</td>\n",
       "      <td>0.425339</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10944 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Press_mm_hg      RH_1      RH_2      RH_3  \\\n",
       "time                                                                   \n",
       "2016-01-11 00:00:00+00:00     0.693237  0.127786  0.324722  0.255336   \n",
       "2016-01-11 00:10:00+00:00     0.695250  0.134942  0.328622  0.258140   \n",
       "2016-01-11 00:20:00+00:00     0.697262  0.138611  0.336128  0.263281   \n",
       "2016-01-11 00:30:00+00:00     0.699275  0.144115  0.343927  0.263281   \n",
       "2016-01-11 00:40:00+00:00     0.701288  0.146133  0.350556  0.263281   \n",
       "...                                ...       ...       ...       ...   \n",
       "2016-03-26 23:10:00+00:00     0.754831  0.201174  0.328037  0.253934   \n",
       "2016-03-26 23:20:00+00:00     0.753623  0.188148  0.320199  0.253934   \n",
       "2016-03-26 23:30:00+00:00     0.752415  0.185396  0.330209  0.253934   \n",
       "2016-03-26 23:40:00+00:00     0.751208  0.185396  0.338448  0.256337   \n",
       "2016-03-26 23:50:00+00:00     0.750000  0.190166  0.343620  0.259168   \n",
       "\n",
       "                               RH_4      RH_5      RH_6      RH_7      RH_8  \\\n",
       "time                                                                          \n",
       "2016-01-11 00:00:00+00:00  0.102083  0.230779  0.247370  0.205674  0.171008   \n",
       "2016-01-11 00:10:00+00:00  0.105062  0.228774  0.252495  0.203073  0.171008   \n",
       "2016-01-11 00:20:00+00:00  0.112363  0.229225  0.249798  0.204374  0.173521   \n",
       "2016-01-11 00:30:00+00:00  0.118024  0.228323  0.247808  0.204374  0.177862   \n",
       "2016-01-11 00:40:00+00:00  0.124430  0.226819  0.249764  0.203073  0.175805   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2016-03-26 23:10:00+00:00  0.148118  0.121567  0.000000  0.192819  0.177862   \n",
       "2016-03-26 23:20:00+00:00  0.138881  0.116991  0.000000  0.189970  0.174777   \n",
       "2016-03-26 23:30:00+00:00  0.147820  0.111853  0.000000  0.190780  0.174777   \n",
       "2016-03-26 23:40:00+00:00  0.167486  0.109323  0.000000  0.187943  0.172515   \n",
       "2016-03-26 23:50:00+00:00  0.185364  0.107132  0.000000  0.187943  0.171008   \n",
       "\n",
       "                               RH_9  ...        T4        T5        T6  \\\n",
       "time                                 ...                                 \n",
       "2016-01-11 00:00:00+00:00  0.426523  ...  0.417117  0.196847  0.353806   \n",
       "2016-01-11 00:10:00+00:00  0.428085  ...  0.417117  0.196847  0.350216   \n",
       "2016-01-11 00:20:00+00:00  0.428085  ...  0.414414  0.203854  0.346335   \n",
       "2016-01-11 00:30:00+00:00  0.426523  ...  0.414414  0.196847  0.344297   \n",
       "2016-01-11 00:40:00+00:00  0.426523  ...  0.411411  0.196847  0.342163   \n",
       "...                             ...  ...       ...       ...       ...   \n",
       "2016-03-26 23:10:00+00:00  0.391392  ...  0.723724  0.704252  0.682724   \n",
       "2016-03-26 23:20:00+00:00  0.389749  ...  0.717718  0.704252  0.682724   \n",
       "2016-03-26 23:30:00+00:00  0.386706  ...  0.717718  0.704252  0.685926   \n",
       "2016-03-26 23:40:00+00:00  0.380804  ...  0.723724  0.704252  0.693494   \n",
       "2016-03-26 23:50:00+00:00  0.378613  ...  0.735135  0.704252  0.688837   \n",
       "\n",
       "                                 T7        T8        T9     T_out  Tdewpoint  \\\n",
       "time                                                                           \n",
       "2016-01-11 00:00:00+00:00  0.622997  0.570034  0.375650  0.335484   0.108597   \n",
       "2016-01-11 00:10:00+00:00  0.616085  0.563625  0.375650  0.332258   0.110106   \n",
       "2016-01-11 00:20:00+00:00  0.609488  0.556912  0.375650  0.329032   0.111614   \n",
       "2016-01-11 00:30:00+00:00  0.603205  0.547757  0.371835  0.325806   0.113122   \n",
       "2016-01-11 00:40:00+00:00  0.594722  0.542264  0.371835  0.322581   0.114630   \n",
       "...                             ...       ...       ...       ...        ...   \n",
       "2016-03-26 23:10:00+00:00  0.791706  0.805005  0.832466  0.605376   0.479638   \n",
       "2016-03-26 23:20:00+00:00  0.790494  0.802389  0.832466  0.607527   0.466063   \n",
       "2016-03-26 23:30:00+00:00  0.786616  0.795850  0.832466  0.609677   0.452489   \n",
       "2016-03-26 23:40:00+00:00  0.789282  0.793836  0.832466  0.611828   0.438914   \n",
       "2016-03-26 23:50:00+00:00  0.786616  0.788657  0.832466  0.613978   0.425339   \n",
       "\n",
       "                           Visibility  Windspeed  \n",
       "time                                              \n",
       "2016-01-11 00:00:00+00:00    0.609375   0.538462  \n",
       "2016-01-11 00:10:00+00:00    0.609375   0.525641  \n",
       "2016-01-11 00:20:00+00:00    0.609375   0.512821  \n",
       "2016-01-11 00:30:00+00:00    0.609375   0.500000  \n",
       "2016-01-11 00:40:00+00:00    0.609375   0.487179  \n",
       "...                               ...        ...  \n",
       "2016-03-26 23:10:00+00:00    0.609375   0.153846  \n",
       "2016-03-26 23:20:00+00:00    0.609375   0.153846  \n",
       "2016-03-26 23:30:00+00:00    0.609375   0.153846  \n",
       "2016-03-26 23:40:00+00:00    0.609375   0.153846  \n",
       "2016-03-26 23:50:00+00:00    0.609375   0.153846  \n",
       "\n",
       "[10944 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32999ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.375\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(val_X)/128)\n",
    "print(len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a7ce2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 144 nan_limit_num: 72\n",
      "(10944, 24) (72, 144, 24)\n",
      "(76, 1) (72, 1)\n",
      "window_size: 144 nan_limit_num: 72\n",
      "(2736, 24) (19, 144, 24)\n",
      "(19, 1) (19, 1)\n"
     ]
    }
   ],
   "source": [
    "# 5. Transform array style\n",
    "train_X_array, train_y_array = ML_pipeline.transform_data_by_split_mode(param['transform_param'], \n",
    "                                                                        train_X, \n",
    "                                                                        train_y)\n",
    "val_X_array, val_y_array = ML_pipeline.transform_data_by_split_mode(param['transform_param'], \n",
    "                                                                    val_X, \n",
    "                                                                    val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6624e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 2, 'output_dim': 1, 'dropout': 0.1, 'bidirectional': True}\n",
      "./Models/LSTM_rg/regression_energy_cleanLevel4_trainX_regression_LSTM_rg_/regression_energy_cleanLevel4_trainX/model.pkl\n",
      "Start training model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4.Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[43mML_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mML_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/common/ML_api.py:186\u001b[0m, in \u001b[0;36mML_training\u001b[0;34m(train_X_array, train_y_array, val_X_array, val_y_array, param)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# input 순서 일관되도록 펑션 수정\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_purpose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m:    \n\u001b[0;32m--> 186\u001b[0m     \u001b[43mML_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLUST_regresstion_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_y_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_purpose\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    193\u001b[0m     ML_pipeline\u001b[38;5;241m.\u001b[39mCLUST_classification_train(train_X_array, \n\u001b[1;32m    194\u001b[0m                                            train_y_array, \n\u001b[1;32m    195\u001b[0m                                            val_X_array, \n\u001b[1;32m    196\u001b[0m                                            val_y_array, \n\u001b[1;32m    197\u001b[0m                                            param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/common/ML_pipeline.py:201\u001b[0m, in \u001b[0;36mCLUST_regresstion_train\u001b[0;34m(train_X_array, train_y_array, val_X_array, val_y_array, model_info)\u001b[0m\n\u001b[1;32m    199\u001b[0m rml\u001b[38;5;241m.\u001b[39mset_model(model_method, model_parameter)\n\u001b[1;32m    200\u001b[0m rml\u001b[38;5;241m.\u001b[39mset_data(train_X_array, train_y_array, val_X_array, val_y_array)\n\u001b[0;32m--> 201\u001b[0m \u001b[43mrml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m rml\u001b[38;5;241m.\u001b[39msave_best_model(model_file_path)\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/train.py:83\u001b[0m, in \u001b[0;36mRegressionTrain.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/clust_models/rnn_clust.py:69\u001b[0m, in \u001b[0;36mRNNClust.train\u001b[0;34m(self, train_params, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     67\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mview([batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_features])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mview([batch_size, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 69\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     71\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(batch_losses)\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/clust_models/rnn_clust.py:291\u001b[0m, in \u001b[0;36mRNNClust._train_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Makes predictions\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Computes loss\u001b[39;00m\n\u001b[1;32m    294\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y, yhat)\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/models/rnn.py:66\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_directions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# We need to detach as we are doing truncated backpropagation through time (BPTT)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Forward propagation by passing in the input, hidden state, and cell state into the model\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     68\u001b[0m     out, h0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x, h0\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu"
     ]
    }
   ],
   "source": [
    "# 4.Training\n",
    "param = ML_api.ML_training(train_X_array,  train_y_array, val_X_array, val_y_array, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e8f71cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingestion_param_X': {'bucket_name': 'integration',\n",
       "  'ms_name': 'regression_energy_cleanLevel4_trainX',\n",
       "  'feature_list': ['Press_mm_hg',\n",
       "   'RH_1',\n",
       "   'RH_2',\n",
       "   'RH_3',\n",
       "   'RH_4',\n",
       "   'RH_5',\n",
       "   'RH_6',\n",
       "   'RH_7',\n",
       "   'RH_8',\n",
       "   'RH_9',\n",
       "   'RH_out',\n",
       "   'T1',\n",
       "   'T2',\n",
       "   'T3',\n",
       "   'T4',\n",
       "   'T5',\n",
       "   'T6',\n",
       "   'T7',\n",
       "   'T8',\n",
       "   'T9',\n",
       "   'T_out',\n",
       "   'Tdewpoint',\n",
       "   'Visibility',\n",
       "   'Windspeed']},\n",
       " 'ingestion_param_y': {'bucket_name': 'integration',\n",
       "  'ms_name': 'regression_energy_cleanLevel4_trainy',\n",
       "  'feature_list': ['value']},\n",
       " 'data_y_flag': True,\n",
       " 'scaler_param': {'scaler_flag': 'scale',\n",
       "  'scale_method': 'minmax',\n",
       "  'scaler_path': './scaler/',\n",
       "  'scaler_file_path': {'XScalerFile': {'fileName': 'scaler.pkl',\n",
       "    'filePath': './scaler/regression_energy_cleanLevel4_trainX/minmax/900878d7bba6f2a4017d1c3399909ea7/scaler.pkl'},\n",
       "   'yScalerFile': {'fileName': 'scaler.pkl',\n",
       "    'filePath': './scaler/regression_energy_cleanLevel4_trainy/minmax/f69156750a210491ffd4a67b605bc88b/scaler.pkl'}}},\n",
       " 'transform_param': {'split_mode': 'window_split',\n",
       "  'data_clean_option': False,\n",
       "  'nan_process_info': {'type': 'num',\n",
       "   'ConsecutiveNanLimit': 10000,\n",
       "   'totalNaNLimit': 100000},\n",
       "  'max_nan_limit_ratio': 0.5,\n",
       "  'future_step': None,\n",
       "  'past_step': 144},\n",
       " 'model_info': {'model_purpose': 'regression',\n",
       "  'model_method': 'LSTM_rg',\n",
       "  'model_name': 'regression_energy_cleanLevel4_trainX_regression_LSTM_rg_',\n",
       "  'model_tags': 'tagstest',\n",
       "  'train_parameter': {'lr': 0.0001,\n",
       "   'weight_decay': 1e-06,\n",
       "   'n_epochs': 5,\n",
       "   'batch_size': 16,\n",
       "   'device': 'cuda'},\n",
       "  'model_parameter': {'rnn_type': 'lstm',\n",
       "   'input_size': 24,\n",
       "   'hidden_size': 64,\n",
       "   'num_layers': 2,\n",
       "   'output_dim': 1,\n",
       "   'dropout': 0.1,\n",
       "   'bidirectional': True},\n",
       "  'seq_len': 144,\n",
       "  'input_size': 24,\n",
       "  'model_file_path': {'modelFile': {'fileName': 'model.pth',\n",
       "    'filePath': './Models/LSTM_rg/regression_energy_cleanLevel4_trainX_regression_LSTM_rg_/regression_energy_cleanLevel4_trainX/model.pkl'}}},\n",
       " 'train_data_info': {'bucket_name': 'integration',\n",
       "  'collection_name': 'regression_energy',\n",
       "  'ms_name': 'regression_energy_cleanLevel4_trainX',\n",
       "  'ingestion_type': 'multiple_ms_by_time',\n",
       "  'ingestion_param': {'ms_list_info': [['life_indoor_environment',\n",
       "     'humidityTrain_10min'],\n",
       "    ['life_indoor_environment', 'temperatureTrain_10min'],\n",
       "    ['weather_outdoor_environment', 'belgiumChieverseAirportTrain_10min']],\n",
       "   'start_time': '2016-01-11',\n",
       "   'end_time': '2016-04-15'},\n",
       "  'processing_type': 'step_3',\n",
       "  'process_param': {'refine_param': {'remove_duplication': {'flag': True},\n",
       "    'static_frequency': {'flag': True, 'frequency': None}},\n",
       "   'outlier_param': {'certain_error_to_NaN': {'flag': True},\n",
       "    'uncertain_error_to_NaN': {'flag': True,\n",
       "     'param': {'outlierDetectorConfig': [{'algorithm': 'IQR',\n",
       "        'percentile': 99,\n",
       "        'alg_parameter': {'weight': 100}}]}}},\n",
       "   'imputation_param': {'flag': True,\n",
       "    'imputation_method': [{'min': 0,\n",
       "      'max': 2,\n",
       "      'method': 'linear',\n",
       "      'parameter': {}}],\n",
       "    'total_non_NaN_ratio': 90}},\n",
       "  'integration_param': {'integration_frequency': 600.0,\n",
       "   'param': {},\n",
       "   'method': 'meta',\n",
       "   'integration_duration': 'common'},\n",
       "  'clean_level': 4}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec3dafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== OK ========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save meta\n",
    "from Clust.clust.ML.tool import meta\n",
    "meta_file_name = \"meta.json\"\n",
    "#ml_meta.save_model_meta_into_mongodb(mongodb_client, param, 'model','meta')\n",
    "meta.save_model_meta_into_local(meta_file_name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2f744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
