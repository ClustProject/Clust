{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0e3d70",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5d01d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as iC\n",
    "from Clust.clust.ingestion.mongo import mongo_client\n",
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "from Clust.clust.ML.common import ML_api\n",
    "influxdb_client = iC.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongodb_client = mongo_client.MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472041e",
   "metadata": {},
   "source": [
    "# 1. set param from Front End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3a7b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "param1 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainy',\n",
    "        \"feature_list\":[\"value\"]\n",
    "    },\n",
    "    'data_y_flag' : 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'split_mode' : 'window_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'data_clean_option' : \"false\"\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# forecasting\n",
    "param2 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Temperature', 'out_temp','sin_hour']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainy',\n",
    "        \"feature_list\":['Temperature']\n",
    "    },\n",
    "    'data_y_flag' : 'false',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"false\",\n",
    "        'split_mode' : 'step_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        'past_step':4, #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'future_step':2\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# classification\n",
    "param3 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainX',\n",
    "        \"feature_list\":['col_0', 'col_1','col_2','col_3','col_4','col_5','col_6','col_7','col_8']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainy',\n",
    "        \"feature_list\":['value']\n",
    "    },\n",
    "    'data_y_flag' : 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"false\",\n",
    "        'split_mode' : 'window_split' # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "    },\n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'classification',\n",
    "        'model_method' : 'LSTM_cf',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\",\"num_classes\":6, 'rnn_type':'lstm'}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79772cfb",
   "metadata": {},
   "source": [
    "# 2. Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3436645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Backend Prameter Setting\n",
    "from Clust.clust.ML.common import ML_api\n",
    "\n",
    "# parameter tunning\n",
    "param = param3\n",
    "param = ML_api.convert_param_for_backend(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7fbfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. train data meta check\n",
    "train_data_info = ML_api.get_train_data_meta (mongodb_client, param['ingestion_param_X'])\n",
    "param['train_data_info'] = train_data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cc8d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket_name': 'integration', 'ms_name': 'classification_actionPattern_cleanLevel0_trainX', 'feature_list': ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']}\n",
      "['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "Make New scaler File\n",
      "./scaler/classification_actionPattern_cleanLevel0_trainX/minmax/2b219d77d5b069971addb3d7c728ec0d/scaler.pkl\n",
      "['value']\n",
      "Make New scaler File\n",
      "window_size: 128 nan_limit_num: 64\n",
      "=================================\n",
      "752844\n",
      "5882\n",
      "5881\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5881 is out of bounds for axis 0 with size 5881",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Data Preparation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_X_array, train_y_array, val_X_array, val_y_array \u001b[38;5;241m=\u001b[39m \u001b[43mML_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mML_data_preparation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfluxdb_client\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/ML/common/ML_api.py:147\u001b[0m, in \u001b[0;36mML_data_preparation\u001b[0;34m(param, influxdb_client)\u001b[0m\n\u001b[1;32m    141\u001b[0m train_X, val_X, train_y, val_y, param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform_param\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m ML_pipeline\u001b[38;5;241m.\u001b[39msplit_data_by_mode(dataX_scaled, \n\u001b[1;32m    142\u001b[0m                                                                                          datay_scaled, \n\u001b[1;32m    143\u001b[0m                                                                                          split_ratio, \n\u001b[1;32m    144\u001b[0m                                                                                          param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform_param\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# 5. Transform array style\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m train_X_array, train_y_array \u001b[38;5;241m=\u001b[39m \u001b[43mML_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_data_by_split_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransform_param\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                                                                        \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m val_X_array, val_y_array \u001b[38;5;241m=\u001b[39m ML_pipeline\u001b[38;5;241m.\u001b[39mtransform_data_by_split_mode(param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform_param\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    151\u001b[0m                                                                     val_X, \n\u001b[1;32m    152\u001b[0m                                                                     val_y)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_X_array, train_y_array, val_X_array, val_y_array\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/ML/common/ML_pipeline.py:158\u001b[0m, in \u001b[0;36mtransform_data_by_split_mode\u001b[0;34m(transformParameter, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformParameter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_split\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClust\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclust\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DFToNPArray\n\u001b[0;32m--> 158\u001b[0m     X_array, y_array\u001b[38;5;241m=\u001b[39m \u001b[43mDFToNPArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrans_DF_to_NP_by_windowNum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformParameter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m transformParameter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_split\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     X_array, y_array \u001b[38;5;241m=\u001b[39m ML\u001b[38;5;241m.\u001b[39mtrans_by_step_info(X, y, transformParameter)\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/transformation/type/DFToNPArray.py:31\u001b[0m, in \u001b[0;36mtrans_DF_to_NP_by_windowNum\u001b[0;34m(X, y, transformParameter)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, splitted \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitted_df):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#list_cols = [splitted[col_name].tolist() for col_name in splitted.columns]\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     np_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(splitted\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m---> 31\u001b[0m     np_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43my_array_old\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     32\u001b[0m     np_X , np_y \u001b[38;5;241m=\u001b[39m ML\u001b[38;5;241m.\u001b[39mcheck_nan_status(np_X, np_y, nan_limit_num)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# step2\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5881 is out of bounds for axis 0 with size 5881"
     ]
    }
   ],
   "source": [
    "# 3. Data Preparation\n",
    "train_X_array, train_y_array, val_X_array, val_y_array = ML_api.ML_data_preparation(param, influxdb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6624e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Training\n",
    "param = ML_api.ML_training(train_X_array,  train_y_array, val_X_array, val_y_array, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fdb1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Clust.clust.ingestion.mongo.mongo_client.MongoClient at 0x7f0c6f0d8ee0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongodb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save meta\n",
    "ml_meta.save_model_meta_data(mongodb_client, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd18151",
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d63758",
   "metadata": {},
   "outputs": [],
   "source": [
    "param['model_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46796c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
