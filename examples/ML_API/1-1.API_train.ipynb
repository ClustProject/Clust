{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0e3d70",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d01d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available.\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as iC\n",
    "from Clust.clust.ingestion.mongo import mongo_client\n",
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "from Clust.clust.ML.common import ML_api\n",
    "influxdb_client = iC.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongodb_client = mongo_client.MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472041e",
   "metadata": {},
   "source": [
    "# 1. set param from Front End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a7b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "param1 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'regression_energy_cleanLevel4_trainy',\n",
    "        \"feature_list\":[\"value\"]\n",
    "    },\n",
    "    'data_y_flag' : 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'split_mode' : 'window_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'data_clean_option' : \"false\"\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# forecasting\n",
    "param2 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX',\n",
    "        \"feature_list\":['Temperature', 'out_temp','sin_hour']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainy',\n",
    "        \"feature_list\":['Temperature']\n",
    "    },\n",
    "    'data_y_flag' : 'false',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"false\",\n",
    "        'split_mode' : 'window_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "        'past_step':4, #step_split일 경우만 past_step과 future_step이 존재\n",
    "        'future_step':2\n",
    "    },\n",
    "    \n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# classification\n",
    "param3 = {\n",
    "    \"ingestion_param_X\" :{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainX',\n",
    "        \"feature_list\":['Temperature', 'out_temp','sin_hour']\n",
    "    },\n",
    "    \"ingestion_param_y\":{\n",
    "        \"bucket_name\": 'integration',\n",
    "        \"ms_name\" : 'classification_actionPattern_cleanLevel0_trainy',\n",
    "        \"feature_list\":['Temperature']\n",
    "    },\n",
    "    'data_y_flag' : 'false',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag':'scale', #scale_param,\n",
    "        'scale_method' :'minmax',\n",
    "        'scaler_path' :'./scaler/'\n",
    "    },\n",
    "    \"transform_param\":{\n",
    "        'data_clean_option' : \"true\",\n",
    "        'split_mode' : 'window_split' # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "    },\n",
    "    \"model_info\" :{\n",
    "        'model_purpose' : 'regression',\n",
    "        'model_method' : 'LSTM_rg',\n",
    "        'model_name' : \"None\",\n",
    "        'model_tags' : 'tagstest',\n",
    "        'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "        'model_parameter' : {\"hidden_size\":64,\"num_layers\":2,\"output_dim\":1,\"dropout\":0.1,\"bidirectional\":\"True\",\"num_classes\":6}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79772cfb",
   "metadata": {},
   "source": [
    "# 2. Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3436645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Backend Prameter Setting\n",
    "from Clust.clust.ML.common import ML_api\n",
    "\n",
    "# parameter tunning\n",
    "param = param1\n",
    "param = ML_api.convert_param_for_backend(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fbfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. train data meta check\n",
    "train_data_info = ML_api.get_train_data_meta (mongodb_client, param['ingestion_param_X'])\n",
    "param['train_data_info'] = train_data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc8d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucket_name': 'integration', 'ms_name': 'regression_energy_cleanLevel4_trainX', 'feature_list': ['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']}\n",
      "['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
      "Make New scaler File\n",
      "./scaler/regression_energy_cleanLevel4_trainX/minmax/900878d7bba6f2a4017d1c3399909ea7/scaler.pkl\n",
      "['value']\n",
      "Make New scaler File\n",
      "window_size: 144 nan_limit_num: 72\n",
      "(10944, 24) (72, 144, 24)\n",
      "(76, 1) (72, 1)\n",
      "window_size: 144 nan_limit_num: 72\n",
      "(2736, 24) (19, 144, 24)\n",
      "(19, 1) (19, 1)\n"
     ]
    }
   ],
   "source": [
    "# 3. Data Preparation\n",
    "train_X_array, train_y_array, val_X_array, val_y_array = ML_api.ML_data_preparation(param, influxdb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6624e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 2, 'output_dim': 1, 'dropout': 0.1, 'bidirectional': True}\n",
      "./Models/LSTM_rg/regression_energy_cleanLevel4_trainX_regression_LSTM_rg_/regression_energy_cleanLevel4_trainX/model.pkl\n",
      "Start training model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4.Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[43mML_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mML_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/common/ML_api.py:182\u001b[0m, in \u001b[0;36mML_training\u001b[0;34m(train_X_array, train_y_array, val_X_array, val_y_array, param)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# input 순서 일관되도록 펑션 수정\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_purpose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m:    \n\u001b[0;32m--> 182\u001b[0m     \u001b[43mML_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLUST_regresstion_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_y_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_info\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_purpose\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    189\u001b[0m     ML_pipeline\u001b[38;5;241m.\u001b[39mCLUST_classification_train(train_X_array, \n\u001b[1;32m    190\u001b[0m                                            train_y_array, \n\u001b[1;32m    191\u001b[0m                                            val_X_array, \n\u001b[1;32m    192\u001b[0m                                            val_y_array, \n\u001b[1;32m    193\u001b[0m                                            param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_info\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/common/ML_pipeline.py:200\u001b[0m, in \u001b[0;36mCLUST_regresstion_train\u001b[0;34m(train_X_array, train_y_array, val_X_array, val_y_array, model_info)\u001b[0m\n\u001b[1;32m    198\u001b[0m rml\u001b[38;5;241m.\u001b[39mset_model(model_method, model_parameter)\n\u001b[1;32m    199\u001b[0m rml\u001b[38;5;241m.\u001b[39mset_data(train_X_array, train_y_array, val_X_array, val_y_array)\n\u001b[0;32m--> 200\u001b[0m \u001b[43mrml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m rml\u001b[38;5;241m.\u001b[39msave_best_model(model_file_path)\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/train.py:89\u001b[0m, in \u001b[0;36mRegressionTrain.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/clust_models/rnn_clust.py:69\u001b[0m, in \u001b[0;36mRNNClust.train\u001b[0;34m(self, train_params, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     67\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mview([batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_features])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39mview([batch_size, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 69\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     71\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(batch_losses)\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/clust_models/rnn_clust.py:291\u001b[0m, in \u001b[0;36mRNNClust._train_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Makes predictions\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Computes loss\u001b[39;00m\n\u001b[1;32m    294\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y, yhat)\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/Clust/clust/ML/regression/models/rnn.py:66\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_directions \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# We need to detach as we are doing truncated backpropagation through time (BPTT)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Forward propagation by passing in the input, hidden state, and cell state into the model\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     68\u001b[0m     out, h0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x, h0\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/sejong/lib/python3.8/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu"
     ]
    }
   ],
   "source": [
    "# 4.Training\n",
    "param = ML_api.ML_training(train_X_array,  train_y_array, val_X_array, val_y_array, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save meta\n",
    "ml_meta.save_model_meta_data(mongodb_client, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd18151",
   "metadata": {},
   "outputs": [],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d63758",
   "metadata": {},
   "outputs": [],
   "source": [
    "param['model_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46796c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sejong",
   "language": "python",
   "name": "sejong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
