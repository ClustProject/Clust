{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/.clust/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")\n",
    "\n",
    "from Clust.clust.ML.common import ML_pipeline, tool\n",
    "app_name= \"Hs2SwineFarmWithWeatherTime\" # \"Hs2SwineFarmWithWeatherTime\", \"energy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f5edd",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc6a75",
   "metadata": {},
   "source": [
    "### 1-1. Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64028082",
   "metadata": {},
   "outputs": [],
   "source": [
    "if app_name == \"energy\":\n",
    "    model_purpose = 'regression'\n",
    "    feature_X_list = ['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    feature_y_list = ['value']\n",
    "    split_mode =\"windows_split\"\n",
    "    data_y_flag = True # 이미 만들어진 Y 데이터를 활용함\n",
    "    \n",
    "elif app_name == \"Hs2SwineFarmWithWeatherTime\":\n",
    "    model_purpose = 'forecasting' \n",
    "    feature_X_list = ['Temperature', 'out_temp','sin_hour']\n",
    "    feature_y_list = ['Temperature']\n",
    "    split_mode = 'step_split'\n",
    "    data_y_flag = False # Y데이터는 없음, X 에서 Y 데이터를 도출함\n",
    "    \n",
    "step = 'train'\n",
    "bucket_name = 'integration' \n",
    "data_clean_level = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5aaf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX', 'forecasting_air_유치원1_cleanLevel0_testX', 'forecasting_air_유치원1_cleanLevel0_trainX', 'forecasting_air_유치원1_cleanLevel4_testX', 'forecasting_air_유치원1_cleanLevel4_trainX', 'forecasting_gunwiStrawberryWeather_cleanLevel0_testX', 'forecasting_gunwiStrawberryWeather_cleanLevel0_trainX', 'forecasting_gunwiStrawberryWeather_cleanLevel4_testX', 'forecasting_gunwiStrawberryWeather_cleanLevel4_trainX', 'forecasting_strawberryOpen_cleanLevel0_testX', 'forecasting_strawberryOpen_cleanLevel0_trainX', 'forecasting_strawberryOpen_cleanLevel4_testX', 'forecasting_strawberryOpen_cleanLevel4_trainX', 'regression_energy_cleanLevel0_testX', 'regression_energy_cleanLevel0_testy', 'regression_energy_cleanLevel0_trainX', 'regression_energy_cleanLevel0_trainy', 'regression_energy_cleanLevel4_testX', 'regression_energy_cleanLevel4_testy', 'regression_energy_cleanLevel4_trainX', 'regression_energy_cleanLevel4_trainy']\n",
      "['forecasting_strawberryOpen_cleanLevel0_testX', 'forecasting_strawberryOpen_cleanLevel4_trainX', 'regression_energy_cleanLevel0_testy', 'regression_energy_cleanLevel0_trainX', 'forecasting_strawberryOpen_cleanLevel4_testX', 'regression_energy_cleanLevel4_trainX', 'regression_energy_cleanLevel0_testX', 'regression_energy_cleanLevel4_trainy', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_testX', 'regression_energy_cleanLevel4_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_testX', 'regression_energy_cleanLevel0_trainy', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX', 'forecasting_strawberryOpen_cleanLevel0_trainX', 'regression_energy_cleanLevel4_testy', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX']\n"
     ]
    }
   ],
   "source": [
    "all_integrated_ms_list = db_client.measurement_list(bucket_name)\n",
    "print(all_integrated_ms_list)\n",
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "print(collection_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3029057",
   "metadata": {},
   "source": [
    "### 1-2. Data Ingestion\n",
    "#### 1-2-1. Select data name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf9f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = model_purpose + '_' + app_name  \n",
    "data_name_X = dataset_name + '_cleanLevel' + str(data_clean_level)+'_'+step+'X'\n",
    "data_name_y = dataset_name+'_cleanLevel' + str(data_clean_level)+'_'+ step+'y'\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'data_name':data_name_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8608cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102bcf3",
   "metadata": {},
   "source": [
    "#### 1-2-2. X-y Data Ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c01141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "ingestion_method = 'ms_all'\n",
    "ingestion_param_X = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_X,\n",
    "    'feature_list' : feature_X_list                              \n",
    "}\n",
    "ingestion_param_y = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_y,\n",
    "    'feature_list' : feature_y_list                              \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcec8e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_X, data_y = ML_pipeline.Xy_data_preparation(ingestion_param_X, data_y_flag, ingestion_param_y, ingestion_method, db_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e818e",
   "metadata": {},
   "source": [
    "### 1-2-2. Random Nan Insert (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9d5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0fe682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/common/tool.py:17: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.loc[df.sample(frac=nan_ratio). index, col] = pd.np.nan\n",
      "/Users/kim-youngkee/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/common/tool.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[df.sample(frac=nan_ratio). index, col] = pd.np.nan\n"
     ]
    }
   ],
   "source": [
    "data_X = tool.random_nan_df(data_X, nan_ratio)\n",
    "data_y = tool.random_nan_df(data_y, nan_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51d355",
   "metadata": {},
   "source": [
    "#### 1-2-3. Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd78ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_param='scale'\n",
    "scale_method='minmax'\n",
    "scaler_path = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768ca14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temperature', 'out_temp', 'sin_hour']\n",
      "Make New scaler File\n",
      "['Temperature']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled, X_scalerFilePath, datay_scaled, y_scalerFilePath= ML_pipeline.Xy_data_scaling_train(data_name_X, data_X, data_name_y, data_y, scaler_path, scaler_param, scale_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54c637",
   "metadata": {},
   "source": [
    "## 2. Cleaning and split\n",
    "### 2.1 pipeline - clean low quality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22975a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = True\n",
    "nan_process_info = {'type':'num', 'ConsecutiveNanLimit':10000, 'totalNaNLimit':100000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28752269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ---> 3\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled = ML_pipeline.clean_low_quality_column(model_clean, nan_process_info, dataX_scaled)\n",
    "feature_X_list= list(dataX_scaled.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ae2c2",
   "metadata": {},
   "source": [
    "### 2.2 Train/Val Split pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2463833",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c884e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 데이터 나뉘는 부분 추가로 작성된 것 지수님에게 물어봐야 함\n",
    "day_window_size = tool.get_default_day_window_size(dataX_scaled)\n",
    "train_x, val_x, train_y, val_y = ML_pipeline.split_data_by_mode(split_mode, split_ratio, dataX_scaled, datay_scaled, day_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0495b",
   "metadata": {},
   "source": [
    "### 2.3 Data Transformation & Clean2 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2f206d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nan_limit_ratio = 0.5\n",
    "if split_mode =='window_split':\n",
    "    transformParameter = {\n",
    "            'past_step':day_window_size,\n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }\n",
    "else:\n",
    "    transformParameter = {\n",
    "            'future_step': 2,\n",
    "            'past_step': 12, \n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77429916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan_limit_num:  6\n",
      "Original num: 8516 Final num: 8366 NaN num: 150\n",
      "nan_limit_num:  6\n",
      "Original num: 2129 Final num: 2115 NaN num: 14\n"
     ]
    }
   ],
   "source": [
    "train_X_array, train_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, train_x, train_y)\n",
    "val_X_array, val_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b9d01",
   "metadata": {},
   "source": [
    "### 2.4 Set Model and train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3adac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "seq_len, input_size = train_X_array.shape[1], train_X_array.shape[2]\n",
    "model_method = 'GRU_rg' # Set model methods i.e., 'LSTM_rg', 'GRU_rg', 'CNN_1D_rg', 'LSTM_FCNs_rg', 'FC_rg' \n",
    "if model_method == 'LSTM_rg' or model_method == 'GRU_rg':\n",
    "    modelParameter = {\n",
    "        'rnn_type': 'lstm',\n",
    "        'input_size': input_size, \n",
    "        'hidden_size': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_dim': 1, \n",
    "        'dropout': 0.1, \n",
    "        'bidirectional': True\n",
    "    }\n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'output_channels': 64,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 0, \n",
    "    'dropout': 0.1\n",
    "    }\n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_layers': 2,\n",
    "    'lstm_dropout': 0.4,\n",
    "    'fc_dropout': 0.1\n",
    "    }\n",
    "# FC model parameters\n",
    "elif model_method == 'FC_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'dropout': 0.1,\n",
    "    'bias': True\n",
    "    }\n",
    "    \n",
    "train_parameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 5, \n",
    "    'batch_size': 16\n",
    "}\n",
    "model_name = None\n",
    "model_file_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798b4aa",
   "metadata": {},
   "source": [
    "### 2.5 Set Model name and path pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19dee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Models/GRU_rg/Hs2SwineFarmWithWeatherTime_GRU_rg_True/forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX/e0c69926ea63923d2dbafa434a27060e/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# model_name and file path check and create\n",
    "model_name = tool.get_default_model_name(model_name, app_name, model_method, model_clean)\n",
    "model_file_path = tool.get_default_model_path(model_name, data_name_X, model_method, train_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44195f",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f51aab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "[1/20] Training loss: 0.0560\t Validation loss: 0.0019\n",
      "[2/20] Training loss: 0.0012\t Validation loss: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ML_pipeline\u001b[39m.\u001b[39;49mCLUST_regresstion_train(train_parameter, model_method, modelParameter, model_file_path, train_X_array, train_y_array, val_X_array, val_y_array)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/common/ML_pipeline.py:166\u001b[0m, in \u001b[0;36mCLUST_regresstion_train\u001b[0;34m(train_parameter, model_method, modelParameter, model_file_path, train_X_array, train_y_array, val_X_array, val_y_array)\u001b[0m\n\u001b[1;32m    164\u001b[0m rml\u001b[39m.\u001b[39mset_model(model_method, modelParameter)\n\u001b[1;32m    165\u001b[0m rml\u001b[39m.\u001b[39mset_data(train_X_array, train_y_array, val_X_array, val_y_array)\n\u001b[0;32m--> 166\u001b[0m rml\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    167\u001b[0m rml\u001b[39m.\u001b[39msave_best_model(model_file_path)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/regression_YK/train.py:89\u001b[0m, in \u001b[0;36mRegressionTrain.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart training model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_loader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalid_loader)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/regression_YK/clust_models/rnn_clust.py:69\u001b[0m, in \u001b[0;36mRNNClust.train\u001b[0;34m(self, train_params, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     67\u001b[0m     x_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39mview([batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_features])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m     y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mview([batch_size, \u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 69\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step(x_batch, y_batch)\n\u001b[1;32m     70\u001b[0m     batch_losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     71\u001b[0m training_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(batch_losses)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ML_pipeline.CLUST_regresstion_train(train_parameter, model_method, modelParameter, model_file_path, train_X_array, train_y_array, val_X_array, val_y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36ad30",
   "metadata": {},
   "source": [
    "## 4. save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "modelTags =[\"model_tag_example\"]\n",
    "trainDataType = \"timeseries\"\n",
    "\n",
    "modelInfoMeta ={\n",
    "    \"trainDataInfo\":data_meta,\n",
    "    \"modelName\":model_name,\n",
    "    \"dataSplitMode\":split_mode,\n",
    "    \"featureXList\":feature_X_list,\n",
    "    \"featureyList\":feature_y_list,\n",
    "    \"data_y_flag\": data_y_flag,\n",
    "    \"trainDataType\":trainDataType,\n",
    "    \"modelPurpose\":model_purpose,\n",
    "    \"modelMethod\":model_method,\n",
    "    \"modelTags\":modelTags,\n",
    "    \"modelCleanLevel\":model_clean,\n",
    "    \"trainParameter\": train_parameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \"transformParameter\":transformParameter,\n",
    "    \"scalerParam\":scaler_param,\n",
    "    \"trainDataName\":[data_name_X, data_name_y], \n",
    "\n",
    "    \"files\":{\n",
    "        \"modelFile\":{\n",
    "            \"fileName\":\"model.pth\",\n",
    "            \"filePath\":model_file_path\n",
    "        },\n",
    "        \"XScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":X_scalerFilePath       \n",
    "        },\n",
    "        \"yScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":y_scalerFilePath      \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "modelInfoMeta = ml_meta.save_model_meta_data(mongo_client, modelInfoMeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5ded7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
