{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/.clust/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd829837",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fc87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New json file is created from data.json file\n",
      "['RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7', 'RH_8', 'RH_9', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'Press_mm_hg', 'RH_out', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
      "Make New scaler File\n",
      "New json file is created from data.json file\n",
      "['value']\n",
      "Make New scaler File\n",
      "window_size: 144 nan_limit_num: 72\n",
      "(10944, 24) (76, 144, 24)\n",
      "(76, 1) (76, 1)\n",
      "window_size: 144 nan_limit_num: 72\n",
      "(2736, 24) (19, 144, 24)\n",
      "(19, 1) (19, 1)\n"
     ]
    }
   ],
   "source": [
    "### 1. Read data from .CSV\n",
    "dataFolderName = \"data_integrated_result\"\n",
    "dataFolderPath = os.path.join(os.getcwd(), dataFolderName)\n",
    "\n",
    "dataName_X = \"IntegrationTrainX\"\n",
    "dataName_y = \"IntegrationTrainy\"\n",
    "\n",
    "fileName_X = os.path.join(dataFolderPath, dataName_X +'.csv')\n",
    "fileName_y = os.path.join(dataFolderPath, dataName_y +'.csv')\n",
    "\n",
    "data_X = pd.read_csv(fileName_X, index_col='datetime', infer_datetime_format=True, parse_dates=['datetime'])\n",
    "data_y = pd.read_csv(fileName_y, index_col='datetime', infer_datetime_format=True, parse_dates=['datetime'])\n",
    "\n",
    "### 2. Preprocessing (e.g., cleaning, scaling, ...)\n",
    "from Clust.clust.ML.common import ML_pipeline\n",
    "\n",
    "scaler_param='scale'\n",
    "scale_method='minmax'\n",
    "scaler_path = './scaler/'\n",
    "\n",
    "# X Data Scaling\n",
    "from Clust.clust.ML.tool import scaler\n",
    "scalerRootPath_X = os.path.join(scaler_path, dataName_X)\n",
    "dataX_scaled, X_scalerFilePath = scaler.get_data_scaler('scale', scalerRootPath_X, data_X, scale_method)   \n",
    "    \n",
    "# y Data Scaling\n",
    "scalerRootPath_y = os.path.join(scaler_path, dataName_y)\n",
    "datay_scaled, y_scalerFilePath = scaler.get_data_scaler('scale', scalerRootPath_y, data_y, scale_method)\n",
    "\n",
    "### 3. Split train/val data\n",
    "from Clust.clust.ML.common import tool\n",
    "from Clust.clust.transformation.purpose import machineLearning as ML\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_mode = 'windows_split'\n",
    "day_window_size = tool.get_default_day_window_size(dataX_scaled)\n",
    "\n",
    "train_X, val_X = ML.split_data_by_ratio(dataX_scaled, split_ratio, split_mode, day_window_size)\n",
    "train_y, val_y = ML.split_data_by_ratio(datay_scaled, split_ratio, None, None)\n",
    "\n",
    "### 4. Transfrom train/val data\n",
    "max_nan_limit_ratio = 0.5\n",
    "transformParameter = {\n",
    "    'past_step':day_window_size,\n",
    "    'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "}\n",
    "\n",
    "train_X_array, train_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, train_X, train_y)\n",
    "val_X_array, val_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, val_X, val_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff6b9d01",
   "metadata": {},
   "source": [
    "### Set Model and train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "seq_len, input_size = train_X_array.shape[1], train_X_array.shape[2]\n",
    "model_method = 'GRU_rg' # Set model methods i.e., 'LSTM_rg', 'GRU_rg', 'CNN_1D_rg', 'LSTM_FCNs_rg', 'FC_rg' \n",
    "if model_method == 'LSTM_rg' or model_method == 'GRU_rg':\n",
    "    modelParameter = {\n",
    "        'rnn_type': 'lstm',\n",
    "        'input_size': input_size, \n",
    "        'hidden_size': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_dim': 1, \n",
    "        'dropout': 0.1, \n",
    "        'bidirectional': True\n",
    "    }\n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'output_channels': 64,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 0, \n",
    "    'dropout': 0.1\n",
    "    }\n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_layers': 2,\n",
    "    'lstm_dropout': 0.4,\n",
    "    'fc_dropout': 0.1\n",
    "    }\n",
    "# FC model parameters\n",
    "elif model_method == 'FC_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'dropout': 0.1,\n",
    "    'bias': True\n",
    "    }\n",
    "    \n",
    "train_parameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 10, \n",
    "    'batch_size': 16\n",
    "}\n",
    "model_name = None\n",
    "model_file_path = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7d2ba80",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad125d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "[1/10] Training loss: 0.2012\t Validation loss: 0.1556\n",
      "[2/10] Training loss: 0.2028\t Validation loss: 0.1438\n",
      "[3/10] Training loss: 0.1854\t Validation loss: 0.1323\n",
      "[4/10] Training loss: 0.1698\t Validation loss: 0.1210\n",
      "[5/10] Training loss: 0.1597\t Validation loss: 0.1100\n",
      "[6/10] Training loss: 0.1489\t Validation loss: 0.0992\n",
      "[7/10] Training loss: 0.1277\t Validation loss: 0.0887\n",
      "[8/10] Training loss: 0.1307\t Validation loss: 0.0782\n",
      "[9/10] Training loss: 0.1124\t Validation loss: 0.0683\n",
      "[10/10] Training loss: 0.1008\t Validation loss: 0.0587\n",
      "\n",
      "Training complete in 0m 12s\n"
     ]
    }
   ],
   "source": [
    "model_file_path = \"./\"\n",
    "\n",
    "from Clust.clust.ML.regression_YK.train import RegressionTrain as RML\n",
    "\n",
    "rml = RML()\n",
    "rml.set_param(train_parameter)\n",
    "rml.set_model(model_method, modelParameter)\n",
    "rml.set_data(train_X_array, train_y_array, val_X_array, val_y_array)\n",
    "rml.train()\n",
    "#rml.save_best_model(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4a5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
