{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")\n",
    "\n",
    "from Clust.clust.ML.common import train_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f5edd",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc6a75",
   "metadata": {},
   "source": [
    "### 1-1. Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64028082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classification_actionPattern_testX_cleanLevel0', 'classification_actionPattern_testy_cleanLevel0', 'classification_actionPattern_trainX_cleanLevel0', 'classification_actionPattern_trainy_cleanLevel0', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_test', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_train', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_test', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_train', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX', 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel0', 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel0_X', 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel4', 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel4_X', 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel0', 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel0_X', 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel4', 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel4_X', 'forecasting_air_유치원1_cleanLevel0_testX', 'forecasting_air_유치원1_cleanLevel0_trainX', 'forecasting_air_유치원1_cleanLevel4_testX', 'forecasting_air_유치원1_cleanLevel4_trainX', 'forecasting_air_유치원1_test_cleanLevel0', 'forecasting_air_유치원1_test_cleanLevel4', 'forecasting_air_유치원1_train_cleanLevel0', 'forecasting_air_유치원1_train_cleanLevel4', 'forecasting_gunwiStrawberryWeather_cleanLevel0_test', 'forecasting_gunwiStrawberryWeather_cleanLevel0_testX', 'forecasting_gunwiStrawberryWeather_cleanLevel0_train', 'forecasting_gunwiStrawberryWeather_cleanLevel0_trainX', 'forecasting_gunwiStrawberryWeather_cleanLevel4_test', 'forecasting_gunwiStrawberryWeather_cleanLevel4_testX', 'forecasting_gunwiStrawberryWeather_cleanLevel4_train', 'forecasting_gunwiStrawberryWeather_cleanLevel4_trainX', 'forecasting_gunwiStrawberryWeather_test_cleanLevel0', 'forecasting_gunwiStrawberryWeather_test_cleanLevel0_X', 'forecasting_gunwiStrawberryWeather_test_cleanLevel4', 'forecasting_gunwiStrawberryWeather_test_cleanLevel4_X', 'forecasting_gunwiStrawberryWeather_train_cleanLevel0', 'forecasting_gunwiStrawberryWeather_train_cleanLevel0_X', 'forecasting_gunwiStrawberryWeather_train_cleanLevel4', 'forecasting_gunwiStrawberryWeather_train_cleanLevel4_X', 'forecasting_strawberryOpen_cleanLevel0_test', 'forecasting_strawberryOpen_cleanLevel0_testX', 'forecasting_strawberryOpen_cleanLevel0_train', 'forecasting_strawberryOpen_cleanLevel0_trainX', 'forecasting_strawberryOpen_cleanLevel4_test', 'forecasting_strawberryOpen_cleanLevel4_testX', 'forecasting_strawberryOpen_cleanLevel4_train', 'forecasting_strawberryOpen_cleanLevel4_trainX', 'forecasting_strawberryOpen_test_cleanLevel0', 'forecasting_strawberryOpen_test_cleanLevel0_X', 'forecasting_strawberryOpen_test_cleanLevel4', 'forecasting_strawberryOpen_train_cleanLevel0', 'forecasting_strawberryOpen_train_cleanLevel0_X', 'forecasting_strawberryOpen_train_cleanLevel4', 'regression_energy_cleanLevel0_testX', 'regression_energy_cleanLevel0_testy', 'regression_energy_cleanLevel0_trainX', 'regression_energy_cleanLevel0_trainy', 'regression_energy_cleanLevel4_testX', 'regression_energy_cleanLevel4_testy', 'regression_energy_cleanLevel4_trainX', 'regression_energy_cleanLevel4_trainy', 'regression_energy_testX_cleanLevel0', 'regression_energy_testX_cleanLevel4', 'regression_energy_testy_cleanLevel0', 'regression_energy_testy_cleanLevel4', 'regression_energy_trainX_cleanLevel0', 'regression_energy_trainX_cleanLevel4', 'regression_energy_trainy_cleanLevel0', 'regression_energy_trainy_cleanLevel4']\n",
      "['forecasting_strawberryOpen', 'forecasting_air_유치원1', 'regression_energy', 'forecasting_Hs2SwineFarmWithWeatherTime', 'forecasting_gunwiStrawberryWeather', 'classification_actionPattern']\n"
     ]
    }
   ],
   "source": [
    "app_name= \"Hs2SwineFarmWithWeatherTime\" # \"Hs2SwineFarmWithWeatherTime\", \"energy\"\n",
    "\n",
    "if app_name == \"energy\":\n",
    "    model_purpose = 'regression'\n",
    "    feature_X_list = ['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    feature_y_list = ['value']\n",
    "    split_mode =\"window_split\"\n",
    "    data_y_flag = True # 이미 만들어진 Y 데이터를 활용함\n",
    "    \n",
    "elif app_name == \"Hs2SwineFarmWithWeatherTime\":\n",
    "    model_purpose = 'forecasting' \n",
    "    feature_X_list = ['Temperature', 'out_temp','sin_hour']\n",
    "    feature_y_list = ['Temperature']\n",
    "    split_mode = 'step_split'\n",
    "    data_y_flag = False # Y데이터는 없음, X 에서 Y 데이터를 도출함\n",
    "    \n",
    "step = 'train'\n",
    "bucket_name = 'integration' \n",
    "scaler_path = './scaler/'\n",
    "\n",
    "data_clean_level = 0 \n",
    "dataset_name = model_purpose + '_' + app_name  \n",
    "data_name_X = dataset_name + '_cleanLevel' + str(data_clean_level)+'_'+step+'X'\n",
    "data_name_y = dataset_name+'_cleanLevel' + str(data_clean_level)+'_'+ step+'y'\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'data_name':data_name_X})[0]\n",
    "all_integrated_ms_list = db_client.measurement_list(bucket_name)\n",
    "print(all_integrated_ms_list)\n",
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "print(collection_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3029057",
   "metadata": {},
   "source": [
    "### 1-2. Data Ingestion\n",
    "#### 1-2-1. X-y Data Ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6022ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "ingestion_method = 'ms_all'\n",
    "ingestion_param_X = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_X,\n",
    "    'feature_list' : feature_X_list                              \n",
    "}\n",
    "ingestion_param_y = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_y,\n",
    "    'feature_list' : feature_y_list                              \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcec8e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_X, data_y = train_pipeline.get_Xy_data_in_Clust(ingestion_param_X, data_y_flag, ingestion_param_y, ingestion_method, db_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e07521",
   "metadata": {},
   "source": [
    "### 1-2-2. Random Nan Insert (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f2470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0fe682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../../Clust/clust/ML/common/train_pipeline.py:31: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df.loc[df.sample(frac=nan_ratio). index, col] = pd.np.nan\n",
      "/home/jwmoon/.conda/envs/sejong/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/jwmoon/.conda/envs/sejong/lib/python3.8/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "data_X = train_pipeline.random_nan_df(data_X, nan_ratio)\n",
    "data_y = train_pipeline.random_nan_df(data_y, nan_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51d355",
   "metadata": {},
   "source": [
    "#### 1-2-3. Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4eb9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_param='scale'\n",
    "scale_method='minmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768ca14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temperature', 'out_temp', 'sin_hour']\n",
      "Make New scaler File\n",
      "['Temperature']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled, X_scalerFilePath, datay_scaled, y_scalerFilePath= train_pipeline.get_scaled_data_in_Clust(data_name_X, data_X, data_name_y, data_y, scaler_path, scaler_param, scale_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54c637",
   "metadata": {},
   "source": [
    "## 2. Cleaning and split\n",
    "### 2.1 Cleaning1 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782fc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = True\n",
    "nan_process_info = {'type':'num', 'ConsecutiveNanLimit':10000, 'totalNaNLimit':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28752269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ---> 3\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled = train_pipeline.get_clean_model_data_1(model_clean, nan_process_info, dataX_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ae2c2",
   "metadata": {},
   "source": [
    "### 2.2 Train/Val Split pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a8fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c884e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 데이터 나뉘는 부분 추가로 작성된 것 지수님에게 물어봐야 함\n",
    "day_window_size = train_pipeline.get_default_day_window_size(dataX_scaled)\n",
    "train_x, val_x, train_y, val_y = train_pipeline.get_split_data_in_CLUST(split_mode, split_ratio, dataX_scaled, datay_scaled, day_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0495b",
   "metadata": {},
   "source": [
    "### 2.3 Data Transformation & Clean2 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0359a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nan_limit_ratio = 0.5\n",
    "if split_mode =='window_split':\n",
    "    transformParameter = {\n",
    "            'past_step':day_window_size,\n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }\n",
    "else:\n",
    "    transformParameter = {\n",
    "            'future_step': 2,\n",
    "            'past_step': 24, \n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77429916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan_limit_num:  12\n",
      "Original num: 8516 Final num: 8310 NaN num: 206\n",
      "nan_limit_num:  12\n",
      "Original num: 2129 Final num: 2092 NaN num: 37\n"
     ]
    }
   ],
   "source": [
    "train_X_array, train_y_array = train_pipeline.get_transfomed_data(split_mode, transformParameter, train_x, train_y)\n",
    "val_X_array, val_y_array = train_pipeline.get_transfomed_data(split_mode, transformParameter, val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b9d01",
   "metadata": {},
   "source": [
    "### 2.4 Set Model and train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3adac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "seq_len, input_size = train_X_array.shape[1], train_X_array.shape[2]\n",
    "model_method = 'GRU_rg' # Set model methods i.e., 'LSTM_rg', 'GRU_rg', 'CNN_1D_rg', 'LSTM_FCNs_rg', 'FC_rg' \n",
    "if model_method == 'LSTM_rg' or model_method == 'GRU_rg':\n",
    "    modelParameter = {\n",
    "        'rnn_type': 'lstm',\n",
    "        'input_size': input_size, \n",
    "        'hidden_size': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_dim': 1, \n",
    "        'dropout': 0.1, \n",
    "        'bidirectional': True\n",
    "    }\n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'output_channels': 64,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 0, \n",
    "    'dropout': 0.1\n",
    "    }\n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_layers': 2,\n",
    "    'lstm_dropout': 0.4,\n",
    "    'fc_dropout': 0.1\n",
    "    }\n",
    "# FC model parameters\n",
    "elif model_method == 'FC_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'dropout': 0.1,\n",
    "    'bias': True\n",
    "    }\n",
    "    \n",
    "train_parameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 10, \n",
    "    'batch_size': 16\n",
    "}\n",
    "model_name = None\n",
    "model_file_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db4a9f",
   "metadata": {},
   "source": [
    "### 2.5 Set Model name and path pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19dee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Models/GRU_rg/Hs2SwineFarmWithWeatherTime_GRU_rg_True/forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX/d531eec11664669cff1f6a3ad9639012/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# model_name and file path check and create\n",
    "model_name = train_pipeline.get_default_model_name(model_name, app_name, model_method, model_clean)\n",
    "model_file_path = train_pipeline.get_default_model_path(model_name, data_name_X, model_method, train_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44195f",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51aab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "[1/10] Training loss: 0.0541\t Validation loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "from Clust.clust.ML.regression_YK.train import RegressionTrain as RML\n",
    "\n",
    "rml = RML()\n",
    "rml.set_param(train_parameter)\n",
    "rml.set_model(model_method, modelParameter)\n",
    "rml.set_data(train_X_array, train_y_array, val_X_array, val_y_array, )\n",
    "rml.train()\n",
    "rml.save_best_model(model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36ad30",
   "metadata": {},
   "source": [
    "## 4. save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "modelTags =[\"model_tag_example\"]\n",
    "trainDataType = \"timeseries\"\n",
    "\n",
    "modelInfoMeta ={\n",
    "    \"trainDataInfo\":data_meta,\n",
    "    \"modelName\":model_name,\n",
    "    \"featureList\":feature_X_list,\n",
    "    \"target\": feature_y_list,\n",
    "    \"trainDataType\":trainDataType,\n",
    "    \"modelPurpose\":model_purpose,\n",
    "    \"modelMethod\":model_method,\n",
    "    \"modelTags\":modelTags,\n",
    "    \"modelCleanLevel\":model_clean,\n",
    "    \"trainParameter\": train_parameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \"transformParameter\":transformParameter,\n",
    "    \"scalerParam\":scaler_param,\n",
    "    \"trainDataName\":[data_name_X, data_name_y], \n",
    "\n",
    "    \"files\":{\n",
    "        \"modelFile\":{\n",
    "            \"fileName\":\"model.pth\",\n",
    "            \"filePath\":model_file_path\n",
    "        },\n",
    "        \"XScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":X_scalerFilePath       \n",
    "        },\n",
    "        \"yScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":y_scalerFilePath      \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "modelInfoMeta = ml_meta.save_model_meta_data(mongo_client, modelInfoMeta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
