{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95790ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")\n",
    "\n",
    "from Clust.clust.ML.common import ML_pipeline, tool\n",
    "app_name= \"Hs2SwineFarmWithWeatherTime\" # \"Hs2SwineFarmWithWeatherTime\", \"energy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f5edd",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc6a75",
   "metadata": {},
   "source": [
    "### 1-1. Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64028082",
   "metadata": {},
   "outputs": [],
   "source": [
    "if app_name == \"energy\":\n",
    "    model_purpose = 'regression'\n",
    "    feature_X_list = ['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "       'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "       'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "    feature_y_list = ['value']\n",
    "    split_mode =\"windows_split\"\n",
    "    data_y_flag = True # 이미 만들어진 Y 데이터를 활용함\n",
    "    \n",
    "elif app_name == \"Hs2SwineFarmWithWeatherTime\":\n",
    "    model_purpose = 'forecasting' \n",
    "    feature_X_list = ['Temperature', 'out_temp','sin_hour']\n",
    "    feature_y_list = ['Temperature']\n",
    "    split_mode = 'step_split'\n",
    "    data_y_flag = False # Y데이터는 없음, X 에서 Y 데이터를 도출함\n",
    "    \n",
    "step = 'train'\n",
    "bucket_name = 'integration' \n",
    "data_clean_level = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e5aaf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX', 'forecasting_strawberryOpen_cleanLevel0_testX', 'forecasting_strawberryOpen_cleanLevel0_trainX', 'forecasting_strawberryOpen_cleanLevel4_testX', 'forecasting_strawberryOpen_cleanLevel4_trainX', 'regression_energy_cleanLevel0_testX', 'regression_energy_cleanLevel0_testy', 'regression_energy_cleanLevel0_trainX', 'regression_energy_cleanLevel0_trainy', 'regression_energy_cleanLevel4_testX', 'regression_energy_cleanLevel4_testy', 'regression_energy_cleanLevel4_trainX', 'regression_energy_cleanLevel4_trainy']\n",
      "==========================================================\n",
      "['forecasting_Hs2SwineFarmWithWeatherTime', 'forecasting_strawberryOpen', 'regression_energy']\n"
     ]
    }
   ],
   "source": [
    "all_integrated_ms_list = db_client.measurement_list(bucket_name)\n",
    "print(all_integrated_ms_list)\n",
    "print(\"==========================================================\")\n",
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "print(collection_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3029057",
   "metadata": {},
   "source": [
    "### 1-2. Data Ingestion\n",
    "#### 1-2-1. Select data name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccf9f326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = model_purpose + '_' + app_name  \n",
    "data_name_X = dataset_name + '_cleanLevel' + str(data_clean_level)+'_'+step+'X'\n",
    "data_name_y = dataset_name+'_cleanLevel' + str(data_clean_level)+'_'+ step+'y'\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'ms_name':data_name_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8608cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bucket_name': 'integration',\n",
       "  'collection_name': 'forecasting_Hs2SwineFarmWithWeatherTime',\n",
       "  'ms_name': 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX',\n",
       "  'ingestion_type': 'multiple_ms_by_time',\n",
       "  'ingestion_param': {'start_time': '2021-02-01 00:00:00',\n",
       "   'end_time': '2021-03-10 00:00:00',\n",
       "   'ms_list_info': [['farm_swine_air', 'HS2'],\n",
       "    ['weather_outdoor_keti_clean', 'sangju'],\n",
       "    ['life_additional_Info', 'trigonometicInfoByHours']]},\n",
       "  'processing_type': 'step_3',\n",
       "  'process_param': {'refine_param': {'removeDuplication': {'flag': True},\n",
       "    'staticFrequency': {'flag': True, 'frequency': None}},\n",
       "   'outlier_param': {'certainErrorToNaN': {'flag': True},\n",
       "    'unCertainErrorToNaN': {'flag': True,\n",
       "     'param': {'outlierDetectorConfig': [{'algorithm': 'IQR',\n",
       "        'percentile': 99,\n",
       "        'alg_parameter': {'weight': 100}}]}}},\n",
       "   'imputation_param': {'flag': True,\n",
       "    'imputation_method': [{'min': 0,\n",
       "      'max': 2,\n",
       "      'method': 'linear',\n",
       "      'parameter': {}}],\n",
       "    'totalNonNanRatio': 90}},\n",
       "  'integration_param': {'integration_frequency': 600,\n",
       "   'param': {},\n",
       "   'method': 'meta',\n",
       "   'integration_duration': 'common'},\n",
       "  'clean_level': 4}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102bcf3",
   "metadata": {},
   "source": [
    "#### 1-2-2. X-y Data Ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98c01141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "ingestion_method = 'ms_all'\n",
    "ingestion_param_X = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_X,\n",
    "    'feature_list' : feature_X_list                              \n",
    "}\n",
    "ingestion_param_y = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_y,\n",
    "    'feature_list' : feature_y_list                              \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bcec8e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_X, data_y = ML_pipeline.Xy_data_preparation(ingestion_param_X, data_y_flag, ingestion_param_y, ingestion_method, db_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e818e",
   "metadata": {},
   "source": [
    "### 1-2-2. Random Nan Insert (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f9d5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff0fe682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../../Clust/clust/ML/common/tool.py:17: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  df.loc[df.sample(frac=nan_ratio). index, col] = pd.np.nan\n",
      "/home/leezy/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/leezy/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:723: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n"
     ]
    }
   ],
   "source": [
    "data_X = tool.random_nan_df(data_X, nan_ratio)\n",
    "data_y = tool.random_nan_df(data_y, nan_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51d355",
   "metadata": {},
   "source": [
    "#### 1-2-3. Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bd78ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_param='scale'\n",
    "scale_method='minmax'\n",
    "scaler_path = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "768ca14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temperature', 'out_temp', 'sin_hour']\n",
      "Make New scaler File\n",
      "['Temperature']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled, X_scalerFilePath, datay_scaled, y_scalerFilePath= ML_pipeline.Xy_data_scaling_train(data_name_X, data_X, data_name_y, data_y, scaler_path, scaler_param, scale_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54c637",
   "metadata": {},
   "source": [
    "## 2. Cleaning and split\n",
    "### 2.1 pipeline - clean low quality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22975a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = True\n",
    "nan_process_info = {'type':'num', 'ConsecutiveNanLimit':10000, 'totalNaNLimit':100000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "28752269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ---> 3\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled = ML_pipeline.clean_low_quality_column(model_clean, nan_process_info, dataX_scaled)\n",
    "feature_X_list= list(dataX_scaled.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ae2c2",
   "metadata": {},
   "source": [
    "### 2.2 Train/Val Split pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2463833",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c884e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 데이터 나뉘는 부분 추가로 작성된 것 지수님에게 물어봐야 함\n",
    "day_window_size = tool.get_default_day_window_size(dataX_scaled)\n",
    "train_x, val_x, train_y, val_y = ML_pipeline.split_data_by_mode(split_mode, split_ratio, dataX_scaled, datay_scaled, day_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0495b",
   "metadata": {},
   "source": [
    "### 2.3 Data Transformation & Clean2 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2f206d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nan_limit_ratio = 0.5\n",
    "if split_mode =='windows_split':\n",
    "    transformParameter = {\n",
    "            'past_step':day_window_size,\n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }\n",
    "else:\n",
    "    transformParameter = {\n",
    "            'future_step': 2,\n",
    "            'past_step': 12, \n",
    "            'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "77429916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan_limit_num:  6\n",
      "Original num: 4258 Final num: 4176 NaN num: 82\n",
      "nan_limit_num:  6\n",
      "Original num: 1065 Final num: 1051 NaN num: 14\n"
     ]
    }
   ],
   "source": [
    "train_X_array, train_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, train_x, train_y)\n",
    "val_X_array, val_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3c56598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4176, 12, 3)\n",
      "(4176, 1)\n",
      "(1051, 12, 3)\n",
      "(1051, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_array.shape)\n",
    "print(train_y_array.shape)\n",
    "print(val_X_array.shape)\n",
    "print(val_y_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b9d01",
   "metadata": {},
   "source": [
    "### 2.4 Set Model and train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3adac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "seq_len, input_size = train_X_array.shape[1], train_X_array.shape[2]\n",
    "model_method = 'GRU_rg' # Set model methods i.e., 'LSTM_rg', 'GRU_rg', 'CNN_1D_rg', 'LSTM_FCNs_rg', 'FC_rg' \n",
    "if model_method == 'LSTM_rg' or model_method == 'GRU_rg':\n",
    "    modelParameter = {\n",
    "        'rnn_type': 'lstm',\n",
    "        'input_size': input_size, \n",
    "        'hidden_size': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_dim': 1, \n",
    "        'dropout': 0.1, \n",
    "        'bidirectional': True\n",
    "    }\n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'output_channels': 64,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 0, \n",
    "    'dropout': 0.1\n",
    "    }\n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_layers': 2,\n",
    "    'lstm_dropout': 0.4,\n",
    "    'fc_dropout': 0.1\n",
    "    }\n",
    "# FC model parameters\n",
    "elif model_method == 'FC_rg':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'dropout': 0.1,\n",
    "    'bias': True\n",
    "    }\n",
    "    \n",
    "train_parameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 20, \n",
    "    'batch_size': 16\n",
    "}\n",
    "model_name = None\n",
    "model_file_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798b4aa",
   "metadata": {},
   "source": [
    "### 2.5 Set Model name and path pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19dee514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Models/GRU_rg/Hs2SwineFarmWithWeatherTime_GRU_rg_True/forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX/e0c69926ea63923d2dbafa434a27060e/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# model_name and file path check and create\n",
    "model_name = tool.get_default_model_name(model_name, app_name, model_method, model_clean)\n",
    "model_file_path = tool.get_default_model_path(model_name, data_name_X, model_method, train_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "674e3d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hs2SwineFarmWithWeatherTime_GRU_rg_True'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44195f",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f51aab4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-eb12b13ecaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mML_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLUST_regresstion_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/common/ML_pipeline.py\u001b[0m in \u001b[0;36mCLUST_regresstion_train\u001b[0;34m(train_parameter, model_method, modelParameter, model_file_path, train_X_array, train_y_array, val_X_array, val_y_array)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/regression_YK/train.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, train_x, train_y, val_x, val_y)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mval_y\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0my\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_trainloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/regression_YK/clust_models/rnn_clust.py\u001b[0m in \u001b[0;36mcreate_trainloader\u001b[0;34m(self, batch_size, train_x, train_y, val_x, val_y)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "ML_pipeline.CLUST_regresstion_train(train_parameter, model_method, modelParameter, model_file_path, train_X_array, train_y_array, val_X_array, val_y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36ad30",
   "metadata": {},
   "source": [
    "## 4. save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "modelTags =[\"model_tag_example\"]\n",
    "trainDataType = \"timeseries\"\n",
    "\n",
    "modelInfoMeta ={\n",
    "    \"trainDataInfo\":data_meta,\n",
    "    \"modelName\":model_name,\n",
    "    \"dataSplitMode\":split_mode,\n",
    "    \"featureXList\":feature_X_list,\n",
    "    \"featureyList\":feature_y_list,\n",
    "    \"data_y_flag\": data_y_flag,\n",
    "    \"trainDataType\":trainDataType,\n",
    "    \"modelPurpose\":model_purpose,\n",
    "    \"modelMethod\":model_method,\n",
    "    \"modelTags\":modelTags,\n",
    "    \"modelCleanLevel\":model_clean,\n",
    "    \"trainParameter\": train_parameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \"transformParameter\":transformParameter,\n",
    "    \"scalerParam\":scaler_param,\n",
    "    \"trainDataName\":[data_name_X, data_name_y], \n",
    "\n",
    "    \"files\":{\n",
    "        \"modelFile\":{\n",
    "            \"fileName\":\"model.pth\",\n",
    "            \"filePath\":model_file_path\n",
    "        },\n",
    "        \"XScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":X_scalerFilePath       \n",
    "        },\n",
    "        \"yScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":y_scalerFilePath      \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "modelInfoMeta = ml_meta.save_model_meta_data(mongo_client, modelInfoMeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5ded7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
