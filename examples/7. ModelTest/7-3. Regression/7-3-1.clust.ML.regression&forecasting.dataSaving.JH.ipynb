{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc796a8",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab272b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import pathSetting\n",
    "import matplotlib.pyplot as plt\n",
    "from Clust.clust.ML.common.common import p1_integratedDataSaving as p1\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f637e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def integrated_data_meta(data_name, dataInfo, start_time, end_time, clean_param, integration_freq_sec, process_param):\n",
    "#     data_info = {}\n",
    "#     data_info[\"data_name\"] = data_name\n",
    "#     data_info[\"dataInfo\"] = dataInfo\n",
    "#     data_info[\"startTime\"] = start_time\n",
    "#     data_info[\"endTime\"] = end_time\n",
    "#     data_info[\"cleanParam\"] = clean_param\n",
    "#     data_info[\"integration_freq_sec\"] = integration_freq_sec\n",
    "#     data_info[\"process_param\"] = process_param\n",
    "    \n",
    "#     return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c95ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_selection = \"regression\" # or forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444638df",
   "metadata": {},
   "source": [
    "## Data Set setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf204cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode_selection == 'regression':\n",
    "    modeList =['trainX', 'trainy', 'testX', 'testy']\n",
    "\n",
    "    clean_param = \"NoClean\"\n",
    "\n",
    "    trainStartTime = \"2016-01-11\"\n",
    "    trainEndTime = \"2016-04-15\"\n",
    "\n",
    "    testStartTime = \"2021-01-01\"\n",
    "    testEndTime = \"2021-02-12\"\n",
    "\n",
    "    trainXDataInfo = [['life_indoor_environment', 'humidityTrain_10min'], \n",
    "                      ['life_indoor_environment', 'temperatureTrain_10min'], \n",
    "                      ['weather_outdoor_environment', 'belgiumChieverseAirportTrain_10min']]\n",
    "\n",
    "    testXDataInfo = [['life_indoor_environment', 'humidityTest_10min'], \n",
    "                     ['life_indoor_environment', 'temperatureTest_10min'], \n",
    "                     ['weather_outdoor_environment', 'belgiumChieverseAirportTest_10min']]\n",
    "    \n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "elif mode_selection == 'forecasting':\n",
    "    datasetNameList=['Hs1SwineFarmWithWeatherTime', 'gunwiStrawberryWithWeatherTime', 'strawberryOpenTime']\n",
    "\n",
    "    datasetName = datasetNameList[0]\n",
    "    integration_freq_sec = 60 * 5 # 5분\n",
    "\n",
    "    if datasetName=='Hs1SwineFarmWithWeatherTime':\n",
    "        trainStartTime = \"2021-02-01 00:00:00\"\n",
    "        trainEndTime =\"2021-03-10 00:00:00\"\n",
    "        testStartTime =\"2021-03-10 00:00:00\"\n",
    "        testEndTime =\"2021-03-17 00:00:00\"\n",
    "        dataInfo = [['farm_swine_air', 'HS2'], ['weather_outdoor_keti_clean', 'sangju'], ['life_additional_Info', 'trigonometicInfoByHours']]\n",
    "\n",
    "    elif datasetName=='gunwiStrawberryWithWeatherTime':\n",
    "        dataInfo = [['farm_strawberry_gunwi', 'control_environment'], ['farm_strawberry_gunwi', 'environment'], ['life_additional_Info', 'trigonometicInfoByHours']]\n",
    "        trainStartTime = \"2022-01-22 00:00:00\"\n",
    "        trainEndTime =\"2022-02-25 00:00:00\"\n",
    "        testStartTime =\"2022-02-25 00:00:00\"\n",
    "        testEndTime =\"2022-02-28 00:00:00\"\n",
    "\n",
    "    elif datasetName =='strawberryOpenTime':\n",
    "        dataInfo = [['farm_strawberry_gunwi', 'control_environment'], ['farm_strawberry_gunwi', 'environment'], ['life_additional_Info', 'trigonometicInfoByHours']]\n",
    "        trainStartTime = \"2022-01-22 00:00:00\"\n",
    "        trainEndTime =\"2022-02-25 00:00:00\"\n",
    "        testStartTime =\"2022-02-25 00:00:00\"\n",
    "        testEndTime =\"2022-02-28 00:00:00\"\n",
    "\n",
    "    ##################################################\n",
    "    #### 1-3. Static Varialbe List\n",
    "    LearningModeList=[\"train\", \"test\"]\n",
    "    cleanParamList =[\"Clean\", \"NoClean\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f1f60",
   "metadata": {},
   "source": [
    "## Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7443815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. information save\n",
    "# mongo db에 process_param, dataInfo, integration_freq_sec, start_time, end_time 정보 적혀야 합니다.\n",
    "# data_name이 중복적으로 발생한다는 단점이 있는데, 이는 추후 덮어쓰지 않기 위해서는, 기존에 이런 데이터가 있냐 덮어쓰겠냐?\n",
    "# UI적으로 요런 루트만 만들어주면 되지 않을까 싶어요.\n",
    "# 위 p1.get_process_param 이부분 나중에 좀 생각해보고 없애겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b8ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'integration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dd3a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===integrationStart===\n",
      "===integrationEnd===\n",
      "========== write success ==========\n",
      "========== Data Save Success ==========\n",
      "===integrationStart===\n",
      "===integrationEnd===\n",
      "========== write success ==========\n",
      "========== Data Save Success ==========\n",
      "===integrationStart===\n",
      "===integrationEnd===\n",
      "========== write success ==========\n",
      "========== Data Save Success ==========\n",
      "===integrationStart===\n",
      "===integrationEnd===\n",
      "========== write success ==========\n",
      "========== Data Save Success ==========\n"
     ]
    }
   ],
   "source": [
    "if mode_selection == 'regression':\n",
    "    for mode in modeList:\n",
    "        # 0. Set Basic Parameter \n",
    "        # 1-1 StartTime, EndTime, DataInfo, Integration_freq_sec, cleanParam, processParam\n",
    "\n",
    "        if mode == 'trainX':\n",
    "            dataName = 'IntegraionTrainX'\n",
    "            start_time = trainStartTime\n",
    "            end_time = trainEndTime\n",
    "            dataInfo = trainXDataInfo\n",
    "            integration_freq_sec = 60 * 10 # 10분\n",
    "\n",
    "        elif mode =='testX':\n",
    "            dataName = 'IntegraionTestX'\n",
    "            start_time = testStartTime\n",
    "            end_time = testEndTime\n",
    "            dataInfo = testXDataInfo\n",
    "            integration_freq_sec = 60 * 10 # 10분\n",
    "\n",
    "        elif mode == 'trainy':\n",
    "            dataName = 'IntegraionTrainy'\n",
    "            start_time = trainStartTime\n",
    "            end_time = trainEndTime\n",
    "            dataInfo = [['life_indoor_environment', 'applianceEnergyDatasetTrainy_1day']]\n",
    "            integration_freq_sec = 60 * 60 * 24 # 24시간\n",
    "\n",
    "        elif mode =='testy':\n",
    "            dataName = 'IntegraionTesty'\n",
    "            start_time = testStartTime\n",
    "            end_time = testEndTime\n",
    "            dataInfo = [['life_indoor_environment', 'applianceEnergyDatasetTesty_1day']]\n",
    "            integration_freq_sec = 60 * 60 * 24 # 24시간\n",
    "\n",
    "        # dataset ingestion---> data preprocessing ---> data integration ---> information save\n",
    "\n",
    "        # 1. Ingestion multiple dataset\n",
    "        #############\n",
    "        ingestion_param ={}\n",
    "        ingestion_param['ms_list_info'] = dataInfo\n",
    "        ingestion_param['start_time'] = start_time\n",
    "        ingestion_param['end_time'] = end_time\n",
    "        #############\n",
    "\n",
    "        from Clust.clust.data import data_interface\n",
    "        multiple_dataset = data_interface.get_data_result(\"multiple_ms_by_time\", db_client, ingestion_param)\n",
    "\n",
    "        # 2. Data Preprocessing\n",
    "        from Clust.clust.preprocessing import processing_interface\n",
    "        process_param = p1.get_process_param(clean_param) \n",
    "        multiple_dataset = processing_interface.get_data_result('step_3', multiple_dataset, process_param)\n",
    "\n",
    "        # 3. Data Integration\n",
    "        from Clust.clust.integration.integrationInterface import IntegrationInterface\n",
    "        integration_param = {\n",
    "            \"integration_frequency\":integration_freq_sec,\n",
    "            \"param\":{},\n",
    "            \"method\":\"meta\",\n",
    "            \"integration_duration\":\"common\"\n",
    "        }\n",
    "        data = IntegrationInterface().multipleDatasetsIntegration(integration_param, multiple_dataset)\n",
    "\n",
    "        ms_name = \"energy\" + mode + '_' + \"regression\" + '_' + clean_param\n",
    "        collection_name = \"energy\" + \"_regression\"\n",
    "        \n",
    "        # save to influxdb\n",
    "        db_client.write_db(db_name, ms_name, data)\n",
    "        \n",
    "        # save to mongodb\n",
    "        data_info = p1.integrated_data_meta(dataInfo, start_time, end_time, integration_freq_sec, clean_param, process_param)\n",
    "        mongo_client.insert_document(db_name, collection_name, data_info)\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "elif mode_selection == 'forecasting':\n",
    "    for learningMode in LearningModeList:\n",
    "        for clean_param in cleanParamList:\n",
    "            processParam = p1.get_process_param(clean_param) \n",
    "            if learningMode == 'train':\n",
    "                start_time = trainStartTime\n",
    "                end_time = trainEndTime\n",
    "\n",
    "            elif learningMode =='test':\n",
    "                start_time = testStartTime\n",
    "                end_time = testEndTime\n",
    "\n",
    "            # 1. Ingestion multiple dataset\n",
    "            ingestion_param ={}\n",
    "            ingestion_param['ms_list_info'] = dataInfo\n",
    "            ingestion_param['start_time'] = start_time\n",
    "            ingestion_param['end_time'] = end_time\n",
    "\n",
    "            from Clust.clust.data import data_interface\n",
    "            multiple_dataset = data_interface.get_data_result(\"multiple_ms_by_time\", db_client, ingestion_param)\n",
    "\n",
    "            # 2. Data Preprocessing\n",
    "            from Clust.clust.preprocessing import processing_interface\n",
    "            process_param = p1.get_process_param(clean_param) \n",
    "            multiple_dataset = processing_interface.get_data_result('step_3', multiple_dataset, process_param)\n",
    "\n",
    "            # 3. Data Integration\n",
    "            from Clust.clust.integration.integrationInterface import IntegrationInterface\n",
    "            integration_param = {\n",
    "                \"integration_frequency\":integration_freq_sec,\n",
    "                \"param\":{},\n",
    "                \"method\":\"meta\",\n",
    "                \"integration_duration\":\"common\"\n",
    "            }\n",
    "            data = IntegrationInterface().multipleDatasetsIntegration(integration_param, multiple_dataset)\n",
    "\n",
    "            ms_name = datasetName + learningMode +'_' + \"forecasting\" + '_' + clean_param\n",
    "            collection_name = datasetName + \"_forecasting\"\n",
    "            \n",
    "            # save to influxdb\n",
    "            db_client.write_db(bucket_name, ms_name, data)\n",
    "            \n",
    "            # save to mongodb\n",
    "            data_info = p1.integrated_data_meta(dataInfo, start_time, end_time, integration_freq_sec, clean_param, process_param)\n",
    "            mongo_client.insert_document(db_name, collection_name, data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91b552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737a1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad07c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
