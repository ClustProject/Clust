{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd79d0c3",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1611f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/.clust/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "import setting\n",
    "\n",
    "from Clust.clust.ML.common.common import p1_integratedDataSaving as p1\n",
    "from Clust.clust.ML.tool import data as ml_data\n",
    "from Clust.clust.ML.tool import scaler as ml_scaler\n",
    "from Clust.clust.ML.tool import clean as ml_clean\n",
    "import pathSetting\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1788c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regression mode i.e., 'regression','forecast' \n",
    "mode_selection = \"regression\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8d30ae7",
   "metadata": {},
   "source": [
    "### 4-1. Get model meta by mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "db_name = 'model'\n",
    "collection_name = 'meta'\n",
    "\n",
    "all_model_meta = mongo_client.get_all_document(db_name, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae5b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {'modelName': 'TestGRU_rg'}\n",
    "model_meta= mongo_client.get_document_by_json(db_name, collection_name, search)\n",
    "model_meta = model_meta[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1f6bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainDataInfo': {'startTime': '2016-01-11',\n",
       "  'endTime': '2016-04-15',\n",
       "  'dataInfo': [['life_indoor_environment', 'humidityTrain_10min'],\n",
       "   ['life_indoor_environment', 'temperatureTrain_10min'],\n",
       "   ['weather_outdoor_environment', 'belgiumChieverseAirportTrain_10min']],\n",
       "  'processParam': {'refine_param': {'removeDuplication': {'flag': False},\n",
       "    'staticFrequency': {'flag': False, 'frequency': None}},\n",
       "   'outlier_param': {'certainErrorToNaN': {'flag': False},\n",
       "    'unCertainErrorToNaN': {'flag': False, 'param': {}}},\n",
       "   'imputation_param': {'flag': False,\n",
       "    'imputation_method': [],\n",
       "    'totalNonNanRatio': 80}},\n",
       "  'integration_freq_sec': 600,\n",
       "  'cleanParam': 'NoClean',\n",
       "  'DataSaveMode': 'CSV'},\n",
       " 'modelName': 'TestGRU_rg',\n",
       " 'featureList': ['RH_1',\n",
       "  'RH_2',\n",
       "  'RH_3',\n",
       "  'RH_4',\n",
       "  'RH_5',\n",
       "  'RH_6',\n",
       "  'RH_7',\n",
       "  'RH_8',\n",
       "  'RH_9',\n",
       "  'T1',\n",
       "  'T2',\n",
       "  'T3',\n",
       "  'T4',\n",
       "  'T5',\n",
       "  'T6',\n",
       "  'T7',\n",
       "  'T8',\n",
       "  'T9',\n",
       "  'Press_mm_hg',\n",
       "  'RH_out',\n",
       "  'T_out',\n",
       "  'Tdewpoint',\n",
       "  'Visibility',\n",
       "  'Windspeed'],\n",
       " 'target': ['value'],\n",
       " 'trainDataType': 'timeseries',\n",
       " 'modelPurpose': 'regression',\n",
       " 'model_method': 'GRU_rg',\n",
       " 'modelTags': ['aaaaa'],\n",
       " 'cleanTrainDataParam': 'NoClean',\n",
       " 'NaNProcessingParam': {'feature_cycle': 'Day',\n",
       "  'feature_cycle_times': 1,\n",
       "  'NanInfoForCleanData': {'type': 'num',\n",
       "   'ConsecutiveNanLimit': 3,\n",
       "   'totalNaNLimit': 30000}},\n",
       " 'trainDataName': ['IntegraionTrainX', 'IntegraionTrainy'],\n",
       " 'trainParameter': {'lr': 0.0001,\n",
       "  'weight_decay': 1e-06,\n",
       "  'device': 'cpu',\n",
       "  'n_epochs': 10,\n",
       "  'batch_size': 16},\n",
       " 'modelParameter': {'rnn_type': 'lstm',\n",
       "  'input_size': 24,\n",
       "  'hidden_size': 64,\n",
       "  'num_layers': 2,\n",
       "  'output_dim': 1,\n",
       "  'dropout': 0.1,\n",
       "  'bidirectional': True},\n",
       " 'transformParameter': {},\n",
       " 'scalerParam': 'scale',\n",
       " 'files': {'modelFile': {'fileName': 'model.pth',\n",
       "   'filePath': './Models/GRU_rg/TestGRU_rg/IntegraionTrainX/d531eec11664669cff1f6a3ad9639012/model.pkl'},\n",
       "  'XScalerFile': {'fileName': 'scaler.pkl',\n",
       "   'filePath': './scaler/IntegraionTrainX/NoClean/minmax/44e77c5a60a148deb89c5ef9a221a365/scaler.pkl'},\n",
       "  'yScalerFile': {'fileName': 'scaler.pkl',\n",
       "   'filePath': './scaler/IntegraionTrainX/NoClean/minmax/f69156750a210491ffd4a67b605bc88b/scaler.pkl'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b9185d9",
   "metadata": {},
   "source": [
    "### 4-2. Inference data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2579d539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0. pick only one data\n",
    "DataMeta = p1.read_json_data(pathSetting.DataMetaPath)\n",
    "dataList =  list(DataMeta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ade136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IntegraionTrainX', 'IntegraionTrainy', 'IntegraionTestX', 'IntegraionTesty']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e11196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode_selection == 'regression':\n",
    "    # dataX\n",
    "\n",
    "    dataName_X = dataList[2]\n",
    "    dataSaveMode_X = DataMeta[dataName_X][\"integrationInfo\"][\"DataSaveMode\"]\n",
    "\n",
    "    dataFolderName = \"data_integrated_result\"\n",
    "    current = os.getcwd()\n",
    "    dataFolderPath = os.path.join(current, dataFolderName)\n",
    "\n",
    "    window_num =144\n",
    "    dataX = ml_data.get_saved_integrated_data(dataSaveMode_X, dataName_X, dataFolderPath)[:window_num]\n",
    "\n",
    "elif mode_selection == 'forecast':\n",
    "    LearningModeList = ['train', 'test']\n",
    "    LearningMode = LearningModeList[1]\n",
    "\n",
    "    cleanParamList = ['Clean', 'NoClean']\n",
    "    cleanMode = cleanParamList[1]\n",
    "\n",
    "    datasetNameList = ['Hs1SwineFarmWithWeatherTime', 'gunwiStrawberryWithWeatherTime', 'strawberryOpenTime']\n",
    "    datasetName = datasetNameList[0]\n",
    "\n",
    "    dataName_X = LearningMode + cleanMode + '_' + datasetName\n",
    "    dataSaveMode_X = DataMeta[dataName_X]['integrationInfo']['DataSaveMode']\n",
    "\n",
    "    dataX = ml_data.get_saved_integrated_data(dataSaveMode_X, dataName_X, pathSetting.dataFolderPath)\n",
    "    integration_freq_sec = DataMeta[dataName_X]['integrationInfo']['integration_freq_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef67904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                RH_1       RH_2       RH_3       RH_4  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  40.260000  43.200000  38.530000  37.363333   \n",
      "2021-01-01 00:10:00+00:00  40.260000  43.163333  38.500000  37.230000   \n",
      "2021-01-01 00:20:00+00:00  40.290000  42.963333  38.633333  37.200000   \n",
      "2021-01-01 00:30:00+00:00  40.290000  42.490000  38.790000  37.200000   \n",
      "2021-01-01 00:40:00+00:00  40.626667  42.156667  38.596667  37.090000   \n",
      "...                              ...        ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  41.500000  42.090000  38.290000  40.730000   \n",
      "2021-01-01 23:20:00+00:00  41.833333  42.290000  38.290000  40.790000   \n",
      "2021-01-01 23:30:00+00:00  42.090000  42.363333  38.290000  41.166667   \n",
      "2021-01-01 23:40:00+00:00  42.030000  42.433333  38.363333  42.093333   \n",
      "2021-01-01 23:50:00+00:00  41.900000  42.500000  38.290000  42.400000   \n",
      "\n",
      "                                RH_5       RH_6       RH_7       RH_8  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  48.126667  35.026667  32.863333  40.290000   \n",
      "2021-01-01 00:10:00+00:00  48.126667  38.763333  32.790000  40.163333   \n",
      "2021-01-01 00:20:00+00:00  48.060000  40.096667  32.663333  39.963333   \n",
      "2021-01-01 00:30:00+00:00  48.060000  41.633333  32.567500  39.900000   \n",
      "2021-01-01 00:40:00+00:00  48.060000  42.160000  32.433333  39.900000   \n",
      "...                              ...        ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  52.126667  36.666667  37.060000  40.700000   \n",
      "2021-01-01 23:20:00+00:00  51.863333  36.333333  37.126667  40.896667   \n",
      "2021-01-01 23:30:00+00:00  51.656667  34.633333  37.126667  41.623333   \n",
      "2021-01-01 23:40:00+00:00  51.560000  36.575000  37.200000  42.245000   \n",
      "2021-01-01 23:50:00+00:00  51.433333  37.526667  37.260000  42.590000   \n",
      "\n",
      "                                RH_9     T1  ...         T6         T7  \\\n",
      "datetime                                     ...                         \n",
      "2021-01-01 00:00:00+00:00  41.966667  22.60  ...  10.630000  21.390000   \n",
      "2021-01-01 00:10:00+00:00  41.766667  22.60  ...  10.233333  21.323333   \n",
      "2021-01-01 00:20:00+00:00  41.700000  22.60  ...   9.960000  21.290000   \n",
      "2021-01-01 00:30:00+00:00  41.700000  22.60  ...   9.763333  21.290000   \n",
      "2021-01-01 00:40:00+00:00  41.560000  22.70  ...   9.630000  21.230000   \n",
      "...                              ...    ...  ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  42.200000  22.00  ...  14.756667  21.100000   \n",
      "2021-01-01 23:20:00+00:00  42.126667  22.00  ...  14.963333  21.100000   \n",
      "2021-01-01 23:30:00+00:00  42.200000  22.00  ...  14.763333  21.033333   \n",
      "2021-01-01 23:40:00+00:00  42.200000  22.00  ...  14.740000  21.066667   \n",
      "2021-01-01 23:50:00+00:00  42.230000  21.89  ...  15.030000  21.066667   \n",
      "\n",
      "                                  T8     T9  Press_mm_hg     RH_out  \\\n",
      "datetime                                                              \n",
      "2021-01-01 00:00:00+00:00  22.856667  19.79   757.000000  66.000000   \n",
      "2021-01-01 00:10:00+00:00  22.890000  19.79   757.116667  65.333333   \n",
      "2021-01-01 00:20:00+00:00  22.963333  19.79   757.233333  64.666667   \n",
      "2021-01-01 00:30:00+00:00  23.050000  19.79   757.350000  64.000000   \n",
      "2021-01-01 00:40:00+00:00  23.133333  19.76   757.466667  63.333333   \n",
      "...                              ...    ...          ...        ...   \n",
      "2021-01-01 23:10:00+00:00  22.700000  20.00   752.650000  73.500000   \n",
      "2021-01-01 23:20:00+00:00  22.700000  20.00   752.500000  73.000000   \n",
      "2021-01-01 23:30:00+00:00  22.760000  20.00   752.350000  72.500000   \n",
      "2021-01-01 23:40:00+00:00  22.840000  20.00   752.200000  72.000000   \n",
      "2021-01-01 23:50:00+00:00  23.000000  20.00   752.050000  71.500000   \n",
      "\n",
      "                               T_out  Tdewpoint  Visibility  Windspeed  \n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  10.400000   4.200000        40.0   4.000000  \n",
      "2021-01-01 00:10:00+00:00  10.316667   4.000000        40.0   3.833333  \n",
      "2021-01-01 00:20:00+00:00  10.233333   3.800000        40.0   3.666667  \n",
      "2021-01-01 00:30:00+00:00  10.150000   3.600000        40.0   3.500000  \n",
      "2021-01-01 00:40:00+00:00  10.066667   3.400000        40.0   3.333333  \n",
      "...                              ...        ...         ...        ...  \n",
      "2021-01-01 23:10:00+00:00  12.950000   8.233333        40.0   7.666667  \n",
      "2021-01-01 23:20:00+00:00  13.100000   8.266667        40.0   7.333333  \n",
      "2021-01-01 23:30:00+00:00  13.250000   8.300000        40.0   7.000000  \n",
      "2021-01-01 23:40:00+00:00  13.400000   8.333333        40.0   6.666667  \n",
      "2021-01-01 23:50:00+00:00  13.550000   8.366667        40.0   6.333333  \n",
      "\n",
      "[144 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataX)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90644dc4",
   "metadata": {},
   "source": [
    "### 4-3. Inference data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba005fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = model_meta['featureList']\n",
    "target = model_meta['target']\n",
    "scaler_param = model_meta['scalerParam']\n",
    "transform_param = model_meta[\"transformParameter\"]\n",
    "model_file_path = model_meta['files']['modelFile']['filePath']\n",
    "model_method = model_meta['model_method']\n",
    "# train_parameter = model_meta[\"trainParameter\"]\n",
    "\n",
    "if mode_selection == 'regression':\n",
    "    # Scaling Inference Input\n",
    "    X_scaler_file_path = model_meta['files']['XScalerFile'][\"filePath\"]\n",
    "    y_scaler_file_path = model_meta['files']['yScalerFile'][\"filePath\"]\n",
    "\n",
    "    infer_X, scaler_X = ml_scaler.get_scaled_test_data(dataX[feature_list], X_scaler_file_path, scaler_param)\n",
    "    scaler_y = ml_scaler.get_scaler_file(y_scaler_file_path)\n",
    "\n",
    "elif mode_selection == 'forecast':\n",
    "    clean_param = model_meta['cleanTrainDataParam']\n",
    "    nan_processing_param = model_meta['NaNProcessingParam']\n",
    "\n",
    "    # Scaling Inference Input\n",
    "    X_scaler_file_path = model_meta['files']['XScalerFile']['filePath']\n",
    "\n",
    "    # only for forecast data?\n",
    "    past_step = transform_param['past_step']\n",
    "    feature_data = dataX[feature_list]\n",
    "    step_data = feature_data[-past_step:][feature_list].values\n",
    "    df_data = pd.DataFrame(step_data, columns=feature_list)\n",
    "\n",
    "    infer_X, scaler_X = ml_scaler.get_scaled_test_data(df_data[feature_list], X_scaler_file_path, scaler_param)\n",
    "    clean_infer_X = ml_clean.get_cleand_data(infer_X, clean_param, integration_freq_sec, nan_processing_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfa7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               RH_1      RH_2      RH_3      RH_4      RH_5  \\\n",
      "datetime                                                                      \n",
      "2021-01-01 00:00:00+00:00  0.364279  0.664944  0.456302  0.386490  0.275336   \n",
      "2021-01-01 00:10:00+00:00  0.364279  0.663872  0.454900  0.380531  0.275336   \n",
      "2021-01-01 00:20:00+00:00  0.365104  0.658023  0.461131  0.379190  0.274333   \n",
      "2021-01-01 00:30:00+00:00  0.365104  0.644180  0.468453  0.379190  0.274333   \n",
      "2021-01-01 00:40:00+00:00  0.374369  0.634432  0.459417  0.374274  0.274333   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  0.398404  0.632482  0.445085  0.536963  0.335480   \n",
      "2021-01-01 23:20:00+00:00  0.407577  0.638331  0.445085  0.539644  0.331521   \n",
      "2021-01-01 23:30:00+00:00  0.414641  0.640476  0.445085  0.556479  0.328413   \n",
      "2021-01-01 23:40:00+00:00  0.412990  0.642523  0.448512  0.597896  0.326960   \n",
      "2021-01-01 23:50:00+00:00  0.409412  0.644473  0.445085  0.611603  0.325055   \n",
      "\n",
      "                               RH_6      RH_7      RH_8      RH_9        T1  \\\n",
      "datetime                                                                      \n",
      "2021-01-01 00:00:00+00:00  0.344051  0.342671  0.366347  0.516115  0.613516   \n",
      "2021-01-01 00:10:00+00:00  0.381834  0.340071  0.362006  0.507596  0.613516   \n",
      "2021-01-01 00:20:00+00:00  0.395315  0.335579  0.355152  0.504756  0.613516   \n",
      "2021-01-01 00:30:00+00:00  0.410853  0.332181  0.352981  0.504756  0.613516   \n",
      "2021-01-01 00:40:00+00:00  0.416178  0.327423  0.352981  0.498793  0.624076   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  0.360634  0.491489  0.380398  0.526054  0.550158   \n",
      "2021-01-01 23:20:00+00:00  0.357263  0.493853  0.387137  0.522931  0.550158   \n",
      "2021-01-01 23:30:00+00:00  0.340074  0.493853  0.412040  0.526054  0.550158   \n",
      "2021-01-01 23:40:00+00:00  0.359707  0.496454  0.433345  0.526054  0.550158   \n",
      "2021-01-01 23:50:00+00:00  0.369329  0.498582  0.445168  0.527332  0.538543   \n",
      "\n",
      "                           ...        T6        T7        T8        T9  \\\n",
      "datetime                   ...                                           \n",
      "2021-01-01 00:00:00+00:00  ...  0.485955  0.565504  0.599634  0.509886   \n",
      "2021-01-01 00:10:00+00:00  ...  0.474409  0.559221  0.602685  0.509886   \n",
      "2021-01-01 00:20:00+00:00  ...  0.466453  0.556079  0.609399  0.509886   \n",
      "2021-01-01 00:30:00+00:00  ...  0.460729  0.556079  0.617333  0.509886   \n",
      "2021-01-01 00:40:00+00:00  ...  0.456848  0.550424  0.624962  0.506764   \n",
      "...                        ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  ...  0.606074  0.538172  0.585291  0.531738   \n",
      "2021-01-01 23:20:00+00:00  ...  0.612089  0.538172  0.585291  0.531738   \n",
      "2021-01-01 23:30:00+00:00  ...  0.606268  0.531888  0.590784  0.531738   \n",
      "2021-01-01 23:40:00+00:00  ...  0.605589  0.535030  0.598108  0.531738   \n",
      "2021-01-01 23:50:00+00:00  ...  0.614030  0.535030  0.612756  0.531738   \n",
      "\n",
      "                           Press_mm_hg    RH_out     T_out  Tdewpoint  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00     0.669082  0.552632  0.493548   0.488688   \n",
      "2021-01-01 00:10:00+00:00     0.671900  0.543860  0.490860   0.479638   \n",
      "2021-01-01 00:20:00+00:00     0.674718  0.535088  0.488172   0.470588   \n",
      "2021-01-01 00:30:00+00:00     0.677536  0.526316  0.485484   0.461538   \n",
      "2021-01-01 00:40:00+00:00     0.680354  0.517544  0.482796   0.452489   \n",
      "...                                ...       ...       ...        ...   \n",
      "2021-01-01 23:10:00+00:00     0.564010  0.651316  0.575806   0.671192   \n",
      "2021-01-01 23:20:00+00:00     0.560386  0.644737  0.580645   0.672700   \n",
      "2021-01-01 23:30:00+00:00     0.556763  0.638158  0.585484   0.674208   \n",
      "2021-01-01 23:40:00+00:00     0.553140  0.631579  0.590323   0.675716   \n",
      "2021-01-01 23:50:00+00:00     0.549517  0.625000  0.595161   0.677225   \n",
      "\n",
      "                           Visibility  Windspeed  \n",
      "datetime                                          \n",
      "2021-01-01 00:00:00+00:00    0.609375   0.307692  \n",
      "2021-01-01 00:10:00+00:00    0.609375   0.294872  \n",
      "2021-01-01 00:20:00+00:00    0.609375   0.282051  \n",
      "2021-01-01 00:30:00+00:00    0.609375   0.269231  \n",
      "2021-01-01 00:40:00+00:00    0.609375   0.256410  \n",
      "...                               ...        ...  \n",
      "2021-01-01 23:10:00+00:00    0.609375   0.589744  \n",
      "2021-01-01 23:20:00+00:00    0.609375   0.564103  \n",
      "2021-01-01 23:30:00+00:00    0.609375   0.538462  \n",
      "2021-01-01 23:40:00+00:00    0.609375   0.512821  \n",
      "2021-01-01 23:50:00+00:00    0.609375   0.487179  \n",
      "\n",
      "[144 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(infer_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb5966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/transformation/type/DFToNPArray.py:221: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfX_partial = dfX[startDate:endDate]\n"
     ]
    }
   ],
   "source": [
    "# transform\n",
    "if mode_selection == 'regression':\n",
    "\n",
    "    from Clust.clust.transformation.type.DFToNPArray import transDFtoNP, trans_df_to_np, trans_df_to_np_inf\n",
    "    inferX = trans_df_to_np_inf(infer_X)\n",
    "\n",
    "# forecast\n",
    "elif mode_selection == 'forecast':\n",
    "    \n",
    "    from Clust.clust.transformation.purpose.machineLearning import LSTMData\n",
    "    LSTMD = LSTMData()\n",
    "    testX, testy = LSTMD.transform_Xy_arr(clean_infer_X, transformParameter, transformParameter['clean_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c71050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1, 24, 144)\n",
      "[[[0.36427851 0.36427851 0.36510412 ... 0.41464086 0.41298963 0.40941198]\n",
      "  [0.66494443 0.6638721  0.65802301 ... 0.64047573 0.64252291 0.64447261]\n",
      "  [0.4563016  0.45489952 0.46113102 ... 0.4450849  0.44851223 0.4450849 ]\n",
      "  ...\n",
      "  [0.48868778 0.47963801 0.47058824 ... 0.67420814 0.67571644 0.67722474]\n",
      "  [0.609375   0.609375   0.609375   ... 0.609375   0.609375   0.609375  ]\n",
      "  [0.30769231 0.29487179 0.28205128 ... 0.53846154 0.51282051 0.48717949]]]\n"
     ]
    }
   ],
   "source": [
    "print(type(inferX), inferX.shape)\n",
    "print(inferX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb22200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParameter = model_meta[\"modelParameter\"]\n",
    "\n",
    "inferParameter = {\n",
    "    'device': 'cpu',\n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb72fb20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ri\u001b[39m.\u001b[39mset_param(inferParameter)\n\u001b[1;32m      6\u001b[0m ri\u001b[39m.\u001b[39mset_model(model_method, model_file_path, modelParameter)\n\u001b[0;32m----> 7\u001b[0m ri\u001b[39m.\u001b[39;49mset_data(infer_X)\n\u001b[1;32m      8\u001b[0m preds \u001b[39m=\u001b[39m ri\u001b[39m.\u001b[39minference()\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(preds)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/regression_YK/inference.py:75\u001b[0m, in \u001b[0;36mRegressionInference.set_data\u001b[0;34m(self, infer_X)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_data\u001b[39m(\u001b[39mself\u001b[39m, infer_X):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    set data for inference & transform data\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m  \n\u001b[0;32m---> 75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minference_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcreate_inferenceloader(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer_params[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m], infer_X)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/7. ModelTest/7-3. Regression/../../../../Clust/clust/ML/regression_YK/clust_models/rnn_clust.py:274\u001b[0m, in \u001b[0;36mRNNClust.create_inferenceloader\u001b[0;34m(self, batch_size, infer_x)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mCreate inference data loader for torch\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m    inference_loader (DataLoader) : inference data loader\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m# infer_x = infer_x.values.astype(np.float32)\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39m# infer_x = infer_x.reshape((-1, infer_x.shape[0], infer_x.shape[1]))\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m infer_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mTensor(infer_x)\n\u001b[1;32m    275\u001b[0m inference_loader \u001b[39m=\u001b[39m DataLoader(infer_x, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minference data shape:\u001b[39m\u001b[39m\"\u001b[39m, infer_x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "# 4. Inference\n",
    "from Clust.clust.ML.regression_YK.inference import RegressionInference as RI\n",
    "\n",
    "ri = RI()\n",
    "ri.set_param(inferParameter)\n",
    "ri.set_model(model_method, model_file_path, modelParameter)\n",
    "ri.set_data(infer_X)\n",
    "preds = ri.inference()\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a6573",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m scaler_param \u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m     base_df_for_inverse \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mtarget, index\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(preds)))\n\u001b[0;32m----> 5\u001b[0m     base_df_for_inverse[target] \u001b[39m=\u001b[39m preds\n\u001b[1;32m      6\u001b[0m     prediction_result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(scaler_y\u001b[39m.\u001b[39minverse_transform(base_df_for_inverse), columns\u001b[39m=\u001b[39mtarget, index\u001b[39m=\u001b[39mbase_df_for_inverse\u001b[39m.\u001b[39mindex)\n\u001b[1;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/CLUSTER/.clust/lib/python3.9/site-packages/pandas/core/frame.py:3966\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3965\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3966\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[1;32m   3967\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/.clust/lib/python3.9/site-packages/pandas/core/frame.py:4025\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   4024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4025\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_not_inplace(key, value)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/.clust/lib/python3.9/site-packages/pandas/core/frame.py:4044\u001b[0m, in \u001b[0;36mDataFrame._iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4042\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m   4043\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(value)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(key):\n\u001b[0;32m-> 4044\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4046\u001b[0m     \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[1;32m   4047\u001b[0m         \u001b[39mself\u001b[39m[col] \u001b[39m=\u001b[39m igetitem(value, i)\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# for regression\n",
    "if mode_selection == 'regression':\n",
    "    if scaler_param =='scale':\n",
    "        base_df_for_inverse = pd.DataFrame(columns=target, index=range(len(preds)))\n",
    "        base_df_for_inverse[target] = preds\n",
    "        prediction_result = pd.DataFrame(scaler_y.inverse_transform(base_df_for_inverse), columns=target, index=base_df_for_inverse.index)\n",
    "    else:\n",
    "        prediction_result = pd.DataFrame(data={\"value\": preds}, index=range(len(preds)))\n",
    "\n",
    "# for forecast\n",
    "elif mode_selection == 'forecast':\n",
    "    if scaler_param =='scale':\n",
    "        base_df_for_inverse = pd.DataFrame(columns=feature_list, index=range(len(preds)))\n",
    "        base_df_for_inverse[target] = preds\n",
    "        inverse_result = pd.DataFrame(scaler_X.inverse_transform(base_df_for_inverse), columns=feature_list, index=base_df_for_inverse.index)\n",
    "        target_data = inverse_result[target]\n",
    "        prediction_result = pd.DataFrame(data={target: target_data}, index=range(len(preds)))\n",
    "    else:\n",
    "        prediction_result = pd.DataFrame(data={target: preds}, index=range(len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e4125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.986181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value\n",
       "0  9.986181"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc660c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
