{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd79d0c3",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1611f6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kim-youngkee/Documents/CLUSTER/.clust/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "import setting\n",
    "\n",
    "from Clust.clust.ML.common.common import p1_integratedDataSaving as p1\n",
    "from Clust.clust.ML.tool import data as ml_data\n",
    "from Clust.clust.ML.tool import scaler as ml_scaler\n",
    "from Clust.clust.ML.tool import clean as ml_clean\n",
    "import pathSetting\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1788c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regression mode i.e., 'regression','forecast' \n",
    "mode_selection = \"forecast\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d30ae7",
   "metadata": {},
   "source": [
    "### 4-1. Get model meta by mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "db_name = 'model'\n",
    "collection_name = 'meta'\n",
    "\n",
    "all_model_meta = mongo_client.get_all_document(db_name, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae5b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = {'modelName': 'TestLSTM_rg'}\n",
    "model_meta= mongo_client.get_document_by_json(db_name, collection_name, search)\n",
    "model_meta = model_meta[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1f6bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainDataInfo': {'startTime': '2016-01-11',\n",
       "  'endTime': '2016-04-15',\n",
       "  'dataInfo': [['life_indoor_environment', 'humidityTrain_10min'],\n",
       "   ['life_indoor_environment', 'temperatureTrain_10min'],\n",
       "   ['weather_outdoor_environment', 'belgiumChieverseAirportTrain_10min']],\n",
       "  'processParam': {'refine_param': {'removeDuplication': {'flag': False},\n",
       "    'staticFrequency': {'flag': False, 'frequency': None}},\n",
       "   'outlier_param': {'certainErrorToNaN': {'flag': False},\n",
       "    'unCertainErrorToNaN': {'flag': False, 'param': {}}},\n",
       "   'imputation_param': {'flag': False,\n",
       "    'imputation_method': [],\n",
       "    'totalNonNanRatio': 80}},\n",
       "  'integration_freq_sec': 600,\n",
       "  'cleanParam': 'NoClean',\n",
       "  'DataSaveMode': 'influx'},\n",
       " 'modelName': 'TestLSTM_rg',\n",
       " 'featureList': ['RH_1',\n",
       "  'RH_2',\n",
       "  'RH_3',\n",
       "  'RH_4',\n",
       "  'RH_5',\n",
       "  'RH_6',\n",
       "  'RH_7',\n",
       "  'RH_8',\n",
       "  'RH_9',\n",
       "  'T1',\n",
       "  'T2',\n",
       "  'T3',\n",
       "  'T4',\n",
       "  'T5',\n",
       "  'T6',\n",
       "  'T7',\n",
       "  'T8',\n",
       "  'T9',\n",
       "  'Press_mm_hg',\n",
       "  'RH_out',\n",
       "  'T_out',\n",
       "  'Tdewpoint',\n",
       "  'Visibility',\n",
       "  'Windspeed'],\n",
       " 'target': ['value'],\n",
       " 'trainDataType': 'timeseries',\n",
       " 'modelPurpose': 'regression',\n",
       " 'model_method': 'LSTM_rg',\n",
       " 'modelTags': ['aaaaa'],\n",
       " 'cleanTrainDataParam': 'NoClean',\n",
       " 'NaNProcessingParam': {'feature_cycle': 'Day',\n",
       "  'feature_cycle_times': 1,\n",
       "  'NanInfoForCleanData': {'type': 'num',\n",
       "   'ConsecutiveNanLimit': 3,\n",
       "   'totalNaNLimit': 30000}},\n",
       " 'trainDataName': ['IntegraionTrainX', 'IntegraionTrainy'],\n",
       " 'trainParameter': {'lr': 0.0001,\n",
       "  'weight_decay': 1e-06,\n",
       "  'device': 'cpu',\n",
       "  'n_epochs': 10,\n",
       "  'batch_size': 16},\n",
       " 'modelParameter': {'rnn_type': 'lstm',\n",
       "  'input_size': 24,\n",
       "  'hidden_size': 64,\n",
       "  'num_layers': 2,\n",
       "  'output_dim': 1,\n",
       "  'dropout': 0.1,\n",
       "  'bidirectional': True},\n",
       " 'transformParameter': {},\n",
       " 'scalerParam': 'scale',\n",
       " 'files': {'modelFile': {'fileName': 'model.pth',\n",
       "   'filePath': './Models/LSTM_rg/TestLSTM_rg/IntegraionTrainX/d531eec11664669cff1f6a3ad9639012/model.pkl'},\n",
       "  'XScalerFile': {'fileName': 'scaler.pkl',\n",
       "   'filePath': './scaler/IntegraionTrainX/NoClean/minmax/44e77c5a60a148deb89c5ef9a221a365/scaler.pkl'},\n",
       "  'yScalerFile': {'fileName': 'scaler.pkl',\n",
       "   'filePath': './scaler/IntegraionTrainX/NoClean/minmax/f69156750a210491ffd4a67b605bc88b/scaler.pkl'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9185d9",
   "metadata": {},
   "source": [
    "### 4-2. Inference data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2579d539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0. pick only one data\n",
    "DataMeta = p1.read_json_data(pathSetting.DataMetaPath)\n",
    "dataList =  list(DataMeta.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ade136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IntegraionTrainX',\n",
       " 'IntegraionTrainy',\n",
       " 'IntegraionTestX',\n",
       " 'IntegraionTesty',\n",
       " 'trainClean_Hs1SwineFarmWithWeatherTime',\n",
       " 'trainNoClean_Hs1SwineFarmWithWeatherTime',\n",
       " 'testClean_Hs1SwineFarmWithWeatherTime',\n",
       " 'testNoClean_Hs1SwineFarmWithWeatherTime']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e11196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode_selection == 'regression':\n",
    "    # dataX\n",
    "    dataName_X = dataList[2]\n",
    "    dataSaveMode_X = DataMeta[dataName_X]['integrationInfo']['DataSaveMode']\n",
    "\n",
    "    dataFolderName = \"data_integrated_result\"\n",
    "    current = os.getcwd()\n",
    "    dataFolderPath = os.path.join(current, dataFolderName)\n",
    "\n",
    "    window_num =144\n",
    "    # dataX = ml_data.get_saved_integrated_data(dataSaveMode_X, dataName_X, dataFolderPath)[:window_num]\n",
    "    dataX = ml_data.get_saved_integrated_data('CSV', dataName_X, dataFolderPath)[:window_num]\n",
    "\n",
    "elif mode_selection == 'forecast':\n",
    "    LearningModeList = ['train', 'test']\n",
    "    LearningMode = LearningModeList[1]\n",
    "\n",
    "    cleanParamList = ['Clean', 'NoClean']\n",
    "    cleanMode = cleanParamList[1]\n",
    "\n",
    "    datasetNameList = ['Hs1SwineFarmWithWeatherTime', 'gunwiStrawberryWithWeatherTime', 'strawberryOpenTime']\n",
    "    datasetName = datasetNameList[0]\n",
    "\n",
    "    dataName_X = LearningMode + cleanMode + '_' + datasetName\n",
    "    dataSaveMode_X = DataMeta[dataName_X]['integrationInfo']['DataSaveMode']\n",
    "\n",
    "    dataX = ml_data.get_saved_integrated_data(dataSaveMode_X, dataName_X, pathSetting.dataFolderPath)\n",
    "    integration_freq_sec = DataMeta[dataName_X]['integrationInfo']['integration_freq_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef67904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                RH_1       RH_2       RH_3       RH_4  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  40.260000  43.200000  38.530000  37.363333   \n",
      "2021-01-01 00:10:00+00:00  40.260000  43.163333  38.500000  37.230000   \n",
      "2021-01-01 00:20:00+00:00  40.290000  42.963333  38.633333  37.200000   \n",
      "2021-01-01 00:30:00+00:00  40.290000  42.490000  38.790000  37.200000   \n",
      "2021-01-01 00:40:00+00:00  40.626667  42.156667  38.596667  37.090000   \n",
      "...                              ...        ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  41.500000  42.090000  38.290000  40.730000   \n",
      "2021-01-01 23:20:00+00:00  41.833333  42.290000  38.290000  40.790000   \n",
      "2021-01-01 23:30:00+00:00  42.090000  42.363333  38.290000  41.166667   \n",
      "2021-01-01 23:40:00+00:00  42.030000  42.433333  38.363333  42.093333   \n",
      "2021-01-01 23:50:00+00:00  41.900000  42.500000  38.290000  42.400000   \n",
      "\n",
      "                                RH_5       RH_6       RH_7       RH_8  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  48.126667  35.026667  32.863333  40.290000   \n",
      "2021-01-01 00:10:00+00:00  48.126667  38.763333  32.790000  40.163333   \n",
      "2021-01-01 00:20:00+00:00  48.060000  40.096667  32.663333  39.963333   \n",
      "2021-01-01 00:30:00+00:00  48.060000  41.633333  32.567500  39.900000   \n",
      "2021-01-01 00:40:00+00:00  48.060000  42.160000  32.433333  39.900000   \n",
      "...                              ...        ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  52.126667  36.666667  37.060000  40.700000   \n",
      "2021-01-01 23:20:00+00:00  51.863333  36.333333  37.126667  40.896667   \n",
      "2021-01-01 23:30:00+00:00  51.656667  34.633333  37.126667  41.623333   \n",
      "2021-01-01 23:40:00+00:00  51.560000  36.575000  37.200000  42.245000   \n",
      "2021-01-01 23:50:00+00:00  51.433333  37.526667  37.260000  42.590000   \n",
      "\n",
      "                                RH_9     T1  ...         T6         T7  \\\n",
      "datetime                                     ...                         \n",
      "2021-01-01 00:00:00+00:00  41.966667  22.60  ...  10.630000  21.390000   \n",
      "2021-01-01 00:10:00+00:00  41.766667  22.60  ...  10.233333  21.323333   \n",
      "2021-01-01 00:20:00+00:00  41.700000  22.60  ...   9.960000  21.290000   \n",
      "2021-01-01 00:30:00+00:00  41.700000  22.60  ...   9.763333  21.290000   \n",
      "2021-01-01 00:40:00+00:00  41.560000  22.70  ...   9.630000  21.230000   \n",
      "...                              ...    ...  ...        ...        ...   \n",
      "2021-01-01 23:10:00+00:00  42.200000  22.00  ...  14.756667  21.100000   \n",
      "2021-01-01 23:20:00+00:00  42.126667  22.00  ...  14.963333  21.100000   \n",
      "2021-01-01 23:30:00+00:00  42.200000  22.00  ...  14.763333  21.033333   \n",
      "2021-01-01 23:40:00+00:00  42.200000  22.00  ...  14.740000  21.066667   \n",
      "2021-01-01 23:50:00+00:00  42.230000  21.89  ...  15.030000  21.066667   \n",
      "\n",
      "                                  T8     T9  Press_mm_hg     RH_out  \\\n",
      "datetime                                                              \n",
      "2021-01-01 00:00:00+00:00  22.856667  19.79   757.000000  66.000000   \n",
      "2021-01-01 00:10:00+00:00  22.890000  19.79   757.116667  65.333333   \n",
      "2021-01-01 00:20:00+00:00  22.963333  19.79   757.233333  64.666667   \n",
      "2021-01-01 00:30:00+00:00  23.050000  19.79   757.350000  64.000000   \n",
      "2021-01-01 00:40:00+00:00  23.133333  19.76   757.466667  63.333333   \n",
      "...                              ...    ...          ...        ...   \n",
      "2021-01-01 23:10:00+00:00  22.700000  20.00   752.650000  73.500000   \n",
      "2021-01-01 23:20:00+00:00  22.700000  20.00   752.500000  73.000000   \n",
      "2021-01-01 23:30:00+00:00  22.760000  20.00   752.350000  72.500000   \n",
      "2021-01-01 23:40:00+00:00  22.840000  20.00   752.200000  72.000000   \n",
      "2021-01-01 23:50:00+00:00  23.000000  20.00   752.050000  71.500000   \n",
      "\n",
      "                               T_out  Tdewpoint  Visibility  Windspeed  \n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00  10.400000   4.200000        40.0   4.000000  \n",
      "2021-01-01 00:10:00+00:00  10.316667   4.000000        40.0   3.833333  \n",
      "2021-01-01 00:20:00+00:00  10.233333   3.800000        40.0   3.666667  \n",
      "2021-01-01 00:30:00+00:00  10.150000   3.600000        40.0   3.500000  \n",
      "2021-01-01 00:40:00+00:00  10.066667   3.400000        40.0   3.333333  \n",
      "...                              ...        ...         ...        ...  \n",
      "2021-01-01 23:10:00+00:00  12.950000   8.233333        40.0   7.666667  \n",
      "2021-01-01 23:20:00+00:00  13.100000   8.266667        40.0   7.333333  \n",
      "2021-01-01 23:30:00+00:00  13.250000   8.300000        40.0   7.000000  \n",
      "2021-01-01 23:40:00+00:00  13.400000   8.333333        40.0   6.666667  \n",
      "2021-01-01 23:50:00+00:00  13.550000   8.366667        40.0   6.333333  \n",
      "\n",
      "[144 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90644dc4",
   "metadata": {},
   "source": [
    "### 4-3. Inference data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba005fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = model_meta['featureList']\n",
    "target = model_meta['target']\n",
    "scaler_param = model_meta['scalerParam']\n",
    "model_file_path = model_meta['files']['modelFile']['filePath']\n",
    "model_method = model_meta['model_method']\n",
    "# train_parameter = model_meta[\"trainParameter\"]\n",
    "\n",
    "if mode_selection == 'regression':\n",
    "    # Scaling Inference Input\n",
    "    X_scaler_file_path = model_meta['files']['XScalerFile']['filePath']\n",
    "    y_scaler_file_path = model_meta['files']['yScalerFile']['filePath']\n",
    "\n",
    "    infer_X, scaler_X = ml_scaler.get_scaled_test_data(dataX[feature_list], X_scaler_file_path, scaler_param)\n",
    "    scaler_y = ml_scaler.get_scaler_file(y_scaler_file_path)\n",
    "\n",
    "elif mode_selection == 'forecast':\n",
    "    clean_param = model_meta['cleanTrainDataParam']\n",
    "    nan_processing_param = model_meta['NaNProcessingParam']\n",
    "\n",
    "    # only for forecast data?\n",
    "    # past_step = transform_param['past_step']\n",
    "    # feature_data = dataX[feature_list]\n",
    "    # step_data = feature_data[-past_step:][feature_list].values\n",
    "    # df_data = pd.DataFrame(step_data, columns=feature_list)\n",
    "\n",
    "    # Scaling Inference Input\n",
    "    X_scaler_file_path = model_meta['files']['XScalerFile']['filePath']\n",
    "    infer_X, scaler_X = ml_scaler.get_scaled_test_data(dataX[feature_list], X_scaler_file_path, scaler_param)\n",
    "    clean_infer_X = ml_clean.get_cleand_data(infer_X, clean_param, integration_freq_sec, nan_processing_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfa7250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (144, 24)\n",
      "                               RH_1      RH_2      RH_3      RH_4      RH_5  \\\n",
      "datetime                                                                      \n",
      "2021-01-01 00:00:00+00:00  0.364279  0.664944  0.456302  0.386490  0.275336   \n",
      "2021-01-01 00:10:00+00:00  0.364279  0.663872  0.454900  0.380531  0.275336   \n",
      "2021-01-01 00:20:00+00:00  0.365104  0.658023  0.461131  0.379190  0.274333   \n",
      "2021-01-01 00:30:00+00:00  0.365104  0.644180  0.468453  0.379190  0.274333   \n",
      "2021-01-01 00:40:00+00:00  0.374369  0.634432  0.459417  0.374274  0.274333   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  0.398404  0.632482  0.445085  0.536963  0.335480   \n",
      "2021-01-01 23:20:00+00:00  0.407577  0.638331  0.445085  0.539644  0.331521   \n",
      "2021-01-01 23:30:00+00:00  0.414641  0.640476  0.445085  0.556479  0.328413   \n",
      "2021-01-01 23:40:00+00:00  0.412990  0.642523  0.448512  0.597896  0.326960   \n",
      "2021-01-01 23:50:00+00:00  0.409412  0.644473  0.445085  0.611603  0.325055   \n",
      "\n",
      "                               RH_6      RH_7      RH_8      RH_9        T1  \\\n",
      "datetime                                                                      \n",
      "2021-01-01 00:00:00+00:00  0.344051  0.342671  0.366347  0.516115  0.613516   \n",
      "2021-01-01 00:10:00+00:00  0.381834  0.340071  0.362006  0.507596  0.613516   \n",
      "2021-01-01 00:20:00+00:00  0.395315  0.335579  0.355152  0.504756  0.613516   \n",
      "2021-01-01 00:30:00+00:00  0.410853  0.332181  0.352981  0.504756  0.613516   \n",
      "2021-01-01 00:40:00+00:00  0.416178  0.327423  0.352981  0.498793  0.624076   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  0.360634  0.491489  0.380398  0.526054  0.550158   \n",
      "2021-01-01 23:20:00+00:00  0.357263  0.493853  0.387137  0.522931  0.550158   \n",
      "2021-01-01 23:30:00+00:00  0.340074  0.493853  0.412040  0.526054  0.550158   \n",
      "2021-01-01 23:40:00+00:00  0.359707  0.496454  0.433345  0.526054  0.550158   \n",
      "2021-01-01 23:50:00+00:00  0.369329  0.498582  0.445168  0.527332  0.538543   \n",
      "\n",
      "                           ...        T6        T7        T8        T9  \\\n",
      "datetime                   ...                                           \n",
      "2021-01-01 00:00:00+00:00  ...  0.485955  0.565504  0.599634  0.509886   \n",
      "2021-01-01 00:10:00+00:00  ...  0.474409  0.559221  0.602685  0.509886   \n",
      "2021-01-01 00:20:00+00:00  ...  0.466453  0.556079  0.609399  0.509886   \n",
      "2021-01-01 00:30:00+00:00  ...  0.460729  0.556079  0.617333  0.509886   \n",
      "2021-01-01 00:40:00+00:00  ...  0.456848  0.550424  0.624962  0.506764   \n",
      "...                        ...       ...       ...       ...       ...   \n",
      "2021-01-01 23:10:00+00:00  ...  0.606074  0.538172  0.585291  0.531738   \n",
      "2021-01-01 23:20:00+00:00  ...  0.612089  0.538172  0.585291  0.531738   \n",
      "2021-01-01 23:30:00+00:00  ...  0.606268  0.531888  0.590784  0.531738   \n",
      "2021-01-01 23:40:00+00:00  ...  0.605589  0.535030  0.598108  0.531738   \n",
      "2021-01-01 23:50:00+00:00  ...  0.614030  0.535030  0.612756  0.531738   \n",
      "\n",
      "                           Press_mm_hg    RH_out     T_out  Tdewpoint  \\\n",
      "datetime                                                                \n",
      "2021-01-01 00:00:00+00:00     0.669082  0.552632  0.493548   0.488688   \n",
      "2021-01-01 00:10:00+00:00     0.671900  0.543860  0.490860   0.479638   \n",
      "2021-01-01 00:20:00+00:00     0.674718  0.535088  0.488172   0.470588   \n",
      "2021-01-01 00:30:00+00:00     0.677536  0.526316  0.485484   0.461538   \n",
      "2021-01-01 00:40:00+00:00     0.680354  0.517544  0.482796   0.452489   \n",
      "...                                ...       ...       ...        ...   \n",
      "2021-01-01 23:10:00+00:00     0.564010  0.651316  0.575806   0.671192   \n",
      "2021-01-01 23:20:00+00:00     0.560386  0.644737  0.580645   0.672700   \n",
      "2021-01-01 23:30:00+00:00     0.556763  0.638158  0.585484   0.674208   \n",
      "2021-01-01 23:40:00+00:00     0.553140  0.631579  0.590323   0.675716   \n",
      "2021-01-01 23:50:00+00:00     0.549517  0.625000  0.595161   0.677225   \n",
      "\n",
      "                           Visibility  Windspeed  \n",
      "datetime                                          \n",
      "2021-01-01 00:00:00+00:00    0.609375   0.307692  \n",
      "2021-01-01 00:10:00+00:00    0.609375   0.294872  \n",
      "2021-01-01 00:20:00+00:00    0.609375   0.282051  \n",
      "2021-01-01 00:30:00+00:00    0.609375   0.269231  \n",
      "2021-01-01 00:40:00+00:00    0.609375   0.256410  \n",
      "...                               ...        ...  \n",
      "2021-01-01 23:10:00+00:00    0.609375   0.589744  \n",
      "2021-01-01 23:20:00+00:00    0.609375   0.564103  \n",
      "2021-01-01 23:30:00+00:00    0.609375   0.538462  \n",
      "2021-01-01 23:40:00+00:00    0.609375   0.512821  \n",
      "2021-01-01 23:50:00+00:00    0.609375   0.487179  \n",
      "\n",
      "[144 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(type(clean_infer_X), clean_infer_X.shape)\n",
    "# print(clean_infer_X)\n",
    "print(type(infer_X), infer_X.shape)\n",
    "print(infer_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0775e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transDFtoNP_inf_yk(dfX, windowNum = 0, dim = None):\n",
    "    \"\"\"\n",
    "    Make NumpyArray by input DataFrame.\n",
    "    if windowNum = 0 ----> slice X by day\n",
    "    if windowNum = N ----> slice X by windowNum\n",
    "    \n",
    "    Example:\n",
    "        >>> Retunrn \n",
    "        ... X.shape (sampleNum, featureNum, sequenceNum )\n",
    "\n",
    "    Args:\n",
    "        dfX (DataFrame): dfX\n",
    "        windowNum (Interger): windowNum\n",
    "\n",
    "    Returns:\n",
    "        numpy array:  X\n",
    "    \n",
    "    \"\"\"\n",
    "    import datetime as dt\n",
    "    import numpy as np\n",
    "\n",
    "    if dim == 2:\n",
    "        X = dfX.to_numpy()\n",
    "    else:\n",
    "        X =[]\n",
    "\n",
    "        if windowNum ==0:\n",
    "            dateList = dfX.index.map(lambda t: t.date()).unique()\n",
    "            for startDate in dateList:\n",
    "                endDate  = dt.datetime.combine(startDate, dt.time(23, 59, 59, 59))\n",
    "                dfX_partial = dfX[startDate:endDate]\n",
    "                X_partial = dfX_partial.values\n",
    "                X.append (X_partial)\n",
    "        else:\n",
    "            import math\n",
    "            roundNum = math.ceil(len(dfX)/windowNum)\n",
    "            for i in range(roundNum): #This ensures all rows are captured\n",
    "                dfX_partial = dfX[i*windowNum:(i+1)*windowNum]\n",
    "                X_partial = dfX_partial.values\n",
    "                X.append (X_partial)\n",
    "\n",
    "        X = np.array(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb5966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gs/pbqr84y96p71g7j8lmqfh1r00000gn/T/ipykernel_46313/2120287005.py:31: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
      "  dfX_partial = dfX[startDate:endDate]\n"
     ]
    }
   ],
   "source": [
    "transformParameter = model_meta['transformParameter']\n",
    "# # transform\n",
    "if mode_selection == 'regression':\n",
    "\n",
    "    # from Clust.clust.transformation.type.DFToNPArray import transDFtoNP, trans_df_to_np, trans_df_to_np_inf\n",
    "    inferX = transDFtoNP_inf_yk(infer_X)\n",
    "\n",
    "# forecast\n",
    "elif mode_selection == 'forecast':\n",
    "    \n",
    "    from Clust.clust.transformation.purpose.machineLearning import LSTMData\n",
    "    LSTMD = LSTMData()\n",
    "    inferX, _ = LSTMD.transform_Xy_arr(clean_infer_X, transformParameter, transformParameter['clean_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c71050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1, 144, 24)\n",
      "[[[0.36427851 0.66494443 0.4563016  ... 0.48868778 0.609375   0.30769231]\n",
      "  [0.36427851 0.6638721  0.45489952 ... 0.47963801 0.609375   0.29487179]\n",
      "  [0.36510412 0.65802301 0.46113102 ... 0.47058824 0.609375   0.28205128]\n",
      "  ...\n",
      "  [0.41464086 0.64047573 0.4450849  ... 0.67420814 0.609375   0.53846154]\n",
      "  [0.41298963 0.64252291 0.44851223 ... 0.67571644 0.609375   0.51282051]\n",
      "  [0.40941198 0.64447261 0.4450849  ... 0.67722474 0.609375   0.48717949]]]\n"
     ]
    }
   ],
   "source": [
    "print(type(inferX), inferX.shape)\n",
    "print(inferX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb22200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParameter = model_meta[\"modelParameter\"]\n",
    "\n",
    "inferParameter = {\n",
    "    'device': 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb72fb20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference data shape: torch.Size([1, 144, 24])\n",
      "\n",
      "Start inference\n",
      "\n",
      "** Dimension of result for inference dataset = (1,)\n",
      "[0.22638921]\n"
     ]
    }
   ],
   "source": [
    "# 4. Inference\n",
    "from Clust.clust.ML.regression_YK.inference import RegressionInference as RI\n",
    "\n",
    "ri = RI()\n",
    "ri.set_param(inferParameter)\n",
    "ri.set_model(model_method, model_file_path, modelParameter)\n",
    "ri.set_data(inferX)\n",
    "preds = ri.inference()\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d92a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290a6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression\n",
    "if mode_selection == 'regression':\n",
    "    if scaler_param =='scale':\n",
    "        base_df_for_inverse = pd.DataFrame(columns=target, index=range(len(preds)))\n",
    "        base_df_for_inverse[target] = preds\n",
    "        prediction_result = pd.DataFrame(scaler_y.inverse_transform(base_df_for_inverse), columns=target, index=base_df_for_inverse.index)\n",
    "    else:\n",
    "        prediction_result = pd.DataFrame(data={\"value\": preds}, index=range(len(preds)))\n",
    "\n",
    "# for forecast\n",
    "elif mode_selection == 'forecast':\n",
    "    if scaler_param =='scale':\n",
    "        base_df_for_inverse = pd.DataFrame(columns=feature_list, index=range(len(preds)))\n",
    "        base_df_for_inverse[target] = preds\n",
    "        inverse_result = pd.DataFrame(scaler_X.inverse_transform(base_df_for_inverse), columns=feature_list, index=base_df_for_inverse.index)\n",
    "        target_data = inverse_result[target]\n",
    "        prediction_result = pd.DataFrame(data={target: target_data}, index=range(len(preds)))\n",
    "    else:\n",
    "        prediction_result = pd.DataFrame(data={target: preds}, index=range(len(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c7e4125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.08059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value\n",
       "0  10.08059"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc660c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e92cea83a25a22cd774ff9f8132db57ccb94d86fd97b7fe80ee00c35daecdd05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
