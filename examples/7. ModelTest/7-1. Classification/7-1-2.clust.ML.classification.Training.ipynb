{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43276846",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T03:21:52.373651Z",
     "start_time": "2022-08-23T03:21:48.164603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setting\n",
    "import pathSetting\n",
    "import torch\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from Clust.clust.transformation.type.DFToNPArray import transDFtoNP, trans_df_to_np, trans_df_to_np_inf\n",
    "from Clust.clust.ML.tool import data as ml_data\n",
    "from Clust.clust.ML.tool import model as ml_model\n",
    "from Clust.clust.ML.tool import clean as ml_clean\n",
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "\n",
    "import torch\n",
    "\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f2a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model methods i.e., 'LSTM_cf', 'GRU_cf', 'CNN_1D_cf', 'LSTM_FCNs_cf', 'FC_cf' \n",
    "model_method = 'LSTM_cf'\n",
    "\n",
    "# get integrated data name\n",
    "bucket_name = 'integration'\n",
    "\n",
    "# scaler path\n",
    "scalerPath = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a32132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification_actionPattern_testX_cleanLevel0',\n",
       " 'classification_actionPattern_testy_cleanLevel0',\n",
       " 'classification_actionPattern_trainX_cleanLevel0',\n",
       " 'classification_actionPattern_trainy_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel4',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel4',\n",
       " 'forecasting_gunwiStrawberryWeather_test_cleanLevel0',\n",
       " 'forecasting_gunwiStrawberryWeather_test_cleanLevel4',\n",
       " 'forecasting_gunwiStrawberryWeather_train_cleanLevel0',\n",
       " 'forecasting_gunwiStrawberryWeather_train_cleanLevel4',\n",
       " 'forecasting_strawberryOpen_test_cleanLevel0',\n",
       " 'forecasting_strawberryOpen_test_cleanLevel4',\n",
       " 'forecasting_strawberryOpen_train_cleanLevel0',\n",
       " 'forecasting_strawberryOpen_train_cleanLevel4',\n",
       " 'regression_energy_testX_cleanLevel0',\n",
       " 'regression_energy_testX_cleanLevel4',\n",
       " 'regression_energy_testy_cleanLevel0',\n",
       " 'regression_energy_testy_cleanLevel4',\n",
       " 'regression_energy_trainX_cleanLevel0',\n",
       " 'regression_energy_trainX_cleanLevel4',\n",
       " 'regression_energy_trainy_cleanLevel0',\n",
       " 'regression_energy_trainy_cleanLevel4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ms_list = db_client.measurement_list(bucket_name)\n",
    "get_ms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb204c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forecasting_strawberryOpen',\n",
       " 'regression_energy',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime',\n",
       " 'forecasting_gunwiStrawberryWeather',\n",
       " 'classification_actionPattern']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "collection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f00953",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_X = 'classification_actionPattern_trainX_cleanLevel0'\n",
    "dataX = db_client.get_data(bucket_name, data_name_X)\n",
    "\n",
    "# datay\n",
    "data_name_y = 'classification_actionPattern_trainy_cleanLevel0'\n",
    "datay = db_client.get_data(bucket_name, data_name_y)\n",
    "\n",
    "dataset_name = collection_list[4]\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'data_name':data_name_X})[0]\n",
    "clean_level = data_meta[\"clean_level\"]\n",
    "integration_freq_sec = data_meta[\"integration_param\"][\"integration_frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b7bc91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "# 2 Training Data Preparation\n",
    "# 2-1\n",
    "featureListX= list(dataX.columns)\n",
    "featureListy= list(datay.columns)\n",
    "\n",
    "# 2-2\n",
    "# cleanTrainDataParam = 'NoClean'#  Classification, Regression과 같이 X, y가 분리된 경우에는 현재 고정해서 사용해야함\n",
    "# cleanTrainDataParam = clean_level --> clean_level로 변경\n",
    "\n",
    "# 2-2-1 cleanTrainDataParam == Clean 일 경우\n",
    "NaNProcessingParam ={\n",
    "    \"feature_cycle\":'Day',\n",
    "    \"feature_cycle_times\":1,\n",
    "    \"NanInfoForCleanData\":{'type':'num', 'ConsecutiveNanLimit':3, 'totalNaNLimit':30000}\n",
    "}\n",
    "# 2-3\n",
    "scalerParam='scale'\n",
    "scaleMethod='minmax'\n",
    "\n",
    "# 2-4\n",
    "splitRatio = 0.8\n",
    "mode = 'Classification'\n",
    "\n",
    "# 2-5\n",
    "scalerRootPath_X = os.path.join(scalerPath, data_name_X, str(clean_level))\n",
    "scalerRootPath_y = os.path.join(scalerPath, data_name_y, str(clean_level))\n",
    "train_X, val_X, X_scalerFilePath = ml_data.get_train_val_data(dataX, featureListX, scalerRootPath_X, splitRatio, scalerParam, scaleMethod, mode)\n",
    "train_y, val_y, y_scalerFilePath = ml_data.get_train_val_data(datay, featureListy, scalerRootPath_y, splitRatio, \"NoScale\", scaleMethod, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6e8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_num = 0\n",
    "dim = 3\n",
    "\n",
    "if model_method == \"FC_cf\":\n",
    "    dim = 2\n",
    "\n",
    "if type(train_x) !=  np.ndarray:\n",
    "    train_x, train_y = transDFtoNP(train_x, train_y, window_num, dim)\n",
    "    val_x, val_y = transDFtoNP(val_x, val_y, window_num, dim)\n",
    "\n",
    "input_size = train_x.shape[1]\n",
    "if dim != 2:\n",
    "    seq_len = train_x.shape[2] # seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be503f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (5881, 9, 128)\n",
      "[[[0.48670847 0.49064098 0.49030017 ... 0.48618388 0.48654927 0.48725925]\n",
      "  [0.58418424 0.58238032 0.58339245 ... 0.57961972 0.58022402 0.58086851]\n",
      "  [0.58408219 0.58390294 0.58113932 ... 0.5623219  0.56221218 0.56029954]\n",
      "  ...\n",
      "  [0.55528389 0.55904341 0.55874125 ... 0.55739637 0.55774432 0.55841957]\n",
      "  [0.52112852 0.51982151 0.52084739 ... 0.52082385 0.52129699 0.52180391]\n",
      "  [0.59656275 0.59750528 0.59627805 ... 0.59569013 0.59551497 0.59384219]]\n",
      "\n",
      " [[0.48706899 0.48843397 0.48777409 ... 0.48480219 0.48547545 0.48600567]\n",
      "  [0.57752643 0.57632005 0.57591419 ... 0.57718512 0.57825884 0.57644752]\n",
      "  [0.55018704 0.5509113  0.55055067 ... 0.56110973 0.55922348 0.55983588]\n",
      "  ...\n",
      "  [0.55754876 0.55887337 0.55827319 ... 0.55602371 0.55666594 0.55717266]\n",
      "  [0.52085729 0.51984573 0.51949623 ... 0.51905306 0.51998268 0.51851992]\n",
      "  [0.59484945 0.59533603 0.59491252 ... 0.59334502 0.59180443 0.59234438]]\n",
      "\n",
      " [[0.48803162 0.48753947 0.48647128 ... 0.48712912 0.48786793 0.48749705]\n",
      "  [0.58146549 0.58085803 0.58031104 ... 0.57678974 0.57670193 0.57720132]\n",
      "  [0.55880061 0.55953085 0.56100971 ... 0.55652746 0.55628558 0.55597565]\n",
      "  ...\n",
      "  [0.55915376 0.55868645 0.5576715  ... 0.55837078 0.55908169 0.55873787]\n",
      "  [0.52227197 0.52174197 0.52126284 ... 0.51839261 0.51827323 0.51864019]\n",
      "  [0.59251704 0.59305074 0.59421069 ... 0.58974216 0.58951024 0.58922046]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.48620815 0.48552169 0.4855358  ... 0.4894044  0.48914991 0.48895676]\n",
      "  [0.58241331 0.58225709 0.5814335  ... 0.58121075 0.58095746 0.57896476]\n",
      "  [0.5613607  0.56142982 0.56322458 ... 0.55054277 0.54862045 0.55001019]\n",
      "  ...\n",
      "  [0.55706531 0.55641407 0.55642871 ... 0.56041794 0.56017884 0.5599983 ]\n",
      "  [0.50397049 0.5038545  0.50318658 ... 0.50713667 0.50691316 0.50524793]\n",
      "  [0.56519392 0.56525634 0.56675586 ... 0.55793335 0.55630748 0.55743621]]\n",
      "\n",
      " [[0.48727724 0.48731031 0.48792524 ... 0.48396764 0.48509593 0.48677032]\n",
      "  [0.58048524 0.58041682 0.58063923 ... 0.58257987 0.58448559 0.58147902]\n",
      "  [0.56287426 0.56097251 0.56014668 ... 0.56896437 0.56733235 0.56590522]\n",
      "  ...\n",
      "  [0.55815495 0.55818986 0.55877841 ... 0.55515627 0.55622077 0.557804  ]\n",
      "  [0.50528479 0.50529119 0.50553809 ... 0.50648514 0.50802835 0.50549905]\n",
      "  [0.5677181  0.56615933 0.56549548 ... 0.57203786 0.57073287 0.5696007 ]]\n",
      "\n",
      " [[0.48804539 0.4872786  0.48801205 ... 0.48746264 0.48719498 0.48766972]\n",
      "  [0.57599185 0.57405509 0.57562544 ... 0.58115237 0.58238083 0.58256438]\n",
      "  [0.55339163 0.55637149 0.55898017 ... 0.56354668 0.56323294 0.56060955]\n",
      "  ...\n",
      "  [0.55913537 0.55840982 0.55911097 ... 0.55812417 0.55787419 0.55833024]\n",
      "  [0.50277056 0.50115284 0.50244346 ... 0.50392291 0.50493911 0.5050895 ]\n",
      "  [0.56022017 0.5626669  0.56480175 ... 0.57021234 0.56992028 0.56770409]]]\n"
     ]
    }
   ],
   "source": [
    "print(type(train_x), train_x.shape)\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b86cd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "if model_method == 'LSTM_cf' or model_method == 'GRU_cf':\n",
    "    modelParameter = {\n",
    "        'input_size': input_size,\n",
    "        'seq_len': seq_len,\n",
    "        'num_classes': 6,\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True  # 모델의 양방향성 여부, bool(default: True)   \n",
    "    }\n",
    "    if model_method == 'LSTM_cf':\n",
    "        modelParameter['rnn_type'] = 'lstm'\n",
    "    else:\n",
    "        modelParameter['rnn_type'] = 'gru'\n",
    "        \n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "    'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "    'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "    'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "    'drop_out': 0.1 # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "    'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "    'fc_drop_out': 0.1 # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# FC model parameters\n",
    "elif model_method == 'FC_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_classes': 6,\n",
    "    'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    'bias': True# bias 사용 여부, bool(default: True)\n",
    "    }\n",
    "\n",
    "trainParameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 5, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2e173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4d790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9c159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b53117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a8d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConfig={\n",
    "    \"LSTM_cf\":{# Case 1. LSTM model (w/o data representation)\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)   \n",
    "        \"lr\":0.0001\n",
    "    },\n",
    "    \"GRU_cf\":{# Case 2. GRU model (w/o data representation)\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "        \"lr\":0.0001\n",
    "        \n",
    "    },\n",
    "    \"CNN_1D_cf\":{# Case 3. CNN_1D model (w/o data representation)\n",
    "        'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "        'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "        'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "        'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "        'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        \"lr\":0.0001\n",
    "    },\n",
    "    \"LSTM_FCNs_cf\":{#Case 4. LSTM_FCNs model (w/o data representation)\n",
    "        'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "        'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "        'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        \"lr\":0.0001\n",
    "    },\n",
    "    \"FC_cf\":{# Case 5. fully-connected layers (w/ data representation)\n",
    "        'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bias': True,# bias 사용 여부, bool(default: True)\n",
    "        \"lr\":0.0001}  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\"LSTM_cf\",\"GRU_cf\", \"CNN_1D_cf\",\"LSTM_FCNs_cf\"]\n",
    "model_method = model_list[0]\n",
    "\n",
    "n_epochs = 2 # 학습 epoch 횟수, int(default: 1000, 범위: 1 이상)\n",
    "batch_size = 16  # batch 크기, int(default: 16, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "num_classes = 6 # class 개수\n",
    "#targetNames = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5'] ## result_metrics_df 에서 target 이름 설정.... Inference 에서 힘들음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95763e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainParameter = modelConfig[model_method]\n",
    "trainParameter['device']  = device\n",
    "trainParameter['n_epochs'] = n_epochs\n",
    "trainParameter['num_classes'] = num_classes\n",
    "trainParameter['batch_size'] = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_num=0\n",
    "\n",
    "dim = 3\n",
    "if model_method == \"FC_cf\":\n",
    "    dim = 2\n",
    "if type(train_x) !=  np.ndarray:\n",
    "    train_x, train_y = transDFtoNP(train_x, train_y, window_num, dim)\n",
    "    val_x, val_y = transDFtoNP(val_x, val_y, window_num, dim)\n",
    "\n",
    "trainParameter['input_size'] = train_x.shape[1]\n",
    "if dim != 2:\n",
    "    trainParameter['seq_len']  = train_x.shape[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d6236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T04:01:15.866029Z",
     "start_time": "2022-08-23T03:56:24.865168Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelTags =[\"action\", \"sensor\", \"classification\", \"pattern\"]\n",
    "trainDataType = \"timeseries\"\n",
    "modelPurpose = \"classification\"\n",
    "\n",
    "# 2\n",
    "trainDataInfo = DataMeta[dataName_X]['integrationInfo']\n",
    "\n",
    "# model_name = 'New_ClassificationNocleanLSTM_cf'\n",
    "model_name = 'test_meta_classification'\n",
    "\n",
    "# 3. 모델을 저장할 파일 패스를 생성한다.\n",
    "from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "trainParameter_encode =  encode_hash_style(str(trainParameter))\n",
    "# trainDataPathList = [\"ActionClassificationLSTMCF\", dataName_X, trainParameter_encode]\n",
    "trainDataPathList = [model_name, dataName_X, trainParameter_encode]\n",
    "# trainDataPathList = [model_name]\n",
    "modelFilePath = ml_model.get_model_file_path(trainDataPathList, model_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training\n",
    "from Clust.clust.ML.classification.train import ClassificationTrain as CTrain\n",
    "ctrain = CTrain()\n",
    "ctrain.set_param(trainParameter)\n",
    "ctrain.set_model(model_method)\n",
    "ctrain.set_data(train_x, train_y, val_x, val_y)\n",
    "ctrain.train()\n",
    "ctrain.save_best_model(modelFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c50144",
   "metadata": {},
   "source": [
    "## Model Meta Save - mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ingestion.mongo import mongo_client\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "\n",
    "mongo_client = mongo_client.MongoClient(ins.CLUSTMetaInfo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = modelConfig[model_method]\n",
    "train_meta['device']  = device\n",
    "train_meta['n_epochs'] = n_epochs\n",
    "train_meta['num_classes'] = num_classes\n",
    "train_meta['batch_size'] = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    \"trainDataInfo\": trainDataInfo,\n",
    "    \"featureList\": featureListX,\n",
    "    \"target\": featureListy,\n",
    "    \"trainDataType\": trainDataType,\n",
    "    \"modelPurpose\": modelPurpose,\n",
    "    \"model_method\": model_method,\n",
    "    \"modelTags\": modelTags,\n",
    "    \"trainDataName\": [dataName_X,dataName_y],\n",
    "    \"cleanTrainDataParam\":cleanTrainDataParam,\n",
    "    \"NaNProcessingParam\":NaNProcessingParam,\n",
    "    \"scalerParam\": scalerParam,\n",
    "    \"files\":{\n",
    "            \"modelFile\":{\n",
    "                    \"fileName\":\"model.pth\",\n",
    "                    \"filePath\":modelFilePath\n",
    "                },\n",
    "            \"XScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":X_scalerFilePath       \n",
    "                },\n",
    "            \"yScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":y_scalerFilePath       \n",
    "                }\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce953a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a434778",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_info_meta = {\n",
    "    \"model_name\": model_name,\n",
    "    \"model_meta\": model_meta,\n",
    "    \"train_meta\": trainParameter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_meta.save_model_meta_data(mongo_client, ml_info_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c598ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_info_meta[\"model_meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_info_meta[\"train_meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd04cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f1ef7e1f828dbb4e75f421045d2c565197efaf8469a0be4a314c6ea8378b5cb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
