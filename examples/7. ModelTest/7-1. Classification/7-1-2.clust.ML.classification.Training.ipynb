{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43276846",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T03:21:52.373651Z",
     "start_time": "2022-08-23T03:21:48.164603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import setting\n",
    "import pathSetting\n",
    "import torch\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "from Clust.clust.transformation.type.DFToNPArray import transDFtoNP, trans_df_to_np, trans_df_to_np_inf\n",
    "from Clust.clust.ML.tool import data as ml_data\n",
    "from Clust.clust.ML.tool import model as ml_model\n",
    "from Clust.clust.ML.tool import clean as ml_clean\n",
    "from Clust.clust.ML.tool import meta as ml_meta\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "\n",
    "import torch\n",
    "\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8729e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model methods i.e., 'LSTM_cf', 'GRU_cf', 'CNN_1D_cf', 'LSTM_FCNs_cf', 'FC_cf' \n",
    "model_method = 'LSTM_cf'\n",
    "\n",
    "# get integrated data name\n",
    "bucket_name = 'integration'\n",
    "\n",
    "# scaler path\n",
    "scalerPath = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4967f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification_actionPattern_testX_cleanLevel0',\n",
       " 'classification_actionPattern_testy_cleanLevel0',\n",
       " 'classification_actionPattern_trainX_cleanLevel0',\n",
       " 'classification_actionPattern_trainy_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_test_cleanLevel4',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel0',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime_train_cleanLevel4',\n",
       " 'forecasting_gunwiStrawberryWeather_test_cleanLevel0',\n",
       " 'forecasting_gunwiStrawberryWeather_test_cleanLevel4',\n",
       " 'forecasting_gunwiStrawberryWeather_train_cleanLevel0',\n",
       " 'forecasting_gunwiStrawberryWeather_train_cleanLevel4',\n",
       " 'forecasting_strawberryOpen_test_cleanLevel0',\n",
       " 'forecasting_strawberryOpen_test_cleanLevel4',\n",
       " 'forecasting_strawberryOpen_train_cleanLevel0',\n",
       " 'forecasting_strawberryOpen_train_cleanLevel4',\n",
       " 'regression_energy_testX_cleanLevel0',\n",
       " 'regression_energy_testX_cleanLevel4',\n",
       " 'regression_energy_testy_cleanLevel0',\n",
       " 'regression_energy_testy_cleanLevel4',\n",
       " 'regression_energy_trainX_cleanLevel0',\n",
       " 'regression_energy_trainX_cleanLevel4',\n",
       " 'regression_energy_trainy_cleanLevel0',\n",
       " 'regression_energy_trainy_cleanLevel4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ms_list = db_client.measurement_list(bucket_name)\n",
    "get_ms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc33c68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forecasting_strawberryOpen',\n",
       " 'regression_energy',\n",
       " 'forecasting_Hs2SwineFarmWithWeatherTime',\n",
       " 'forecasting_gunwiStrawberryWeather',\n",
       " 'classification_actionPattern']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "collection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2531f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_X = 'classification_actionPattern_trainX_cleanLevel0'\n",
    "dataX = db_client.get_data(bucket_name, data_name_X)\n",
    "\n",
    "# datay\n",
    "data_name_y = 'classification_actionPattern_trainy_cleanLevel0'\n",
    "datay = db_client.get_data(bucket_name, data_name_y)\n",
    "\n",
    "dataset_name = collection_list[4]\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'data_name':data_name_X})[0]\n",
    "clean_level = data_meta[\"clean_level\"]\n",
    "integration_freq_sec = data_meta[\"integration_param\"][\"integration_frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0bca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "# 2 Training Data Preparation\n",
    "# 2-1\n",
    "featureListX= list(dataX.columns)\n",
    "featureListy= list(datay.columns)\n",
    "\n",
    "# 2-2\n",
    "# cleanTrainDataParam = 'NoClean'#  Classification, Regression과 같이 X, y가 분리된 경우에는 현재 고정해서 사용해야함\n",
    "# cleanTrainDataParam = clean_level --> clean_level로 변경\n",
    "\n",
    "# 2-2-1 cleanTrainDataParam == Clean 일 경우\n",
    "NaNProcessingParam ={\n",
    "    \"feature_cycle\":'Day',\n",
    "    \"feature_cycle_times\":1,\n",
    "    \"NanInfoForCleanData\":{'type':'num', 'ConsecutiveNanLimit':3, 'totalNaNLimit':30000}\n",
    "}\n",
    "# 2-3\n",
    "scalerParam='scale'\n",
    "scaleMethod='minmax'\n",
    "\n",
    "# 2-4\n",
    "splitRatio = 0.8\n",
    "mode = 'Classification'\n",
    "\n",
    "# 2-5\n",
    "scalerRootPath_X = os.path.join(scalerPath, data_name_X, str(clean_level))\n",
    "scalerRootPath_y = os.path.join(scalerPath, data_name_y, str(clean_level))\n",
    "train_X, val_X, X_scalerFilePath = ml_data.get_train_val_data(dataX, featureListX, scalerRootPath_X, splitRatio, scalerParam, scaleMethod, mode)\n",
    "train_y, val_y, y_scalerFilePath = ml_data.get_train_val_data(datay, featureListy, scalerRootPath_y, splitRatio, \"NoScale\", scaleMethod, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b971b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../../Clust/clust/transformation/type/DFToNPArray.py:38: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
      "  dfX_partial = dfX[startDate:endDate]\n",
      "../../../../Clust/clust/transformation/type/DFToNPArray.py:39: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version.  Use a timezone-aware object instead.\n",
      "  dfy_partial = dfy[startDate:endDate]\n"
     ]
    }
   ],
   "source": [
    "window_num = 0\n",
    "dim = 3\n",
    "\n",
    "if model_method == \"FC_cf\":\n",
    "    dim = 2\n",
    "\n",
    "if type(train_X) !=  np.ndarray:\n",
    "    train_X, train_y = transDFtoNP(train_X, train_y, window_num, dim)\n",
    "    val_X, val_y = transDFtoNP(val_X, val_y, window_num, dim)\n",
    "\n",
    "input_size = train_X.shape[1]\n",
    "if dim != 2:\n",
    "    seq_len = train_X.shape[2] # seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58949b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (5881, 9, 128)\n",
      "[[[0.48670847 0.49064098 0.49030017 ... 0.48618388 0.48654927 0.48725925]\n",
      "  [0.58418424 0.58238032 0.58339245 ... 0.57961972 0.58022402 0.58086851]\n",
      "  [0.58408219 0.58390294 0.58113932 ... 0.5623219  0.56221218 0.56029954]\n",
      "  ...\n",
      "  [0.55528389 0.55904341 0.55874125 ... 0.55739637 0.55774432 0.55841957]\n",
      "  [0.52112852 0.51982151 0.52084739 ... 0.52082385 0.52129699 0.52180391]\n",
      "  [0.59656275 0.59750528 0.59627805 ... 0.59569013 0.59551497 0.59384219]]\n",
      "\n",
      " [[0.48706899 0.48843397 0.48777409 ... 0.48480219 0.48547545 0.48600567]\n",
      "  [0.57752643 0.57632005 0.57591419 ... 0.57718512 0.57825884 0.57644752]\n",
      "  [0.55018704 0.5509113  0.55055067 ... 0.56110973 0.55922348 0.55983588]\n",
      "  ...\n",
      "  [0.55754876 0.55887337 0.55827319 ... 0.55602371 0.55666594 0.55717266]\n",
      "  [0.52085729 0.51984573 0.51949623 ... 0.51905306 0.51998268 0.51851992]\n",
      "  [0.59484945 0.59533603 0.59491252 ... 0.59334502 0.59180443 0.59234438]]\n",
      "\n",
      " [[0.48803162 0.48753947 0.48647128 ... 0.48712912 0.48786793 0.48749705]\n",
      "  [0.58146549 0.58085803 0.58031104 ... 0.57678974 0.57670193 0.57720132]\n",
      "  [0.55880061 0.55953085 0.56100971 ... 0.55652746 0.55628558 0.55597565]\n",
      "  ...\n",
      "  [0.55915376 0.55868645 0.5576715  ... 0.55837078 0.55908169 0.55873787]\n",
      "  [0.52227197 0.52174197 0.52126284 ... 0.51839261 0.51827323 0.51864019]\n",
      "  [0.59251704 0.59305074 0.59421069 ... 0.58974216 0.58951024 0.58922046]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.48620815 0.48552169 0.4855358  ... 0.4894044  0.48914991 0.48895676]\n",
      "  [0.58241331 0.58225709 0.5814335  ... 0.58121075 0.58095746 0.57896476]\n",
      "  [0.5613607  0.56142982 0.56322458 ... 0.55054277 0.54862045 0.55001019]\n",
      "  ...\n",
      "  [0.55706531 0.55641407 0.55642871 ... 0.56041794 0.56017884 0.5599983 ]\n",
      "  [0.50397049 0.5038545  0.50318658 ... 0.50713667 0.50691316 0.50524793]\n",
      "  [0.56519392 0.56525634 0.56675586 ... 0.55793335 0.55630748 0.55743621]]\n",
      "\n",
      " [[0.48727724 0.48731031 0.48792524 ... 0.48396764 0.48509593 0.48677032]\n",
      "  [0.58048524 0.58041682 0.58063923 ... 0.58257987 0.58448559 0.58147902]\n",
      "  [0.56287426 0.56097251 0.56014668 ... 0.56896437 0.56733235 0.56590522]\n",
      "  ...\n",
      "  [0.55815495 0.55818986 0.55877841 ... 0.55515627 0.55622077 0.557804  ]\n",
      "  [0.50528479 0.50529119 0.50553809 ... 0.50648514 0.50802835 0.50549905]\n",
      "  [0.5677181  0.56615933 0.56549548 ... 0.57203786 0.57073287 0.5696007 ]]\n",
      "\n",
      " [[0.48804539 0.4872786  0.48801205 ... 0.48746264 0.48719498 0.48766972]\n",
      "  [0.57599185 0.57405509 0.57562544 ... 0.58115237 0.58238083 0.58256438]\n",
      "  [0.55339163 0.55637149 0.55898017 ... 0.56354668 0.56323294 0.56060955]\n",
      "  ...\n",
      "  [0.55913537 0.55840982 0.55911097 ... 0.55812417 0.55787419 0.55833024]\n",
      "  [0.50277056 0.50115284 0.50244346 ... 0.50392291 0.50493911 0.5050895 ]\n",
      "  [0.56022017 0.5626669  0.56480175 ... 0.57021234 0.56992028 0.56770409]]]\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X), train_X.shape)\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c95224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "if model_method == 'LSTM_cf' or model_method == 'GRU_cf':\n",
    "    modelParameter = {\n",
    "        'input_size': input_size,\n",
    "        'seq_len': seq_len,\n",
    "        'num_classes': 6,\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True  # 모델의 양방향성 여부, bool(default: True)   \n",
    "    }\n",
    "    if model_method == 'LSTM_cf':\n",
    "        modelParameter['rnn_type'] = 'lstm'\n",
    "    else:\n",
    "        modelParameter['rnn_type'] = 'gru'\n",
    "        \n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "    'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "    'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "    'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "    'drop_out': 0.1 # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "    'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "    'fc_drop_out': 0.1 # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# FC model parameters\n",
    "elif model_method == 'FC_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_classes': 6,\n",
    "    'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    'bias': True# bias 사용 여부, bool(default: True)\n",
    "    }\n",
    "\n",
    "trainParameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 5, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76967ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_actionPattern_LSTM_cf_cleanLevel0\n",
      "./Models/LSTM_cf/classification_actionPattern_LSTM_cf_cleanLevel0/classification_actionPattern_trainX_cleanLevel0/035b06e2d9df4a58aa1dd8622746dd1f/model.pkl\n"
     ]
    }
   ],
   "source": [
    "modelTags =[\"action\", \"sensor\", \"classification\", \"pattern\"]\n",
    "trainDataType = \"timeseries\"\n",
    "modelPurpose = \"classification\"\n",
    "\n",
    "# # 2\n",
    "trainDataInfo = data_meta\n",
    "\n",
    "# 3. 모델을 저장할 파일 패스를 생성한다.\n",
    "model_name = None\n",
    "if model_name is None:\n",
    "    model_name = dataset_name + '_' + model_method + '_cleanLevel' + str(clean_level)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(model_name)\n",
    "\n",
    "from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "trainParameter_encode =  encode_hash_style(str(trainParameter))\n",
    "trainDataPathList = [model_name, data_name_X, trainParameter_encode]\n",
    "modelFilePath = ml_model.get_model_file_path(trainDataPathList, model_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d2e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "=================================11111111111111111111111111111111111111111111\n",
      "cpu\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-07ffbd4b5cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/classification_model/rnn_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_params, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0;31m# input을 model에 넣어 output을 도출한 후, loss를 계산함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/models/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# initial hidden states 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_directions\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 선택한 rnn_type의 RNN으로부터 output 도출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from Clust.clust.ML.classification.train import ClassificationTrain as CML\n",
    "\n",
    "cml = CML()\n",
    "cml.set_param(trainParameter)\n",
    "cml.set_model(model_method, modelParameter)\n",
    "cml.set_data(train_X, train_y, val_X, val_y)\n",
    "cml.train()\n",
    "cml.save_best_model(modelFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    \"trainDataInfo\": trainDataInfo,\n",
    "    \"featureList\": featureListX,\n",
    "    \"target\": featureListy,\n",
    "    \"trainDataType\": trainDataType,\n",
    "    \"modelPurpose\": modelPurpose,\n",
    "    \"model_method\": model_method,\n",
    "    \"modelTags\": modelTags,\n",
    "    \"trainDataName\": [data_name_X,data_name_y],\n",
    "    \"cleanTrainDataParam\":cleanTrainDataParam,\n",
    "    \"NaNProcessingParam\":NaNProcessingParam,\n",
    "    \"scalerParam\": scalerParam,\n",
    "    \"trainParameter\": trainParameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \n",
    "    \"files\":{\n",
    "            \"modelFile\":{\n",
    "                    \"fileName\":\"model.pth\",\n",
    "                    \"filePath\":modelFilePath\n",
    "                },\n",
    "            \"XScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":X_scalerFilePath       \n",
    "                },\n",
    "            \"yScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":y_scalerFilePath       \n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "modelInfoMeta = ml_meta.save_model_meta_data(mongo_client, model_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a987601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bae6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f1ef7e1f828dbb4e75f421045d2c565197efaf8469a0be4a314c6ea8378b5cb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
