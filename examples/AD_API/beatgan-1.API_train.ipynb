{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n",
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as iC\n",
    "from Clust.clust.ingestion.mongo import mongo_client\n",
    "from Clust.clust.ML.common import AD_api\n",
    "from Clust.clust.ML.tool import meta\n",
    "\n",
    "influxdb_client = iC.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongodb_client = mongo_client.MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. set param from Front End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatgan_ad_model_info = {\n",
    "    'in_c': 51,     # the number of feature\n",
    "    'hidden_c': 32,\n",
    "    'latent_c': 16\n",
    "}\n",
    "\n",
    "train_parameter = {\n",
    "    'lr': 0.0001,\n",
    "    'n_epochs': 1,\n",
    "    'input_size': 51,\n",
    "    'batch_size': 32,\n",
    "    'device': 'cpu',\n",
    "}\n",
    "\n",
    "# To be replaced\n",
    "params1 = {\n",
    "    'ingestion_param_X': {\n",
    "        'bucket_name': 'local',\n",
    "        'ms_name': 'anomaly_detection_SWaT',\n",
    "        'feature_list': ['FIT101', 'LIT101', 'MV101', 'P101', 'P102', 'AIT201', 'AIT202', 'AIT203', \n",
    "                         'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206', \n",
    "                         'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'MV303', 'MV304', \n",
    "                         'P301', 'P302', 'AIT401', 'AIT402', 'FIT401', 'LIT401', 'P401', 'P402','P403', 'P404', \n",
    "                         'UV401', 'AIT501', 'AIT502', 'AIT503', 'AIT504',\n",
    "                         'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502',\n",
    "                         'PIT503', 'FIT601', 'P601', 'P602', 'P603']\n",
    "    },\n",
    "    'ingestion_param_y': {\n",
    "        'bucket_name': 'local',\n",
    "        'ms_name': 'anomaly_detection_SWaT',\n",
    "        'feature_list': ['attack']\n",
    "    },\n",
    "    'data_y_flag': 'true',\n",
    "    'scaler_param':{\n",
    "        'scaler_flag': 'none',\n",
    "        'scale_method': 'none',\n",
    "        'sclaer_path': 'none'\n",
    "    },\n",
    "    'transform_param': {\n",
    "        'split_mode': 'none',\n",
    "        'data_clean_option': 'none'\n",
    "    },\n",
    "    'model_info': {\n",
    "        'model_purpose': 'anomaly_detection',\n",
    "        'model_method': 'BeatGAN_ad',\n",
    "        'model_name': 'None',\n",
    "        'model_tags': 'tagstest',\n",
    "        'train_parameter': train_parameter,\n",
    "        'model_parameter': beatgan_ad_model_info\n",
    "    }\n",
    "}\n",
    "\n",
    "# params1 = {\n",
    "#     \"ingestion_param_X\" :{\n",
    "#         \"bucket_name\": 'integration',\n",
    "#         \"ms_name\" : 'regression_energy_cleanLevel4_trainX',\n",
    "#         \"feature_list\":['Press_mm_hg', 'RH_1', 'RH_2', 'RH_3', 'RH_4', 'RH_5', 'RH_6', 'RH_7',\n",
    "#        'RH_8', 'RH_9', 'RH_out', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7',\n",
    "#        'T8', 'T9', 'T_out', 'Tdewpoint', 'Visibility', 'Windspeed']\n",
    "#     },\n",
    "#     \"ingestion_param_y\":{\n",
    "#         \"bucket_name\": 'integration',\n",
    "#         \"ms_name\" : 'regression_energy_cleanLevel4_trainy',\n",
    "#         \"feature_list\":[\"value\"]\n",
    "#     },\n",
    "#     'data_y_flag' : 'true',\n",
    "#     'scaler_param':{\n",
    "#         'scaler_flag':'scale', #scale_param,\n",
    "#         'scale_method' :'minmax',\n",
    "#         'scaler_path' :'./scaler/'\n",
    "#     },\n",
    "#     \"transform_param\":{\n",
    "#         'split_mode' : 'window_split', # 현재 data_y_flag=Ture --> 모두 window_split # data_y = False --> step_split\n",
    "#         #step_split일 경우만 past_step과 future_step이 존재\n",
    "#         'data_clean_option' : \"false\"\n",
    "#     },\n",
    "    \n",
    "#     \"model_info\" :{\n",
    "#         'model_purpose' : 'regression',\n",
    "#         'model_method' : 'GRU_rg',   # 'GRU_rg', 'LSTM_rg', 'CNN_1D_rg', 'LSTM_FCNs_rg'\n",
    "#         'model_name' : 'None',\n",
    "#         'model_tags' : 'tagstest',\n",
    "#         'train_parameter' : {\"lr\":0.0001,\"weight_decay\":0.000001,\"n_epochs\":5,\"batch_size\":16},\n",
    "#         'model_parameter' : GRU_rg_model_info\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Backend Parameter Setting\n",
    "params = params1\n",
    "\n",
    "# parameter tunning\n",
    "params = AD_api.convert_param_for_backend(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data preparation\n",
    "def pre_test_df(test_df):\n",
    "    test_df['attack'] = test_df['attack'].apply(lambda x : 1 if x > 0 else 0)\n",
    "    split_index = int(len(test_df) * 0.5)\n",
    "    \n",
    "    valid_x = test_df.iloc[:split_index,:].drop(columns=['timestamp','attack'])\n",
    "    valid_y = test_df.iloc[:split_index,:]['attack']\n",
    "\n",
    "    test_x = test_df.iloc[split_index:,:].drop(columns=['timestamp','attack'])\n",
    "    test_y = test_df.iloc[split_index:,:]['attack']\n",
    "    \n",
    "    return valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Preparation\n",
    "# train_X_array, train_y_array, val_X_array, val_y_array = AD_api.train_data_preparation(params, influxdb_client)\n",
    "\n",
    "# 추후 ML_api 의 데이터 준비 형식으로 대체 가능\n",
    "import pandas as pd\n",
    "\n",
    "# from train.csv\n",
    "df = pd.read_csv('./data/train_ver2.csv')\n",
    "train_X, train_y = df.drop(columns=['timestamp', 'attack']), df['attack']\n",
    "\n",
    "# from test.csv\n",
    "# 보통 train set 에서 train/val 나누지 않는지?\n",
    "test_df = pd.read_csv('./data/test_ver2.csv')\n",
    "val_X, val_y, test_X, test_y = pre_test_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(49680, 51)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X))\n",
    "print(train_X.shape)  # TBD: [seq_len, n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data_param_X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 3. Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m params \u001b[39m=\u001b[39m AD_api\u001b[39m.\u001b[39;49mAD_train(params, train_X, train_y, val_X, val_y)\n",
      "File \u001b[0;32m~/Documents/CLUSTER/Clust/examples/AD_API/../../../Clust/clust/ML/common/AD_api.py:137\u001b[0m, in \u001b[0;36mAD_train\u001b[0;34m(params, train_X, train_y, val_X, val_y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mClust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclust\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mML\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtool\u001b[39;00m \u001b[39mimport\u001b[39;00m model \u001b[39mas\u001b[39;00m ml_model\n\u001b[1;32m    136\u001b[0m \u001b[39m# train_data_path_list = [params['model_info']['model_name'], params['ingestion_param_X']['ms_name']]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m train_data_path_list \u001b[39m=\u001b[39m [params[\u001b[39m'\u001b[39m\u001b[39mmodel_info\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m], params[\u001b[39m'\u001b[39;49m\u001b[39mdata_param_X\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m    138\u001b[0m model_file_path \u001b[39m=\u001b[39m ml_model\u001b[39m.\u001b[39mget_model_file_path(train_data_path_list, params[\u001b[39m'\u001b[39m\u001b[39mmodel_info\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel_method\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    140\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mmodel_info\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel_file_path\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m {\n\u001b[1;32m    141\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodelFile\u001b[39m\u001b[39m'\u001b[39m:{\n\u001b[1;32m    142\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfileName\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmodel.pth\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    143\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfilePath\u001b[39m\u001b[39m'\u001b[39m: model_file_path\n\u001b[1;32m    144\u001b[0m     }\n\u001b[1;32m    145\u001b[0m }\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_param_X'"
     ]
    }
   ],
   "source": [
    "# 3. Training\n",
    "params = AD_api.AD_train(params, train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_param_X': {'name': 'SWaT', 'train_path': './data/train_ver2.csv', 'test_path': './data/test_ver2.csv'}, 'model_info': {'model_purpose': 'anomaly_detection', 'model_method': 'beatgan_ad', 'model_name': 'None', 'model_tags': 'tagstest', 'train_parameter': {'lr': 0.0001, 'n_epochs': 5, 'input_size': 51, 'batch_size': 32, 'device': 'cpu'}, 'model_parameter': {'in_c': 51, 'hidden_c': 32, 'latent_c': 16}, 'model_file_path': {'modelFile': {'fileName': 'model.pth', 'filePath': './Models/beatgan_ad/None/SWaT/model.pkl'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save meta\n",
    "from Clust.clust.ML.tool import meta\n",
    "meta_file_name = \"./meta.json\"\n",
    "#ml_meta.save_model_meta_into_mongodb(mongodb_client, param, 'model','meta')\n",
    "meta.save_model_meta_into_local(meta_file_name, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".clust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
