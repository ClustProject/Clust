{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43276846",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95790ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T03:21:52.373651Z",
     "start_time": "2022-08-23T03:21:48.164603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu is available.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../../../\")\n",
    "from Clust.clust.transformation.type.DFToNPArray import transDFtoNP, trans_df_to_np, trans_df_to_np_inf\n",
    "from Clust.clust.ML.common import ML_pipeline, tool\n",
    "from Clust.setting import influx_setting_KETI as ins\n",
    "from Clust.clust.ingestion.influx import influx_client_v2 as influx_Client\n",
    "from Clust.clust.ingestion.mongo.mongo_client import MongoClient\n",
    "\n",
    "\n",
    "\n",
    "db_client = influx_Client.InfluxClient(ins.CLUSTDataServer2)\n",
    "mongo_client = MongoClient(ins.CLUSTMetaInfo2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8601bc",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dca5a",
   "metadata": {},
   "source": [
    "### 1-1. Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd0ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name='actionPattern'\n",
    "model_purpose = 'classification'\n",
    "\n",
    "feature_X_list = ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
    "feature_y_list = ['value']\n",
    "split_mode = \"windows_split\"\n",
    "data_y_flag = True\n",
    "\n",
    "step = 'train'\n",
    "bucket_name = 'integration' \n",
    "data_clean_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f37e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classification_actionPattern_cleanLevel0_testX', 'classification_actionPattern_cleanLevel0_testy', 'classification_actionPattern_cleanLevel0_trainX', 'classification_actionPattern_cleanLevel0_trainy', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel0_trainX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_testX', 'forecasting_Hs2SwineFarmWithWeatherTime_cleanLevel4_trainX', 'forecasting_strawberryOpen_cleanLevel0_testX', 'forecasting_strawberryOpen_cleanLevel0_trainX', 'forecasting_strawberryOpen_cleanLevel4_testX', 'forecasting_strawberryOpen_cleanLevel4_trainX', 'regression_energy_cleanLevel0_testX', 'regression_energy_cleanLevel0_testy', 'regression_energy_cleanLevel0_trainX', 'regression_energy_cleanLevel0_trainy', 'regression_energy_cleanLevel4_testX', 'regression_energy_cleanLevel4_testy', 'regression_energy_cleanLevel4_trainX', 'regression_energy_cleanLevel4_trainy']\n",
      "==========================================================\n",
      "['forecasting_Hs2SwineFarmWithWeatherTime', 'regression_energy', 'classification_actionPattern', 'forecasting_strawberryOpen']\n"
     ]
    }
   ],
   "source": [
    "all_integrated_ms_list = db_client.measurement_list(bucket_name)\n",
    "print(all_integrated_ms_list)\n",
    "print(\"==========================================================\")\n",
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "print(collection_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ed7b1",
   "metadata": {},
   "source": [
    "### 1-2. Data Ingestion\n",
    "#### 1-2-1. Select data name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a390cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = model_purpose + '_' + app_name  \n",
    "data_name_X = dataset_name + '_cleanLevel' + str(data_clean_level)+'_'+step+'X'\n",
    "data_name_y = dataset_name+'_cleanLevel' + str(data_clean_level)+'_'+ step+'y'\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'ms_name':data_name_X})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f5a7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('classification_actionPattern_cleanLevel0_trainX',\n",
       " 'classification_actionPattern_cleanLevel0_trainy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name_X, data_name_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98223f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucket_name': 'integration',\n",
       " 'collection_name': 'classification_actionPattern',\n",
       " 'ms_name': 'classification_actionPattern_cleanLevel0_trainX',\n",
       " 'ingestion_type': 'multiple_ms_by_time',\n",
       " 'ingestion_param': {'ms_list_info': [['bio_action_sensors',\n",
       "    'accelerationTrain']],\n",
       "  'start_time': '1992-01-11',\n",
       "  'end_time': '2012-02-27'},\n",
       " 'processing_type': 'step_3',\n",
       " 'process_param': {'refine_param': {'removeDuplication': {'flag': False},\n",
       "   'staticFrequency': {'flag': False, 'frequency': None}},\n",
       "  'outlier_param': {'certainErrorToNaN': {'flag': False},\n",
       "   'unCertainErrorToNaN': {'flag': False}},\n",
       "  'imputation_param': {'flag': False}},\n",
       " 'integration_param': {'integration_frequency': 675,\n",
       "  'param': {},\n",
       "  'method': 'meta',\n",
       "  'integration_duration': 'common'},\n",
       " 'clean_level': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd1d3e",
   "metadata": {},
   "source": [
    "#### 1-2-2. X-y Data Ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de3c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "ingestion_method = 'ms_all'\n",
    "ingestion_param_X = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_X,\n",
    "    'feature_list' : feature_X_list                              \n",
    "}\n",
    "ingestion_param_y = {\n",
    "    \"bucket_name\" : bucket_name,\n",
    "    'ms_name' : data_name_y,\n",
    "    'feature_list' : feature_y_list                              \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c14470",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = ML_pipeline.Xy_data_preparation(ingestion_param_X, data_y_flag, ingestion_param_y, ingestion_method, db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac47289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941056\n",
      "7352\n",
      "(941056, 9)\n",
      "(7352, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(data_X))\n",
    "print(len(data_y))\n",
    "print(data_X.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe087d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:00:00+00:00</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.022859</td>\n",
       "      <td>1.012817</td>\n",
       "      <td>-0.123217</td>\n",
       "      <td>0.102934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:11:15+00:00</th>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>0.043711</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>1.022833</td>\n",
       "      <td>-0.126876</td>\n",
       "      <td>0.105687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:22:30+00:00</th>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>1.022028</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.102102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:33:45+00:00</th>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.049775</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>1.017877</td>\n",
       "      <td>-0.124928</td>\n",
       "      <td>0.106553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:45:00+00:00</th>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>1.023680</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>0.102814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 23:03:45+00:00</th>\n",
       "      <td>0.022358</td>\n",
       "      <td>-0.280075</td>\n",
       "      <td>-0.180578</td>\n",
       "      <td>0.973228</td>\n",
       "      <td>1.083094</td>\n",
       "      <td>-0.226884</td>\n",
       "      <td>0.991497</td>\n",
       "      <td>-0.486260</td>\n",
       "      <td>-0.205803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 23:15:00+00:00</th>\n",
       "      <td>-0.024451</td>\n",
       "      <td>-0.248612</td>\n",
       "      <td>-0.153920</td>\n",
       "      <td>1.004266</td>\n",
       "      <td>1.187832</td>\n",
       "      <td>-0.313591</td>\n",
       "      <td>0.945067</td>\n",
       "      <td>-0.453405</td>\n",
       "      <td>-0.180733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 23:26:15+00:00</th>\n",
       "      <td>-0.071907</td>\n",
       "      <td>-0.194322</td>\n",
       "      <td>-0.127555</td>\n",
       "      <td>1.004855</td>\n",
       "      <td>1.156645</td>\n",
       "      <td>-0.362512</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>-0.397775</td>\n",
       "      <td>-0.156105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 23:37:30+00:00</th>\n",
       "      <td>-0.142209</td>\n",
       "      <td>-0.147070</td>\n",
       "      <td>-0.092367</td>\n",
       "      <td>1.015589</td>\n",
       "      <td>1.100750</td>\n",
       "      <td>-0.383989</td>\n",
       "      <td>0.828372</td>\n",
       "      <td>-0.349247</td>\n",
       "      <td>-0.122798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 23:48:45+00:00</th>\n",
       "      <td>-0.170999</td>\n",
       "      <td>-0.131399</td>\n",
       "      <td>-0.051127</td>\n",
       "      <td>1.047599</td>\n",
       "      <td>1.011324</td>\n",
       "      <td>-0.335884</td>\n",
       "      <td>0.800243</td>\n",
       "      <td>-0.332372</td>\n",
       "      <td>-0.083572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941056 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              col_0     col_1     col_2     col_3     col_4  \\\n",
       "time                                                                          \n",
       "1992-01-11 00:00:00+00:00  0.000181  0.010767  0.055561  0.030191  0.066014   \n",
       "1992-01-11 00:11:15+00:00  0.010139  0.006579  0.055125  0.043711  0.042699   \n",
       "1992-01-11 00:22:30+00:00  0.009276  0.008929  0.048405  0.035688  0.074850   \n",
       "1992-01-11 00:33:45+00:00  0.005066  0.007489  0.049775  0.040402  0.057320   \n",
       "1992-01-11 00:45:00+00:00  0.010810  0.006141  0.043013  0.047097  0.052343   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2012-02-26 23:03:45+00:00  0.022358 -0.280075 -0.180578  0.973228  1.083094   \n",
       "2012-02-26 23:15:00+00:00 -0.024451 -0.248612 -0.153920  1.004266  1.187832   \n",
       "2012-02-26 23:26:15+00:00 -0.071907 -0.194322 -0.127555  1.004855  1.156645   \n",
       "2012-02-26 23:37:30+00:00 -0.142209 -0.147070 -0.092367  1.015589  1.100750   \n",
       "2012-02-26 23:48:45+00:00 -0.170999 -0.131399 -0.051127  1.047599  1.011324   \n",
       "\n",
       "                              col_5     col_6     col_7     col_8  \n",
       "time                                                               \n",
       "1992-01-11 00:00:00+00:00  0.022859  1.012817 -0.123217  0.102934  \n",
       "1992-01-11 00:11:15+00:00  0.010316  1.022833 -0.126876  0.105687  \n",
       "1992-01-11 00:22:30+00:00  0.013250  1.022028 -0.124004  0.102102  \n",
       "1992-01-11 00:33:45+00:00  0.017751  1.017877 -0.124928  0.106553  \n",
       "1992-01-11 00:45:00+00:00  0.002553  1.023680 -0.125767  0.102814  \n",
       "...                             ...       ...       ...       ...  \n",
       "2012-02-26 23:03:45+00:00 -0.226884  0.991497 -0.486260 -0.205803  \n",
       "2012-02-26 23:15:00+00:00 -0.313591  0.945067 -0.453405 -0.180733  \n",
       "2012-02-26 23:26:15+00:00 -0.362512  0.898095 -0.397775 -0.156105  \n",
       "2012-02-26 23:37:30+00:00 -0.383989  0.828372 -0.349247 -0.122798  \n",
       "2012-02-26 23:48:45+00:00 -0.335884  0.800243 -0.332372 -0.083572  \n",
       "\n",
       "[941056 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f2692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-01-11 00:00:00+00:00</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-12 00:00:00+00:00</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-13 00:00:00+00:00</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-14 00:00:00+00:00</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-01-15 00:00:00+00:00</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-22 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-23 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-24 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-25 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26 00:00:00+00:00</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value\n",
       "time                            \n",
       "1992-01-11 00:00:00+00:00    4.0\n",
       "1992-01-12 00:00:00+00:00    4.0\n",
       "1992-01-13 00:00:00+00:00    4.0\n",
       "1992-01-14 00:00:00+00:00    4.0\n",
       "1992-01-15 00:00:00+00:00    4.0\n",
       "...                          ...\n",
       "2012-02-22 00:00:00+00:00    1.0\n",
       "2012-02-23 00:00:00+00:00    1.0\n",
       "2012-02-24 00:00:00+00:00    1.0\n",
       "2012-02-25 00:00:00+00:00    1.0\n",
       "2012-02-26 00:00:00+00:00    1.0\n",
       "\n",
       "[7352 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab11f1",
   "metadata": {},
   "source": [
    "### 1-2-2. Random Nan Insert (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca253f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratio = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a924d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../../../Clust/clust/ML/common/tool.py:17: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df.loc[df.sample(frac=nan_ratio). index, col] = pd.np.nan\n"
     ]
    }
   ],
   "source": [
    "data_X = tool.random_nan_df(data_X, nan_ratio)\n",
    "data_y = tool.random_nan_df(data_y, nan_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ed176",
   "metadata": {},
   "source": [
    "#### 1-2-3. Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5023759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_param='scale'\n",
    "scale_method='minmax'\n",
    "scaler_path = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be0248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8']\n",
      "Make New scaler File\n",
      "['value']\n",
      "Make New scaler File\n"
     ]
    }
   ],
   "source": [
    "dataX_scaled, X_scalerFilePath, datay_scaled, y_scalerFilePath= ML_pipeline.Xy_data_scaling_train(data_name_X, data_X, data_name_y, data_y, scaler_path, scaler_param, scale_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8f468",
   "metadata": {},
   "source": [
    "## 2. Cleaning and split\n",
    "### 2.1 pipeline - clean low quality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8731a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = False\n",
    "nan_process_info = {'type':'num', 'ConsecutiveNanLimit':10000, 'totalNaNLimit':100000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06b2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_scaled = ML_pipeline.clean_low_quality_column(model_clean, nan_process_info, dataX_scaled)\n",
    "feature_X_list= list(dataX_scaled.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ca2e8",
   "metadata": {},
   "source": [
    "### 2.2 Train/Val Split pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51ba9bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6673e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 데이터 나뉘는 부분 추가로 작성된 것 지수님에게 물어봐야 함\n",
    "day_window_size = tool.get_default_day_window_size(dataX_scaled)\n",
    "train_x, val_x, train_y, val_y = ML_pipeline.split_data_by_mode(split_mode, split_ratio, dataX_scaled, datay_scaled, day_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b6226",
   "metadata": {},
   "source": [
    "### 2.3 Data Transformation & Clean2 pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a7d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nan_limit_ratio = 0.5\n",
    "transformParameter = {\n",
    "        'past_step':day_window_size,\n",
    "        'max_nan_limit_ratio': max_nan_limit_ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "476384ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 128 nan_limit_num: 64\n",
      "(752768, 9) (5881, 128, 9)\n",
      "(5881, 1) (5881, 1)\n",
      "window_size: 128 nan_limit_num: 64\n",
      "(188288, 9) (1471, 128, 9)\n",
      "(1471, 1) (1471, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X_array, train_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, train_x, train_y)\n",
    "val_X_array, val_y_array = ML_pipeline.transform_data_by_split_mode(split_mode, transformParameter, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5aaf071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5881, 128, 9)\n",
      "(5881, 1)\n",
      "(1471, 128, 9)\n",
      "(1471, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_array.shape)\n",
    "print(train_y_array.shape)\n",
    "print(val_X_array.shape)\n",
    "print(val_y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b5d18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_method = 'LSTM_cf'\n",
    "dim = 3\n",
    "\n",
    "if model_method == \"FC_cf\":\n",
    "    dim = 2\n",
    "\n",
    "input_size = train_X_array.shape[1]\n",
    "if dim != 2:\n",
    "    seq_len = train_X_array.shape[2] # seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6fb92",
   "metadata": {},
   "source": [
    "### 2.4 Set Model and train parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d533ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "if model_method == 'LSTM_cf' or model_method == 'GRU_cf':\n",
    "    modelParameter = {\n",
    "        'input_size': input_size,\n",
    "        'seq_len': seq_len,\n",
    "        'num_classes': 6,\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True  # 모델의 양방향성 여부, bool(default: True)   \n",
    "    }\n",
    "    if model_method == 'LSTM_cf':\n",
    "        modelParameter['rnn_type'] = 'lstm'\n",
    "    else:\n",
    "        modelParameter['rnn_type'] = 'gru'\n",
    "        \n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "    'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "    'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "    'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "    'drop_out': 0.1 # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "    'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "    'fc_drop_out': 0.1 # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# FC model parameters\n",
    "elif model_method == 'FC_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_classes': 6,\n",
    "    'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    'bias': True# bias 사용 여부, bool(default: True)\n",
    "    }\n",
    "\n",
    "train_parameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': 'cpu', \n",
    "    'n_epochs': 5, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fccfa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = None\n",
    "model_file_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366ee67",
   "metadata": {},
   "source": [
    "### 2.5 Set Model name and path pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "104e3bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Models/LSTM_cf/actionPattern_LSTM_cf_False/classification_actionPattern_cleanLevel0_trainX/035b06e2d9df4a58aa1dd8622746dd1f/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# model_name and file path check and create\n",
    "model_name = tool.get_default_model_name(model_name, app_name, model_method, model_clean)\n",
    "model_file_path = tool.get_default_model_path(model_name, data_name_X, model_method, train_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0391e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actionPattern_LSTM_cf_False'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454abbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clust.clust.ML.classification.train import ClassificationTrain as CML\n",
    "def CLUST_classification_train(train_X_array, train_y_array, val_X_array, val_y_array, train_parameter, model_method, model_file_path, modelParameter):\n",
    "    cml = CML()\n",
    "    cml.set_param(train_parameter)\n",
    "    cml.set_model(model_method, modelParameter)\n",
    "    cml.set_data(train_X_array, train_y_array, val_X_array, val_y_array)\n",
    "    cml.train()\n",
    "    cml.save_best_model(model_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3ac2c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCLUST_classification_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelParameter\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mCLUST_classification_train\u001b[0;34m(train_X_array, train_y_array, val_X_array, val_y_array, train_parameter, model_method, model_file_path, modelParameter)\u001b[0m\n\u001b[1;32m      5\u001b[0m cml\u001b[38;5;241m.\u001b[39mset_model(model_method, modelParameter)\n\u001b[1;32m      6\u001b[0m cml\u001b[38;5;241m.\u001b[39mset_data(train_X_array, train_y_array, val_X_array, val_y_array)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m cml\u001b[38;5;241m.\u001b[39msave_best_model(model_file_path)\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/train.py:98\u001b[0m, in \u001b[0;36mClassificationTrain.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mTrain and return model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    model: train model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/classification_model/rnn_model.py:95\u001b[0m, in \u001b[0;36mRNNModel.train\u001b[0;34m(self, train_params, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# training 단계에서만 gradient 업데이트 수행\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# input을 model에 넣어 output을 도출한 후, loss를 계산함\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     96\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# output 중 최댓값의 위치에 해당하는 class로 예측을 수행\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/CLUST_KETI/Clust/clust/ML/classification/models/rnn.py:33\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# initial hidden states 설정\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m h0 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_directions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 선택한 rnn_type의 RNN으로부터 output 도출\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgru\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "CLUST_classification_train(train_X_array, train_y_array, val_X_array, val_y_array, train_parameter, model_method, model_file_path, modelParameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834abe4",
   "metadata": {},
   "source": [
    "## 4. save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "modelTags =[\"model_tag_example\"]\n",
    "trainDataType = \"timeseries\"\n",
    "\n",
    "modelInfoMeta ={\n",
    "    \"trainDataInfo\":data_meta,\n",
    "    \"modelName\":model_name,\n",
    "    \"dataSplitMode\":split_mode,\n",
    "    \"featureXList\":feature_X_list,\n",
    "    \"featureyList\":feature_y_list,\n",
    "    \"data_y_flag\": data_y_flag,\n",
    "    \"trainDataType\":trainDataType,\n",
    "    \"modelPurpose\":model_purpose,\n",
    "    \"modelMethod\":model_method,\n",
    "    \"modelTags\":modelTags,\n",
    "    \"modelCleanLevel\":model_clean,\n",
    "    \"trainParameter\": train_parameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \"transformParameter\":transformParameter,\n",
    "    \"scalerParam\":scaler_param,\n",
    "    \"trainDataName\":[data_name_X, data_name_y], \n",
    "\n",
    "    \"files\":{\n",
    "        \"modelFile\":{\n",
    "            \"fileName\":\"model.pth\",\n",
    "            \"filePath\":model_file_path\n",
    "        },\n",
    "        \"XScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":X_scalerFilePath       \n",
    "        },\n",
    "        \"yScalerFile\":{\n",
    "            \"fileName\":\"scaler.pkl\",\n",
    "            \"filePath\":y_scalerFilePath      \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a4774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd30502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7018171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7889e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58784d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c44429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436a3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ac989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177b9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bd32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8729e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model methods i.e., 'LSTM_cf', 'GRU_cf', 'CNN_1D_cf', 'LSTM_FCNs_cf', 'FC_cf' \n",
    "model_method = 'LSTM_cf'\n",
    "\n",
    "# get integrated data name\n",
    "bucket_name = 'integration'\n",
    "\n",
    "# scaler path\n",
    "scalerPath = './scaler/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4967f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ms_list = db_client.measurement_list(bucket_name)\n",
    "get_ms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_list = mongo_client.get_collection_list(bucket_name)\n",
    "collection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_X = 'classification_actionPattern_trainX_cleanLevel0'\n",
    "dataX = db_client.get_data(bucket_name, data_name_X)\n",
    "\n",
    "# datay\n",
    "data_name_y = 'classification_actionPattern_trainy_cleanLevel0'\n",
    "datay = db_client.get_data(bucket_name, data_name_y)\n",
    "\n",
    "dataset_name = collection_list[4]\n",
    "data_meta = mongo_client.get_document_by_json('integration', dataset_name, {'data_name':data_name_X})[0]\n",
    "clean_level = data_meta[\"clean_level\"]\n",
    "integration_freq_sec = data_meta[\"integration_param\"][\"integration_frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0bca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Training Data Preparation\n",
    "# 2-1\n",
    "featureListX= list(dataX.columns)\n",
    "featureListy= list(datay.columns)\n",
    "\n",
    "# 2-2\n",
    "# cleanTrainDataParam = 'NoClean'#  Classification, Regression과 같이 X, y가 분리된 경우에는 현재 고정해서 사용해야함\n",
    "# cleanTrainDataParam = clean_level --> clean_level로 변경\n",
    "\n",
    "# 2-2-1 cleanTrainDataParam == Clean 일 경우\n",
    "NaNProcessingParam ={\n",
    "    \"feature_cycle\":'Day',\n",
    "    \"feature_cycle_times\":1,\n",
    "    \"NanInfoForCleanData\":{'type':'num', 'ConsecutiveNanLimit':3, 'totalNaNLimit':30000}\n",
    "}\n",
    "# 2-3\n",
    "scalerParam='noscale'\n",
    "scaleMethod='minmax'\n",
    "\n",
    "# 2-4\n",
    "splitRatio = 0.8\n",
    "mode = 'Classification'\n",
    "\n",
    "# 2-5\n",
    "scalerRootPath_X = os.path.join(scalerPath, data_name_X, str(clean_level))\n",
    "scalerRootPath_y = os.path.join(scalerPath, data_name_y, str(clean_level))\n",
    "train_X, val_X, X_scalerFilePath = ml_data.get_train_val_data(dataX, featureListX, scalerRootPath_X, splitRatio, scalerParam, scaleMethod, mode)\n",
    "train_y, val_y, y_scalerFilePath = ml_data.get_train_val_data(datay, featureListy, scalerRootPath_y, splitRatio, \"NoScale\", scaleMethod, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b971b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformParameter = {\n",
    "    'window_num':128\n",
    "}\n",
    "\n",
    "window_num = 0\n",
    "dim = 3\n",
    "\n",
    "if model_method == \"FC_cf\":\n",
    "    dim = 2\n",
    "\n",
    "if type(train_X) !=  np.ndarray:\n",
    "    train_X, train_y = transDFtoNP(train_X, train_y, window_num, dim)\n",
    "    val_X, val_y = transDFtoNP(val_X, val_y, window_num, dim)\n",
    "\n",
    "input_size = train_X.shape[1]\n",
    "if dim != 2:\n",
    "    seq_len = train_X.shape[2] # seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58949b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_X), train_X.shape)\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c95224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN models (RNN, LSTM, GRU) parameters\n",
    "if model_method == 'LSTM_cf' or model_method == 'GRU_cf':\n",
    "    modelParameter = {\n",
    "        'input_size': input_size,\n",
    "        'seq_len': seq_len,\n",
    "        'num_classes': 6,\n",
    "        'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "        'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "        'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "        'bidirectional': True  # 모델의 양방향성 여부, bool(default: True)   \n",
    "    }\n",
    "    if model_method == 'LSTM_cf':\n",
    "        modelParameter['rnn_type'] = 'lstm'\n",
    "    else:\n",
    "        modelParameter['rnn_type'] = 'gru'\n",
    "        \n",
    "# CNN_1D model parameters\n",
    "elif model_method == 'CNN_1D_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "    'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "    'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "    'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "    'drop_out': 0.1 # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# LSTM_FCNs model parameters\n",
    "elif model_method == 'LSTM_FCNs_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'seq_len': seq_len,\n",
    "    'num_classes': 6,\n",
    "    'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "    'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "    'fc_drop_out': 0.1 # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    }\n",
    "    \n",
    "# FC model parameters\n",
    "elif model_method == 'FC_cf':\n",
    "    modelParameter = {\n",
    "    'input_size': input_size,\n",
    "    'num_classes': 6,\n",
    "    'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "    'bias': True# bias 사용 여부, bool(default: True)\n",
    "    }\n",
    "\n",
    "trainParameter = {\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-6, \n",
    "    'device': device, \n",
    "    'n_epochs': 5, \n",
    "    'batch_size': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76967ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTags =[\"action\", \"sensor\", \"classification\", \"pattern\"]\n",
    "trainDataType = \"timeseries\"\n",
    "modelPurpose = \"classification\"\n",
    "\n",
    "# # 2\n",
    "trainDataInfo = data_meta\n",
    "\n",
    "# 3. 모델을 저장할 파일 패스를 생성한다.\n",
    "model_name = None\n",
    "if model_name is None:\n",
    "    model_name = dataset_name + '_' + model_method + '_cleanLevel' + str(clean_level)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(model_name)\n",
    "\n",
    "from Clust.clust.transformation.general.dataScaler import encode_hash_style\n",
    "trainParameter_encode =  encode_hash_style(str(trainParameter))\n",
    "trainDataPathList = [model_name, data_name_X, trainParameter_encode]\n",
    "modelFilePath = ml_model.get_model_file_path(trainDataPathList, model_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2e028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Clust.clust.ML.classification.train import ClassificationTrain as CML\n",
    "\n",
    "cml = CML()\n",
    "cml.set_param(trainParameter)\n",
    "cml.set_model(model_method, modelParameter)\n",
    "cml.set_data(train_X, train_y, val_X, val_y)\n",
    "cml.train()\n",
    "cml.save_best_model(modelFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    \"modelName\": model_name,\n",
    "    \"trainDataInfo\": trainDataInfo,\n",
    "    \"featureList\": featureListX,\n",
    "    \"target\": featureListy,\n",
    "    \"trainDataType\": trainDataType,\n",
    "    \"modelPurpose\": modelPurpose,\n",
    "    \"model_method\": model_method,\n",
    "    \"modelTags\": modelTags,\n",
    "    \"trainDataName\": [data_name_X,data_name_y],\n",
    "    \"cleanLevel\":clean_level,\n",
    "    \"NaNProcessingParam\":NaNProcessingParam,\n",
    "    \"scalerParam\": scalerParam,\n",
    "    \"trainParameter\": trainParameter,\n",
    "    \"modelParameter\": modelParameter,\n",
    "    \n",
    "    \"files\":{\n",
    "            \"modelFile\":{\n",
    "                    \"fileName\":\"model.pth\",\n",
    "                    \"filePath\":modelFilePath\n",
    "                },\n",
    "            \"XScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":X_scalerFilePath       \n",
    "                },\n",
    "            \"yScalerFile\":{\n",
    "                    \"fileName\":\"scaler.pkl\",\n",
    "                    \"filePath\":y_scalerFilePath       \n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "modelInfoMeta = ml_meta.save_model_meta_data(mongo_client, model_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a987601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bae6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "f1ef7e1f828dbb4e75f421045d2c565197efaf8469a0be4a314c6ea8378b5cb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
